# -*- org-export-babel-evaluate: nil -*-
#+TITLE: The kcats Programming Language (Production Implementation)
#+AUTHOR: Skyrod Vactai
#+BABEL: :cache yes
#+OPTIONS: toc:4 h:4
#+STARTUP: showeverything
#+PROPERTY: header-args:clojure :noweb yes :results value silent
#+PROPERTY: header-args:kcats :noweb yes :results code :exports both
#+TODO: TODO(t) INPROGRESS(i!) | DONE(d!) CANCELED(c@)
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
#+HTML_HEAD: <style> pre.src { background: black; color: white; } #content { max-width: 1000px } </style>
#+HTML_HEAD: <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
#+HTML_HEAD: <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="https://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="https://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="docs-custom.css"/>

* Production implementation
** Base Language
Built in Rust - it's fast and modern, its memory allocation model
seems well suited to kcats.
** Status
Unstable
** Building
*** Dependencies
- rustc
- cargo
*** Build
Run =cargo build --release=, the binary will be placed in =./target/release= by
default.
** Using
:PROPERTIES:
:CUSTOM_ID: using
:END:

*** Command line REPL
This is the easiest way to get started. Run =kcats -r= and it will print
a prompt and wait for you to input items (as many as you like, on a
single line). It will then evaluate all the items and print the
resulting stack. You can then enter more items. It keeps the stack
intact so you're not starting fresh with each input. If you want to
clear the stack, you can use =[] restore=.

Use Ctrl-C to quit.

Example session:
#+begin_src fundamental
~/workspace/kcats $ kcats -r
kcats> 1
1
kcats> 2
2 1
kcats> +
3
kcats> [7 8 9] [*] step
1512
kcats> 
#+end_src
*** Command line
Execute =kcats=. It will read a program from stdin and execute it,
then print the resulting stack to stdout. You can pass input to it via stdin via
+ interactive typing (end input with CTRL-D on most platforms): =kcats=
+ Piping from a file eg: =kcats < myprog.kcats=
+ Using echo: =echo "[1 2 3] [inc] map" | kcats=
*** Emacs Interactive REPL
See =emacs-ide.org= in the source tree. The elisp files you need to
evaluate are there. Evaluate them, then run =M-x kcats-repl=. You may
need to run =M-x customize-variable=, =kcats-babel-executable=, and enter
the location where you installed the kcats binary.
** Source
:PROPERTIES:
:CUSTOM_ID: source
:END:

*** Project File
#+BEGIN_SRC toml :tangle Cargo.toml
  [package]
  name = "kcats"
  version = "0.6.0"
  edition = "2021"

  # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

  [dependencies]
  # serialization
  edn-format = "3.3.0"
  serde = "1"
  serde_json = "1"

  #edn-format = { path = "../edn-format" }
  base64 = "0.13.0"

  # String literals
  internment = {version = "0.6.0", features = ["serde"]}
  lazy_static = "1.4.0"

  num-integer = "0.1.44"

  # String format
  dynfmt = { version = "0.1.5", features = ["curly"] }

  # crypto stuff
  ed25519-dalek = {version="1", features=["batch_deterministic", "std", "rand"]}
  sha2 = "0.10.6"
  rand_core = "0.5.1" # careful here, having 2 versions present will make weird compile errors
  rand = "0.8"

  # multithreading
  futures = "0.3"
  tokio = { version = "1", features = ["full"] }
  # multiple-consumer channels
  #crossbeam-channel = "0.5" # doesn't support async send/recv
  #async-channel = "1.8.0"
  flume = "0.11.0"

  # debugging
  backtrace = "0.3.61"

  # database
  #indradb-lib = { version = "*", features = ["rocksdb-datastore"] }
  #rocksdb = "0.21.0"
  cozo = { version = "0.7", features = ["storage-sqlite"] }
  chrono = "0.4.31"

  [dev-dependencies]
  test-case = "2.0.0"

  [features]
#+END_SRC
*** Internal data types
**** Basic internal types
We'll start by defining the basic data structures that kcats will use
internally, to keep track of things like the stack, program, lists etc.
#+begin_src rust :tangle src/types.rs :mkdirp yes
  use crate::types::collection as coll;
  use crate::types::dictionary as dict;
  use crate::types::environment as env;
  use crate::types::error::Error;
  use core::default::Default;
  use internment::Intern;
  use lazy_static::lazy_static;
  use std::collections::{HashMap, VecDeque};
  use std::fmt;
  use std::hash::Hash;
  use std::marker::Sync;
  use std::ops::{Deref, DerefMut};
  use std::pin::Pin;

  pub mod associative;
  pub mod collection;
  pub mod dictionary;
  pub mod environment;
  pub mod error;

  // A generic newtype to contain various kinds
  #[derive(PartialEq, Eq, PartialOrd, Ord, Hash)]
  pub struct Newtype<T>(pub T);

  // Access the inner value easily
  impl<T> Deref for Newtype<T> {
      type Target = T;

      fn deref(&self) -> &Self::Target {
          &self.0
      }
  }

  impl<T> DerefMut for Newtype<T> {
      fn deref_mut(&mut self) -> &mut Self::Target {
          &mut self.0
      }
  }

  impl<T: IntoIterator> IntoIterator for Newtype<T> {
      type Item = T::Item;
      type IntoIter = T::IntoIter;

      fn into_iter(self) -> Self::IntoIter {
          self.0.into_iter()
      }
  }

  // but still clone the whole thing, not the inner part
  impl<T: Clone> Clone for Newtype<T> {
      fn clone(&self) -> Self {
          Newtype(self.0.clone())
      }
  }

  // Implement Debug trait for Newtype, so it hides
  // itself and only prints the inner type.
  impl<T: fmt::Debug> fmt::Debug for Newtype<T> {
      fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
          // Directly print the wrapped value
          write!(f, "{:?}", self.0)
      }
  }

  pub type Word = Intern<String>;

  pub type Stack = collection::List;

  pub type Bytes = Vec<u8>;

  pub type Int = i64;

  pub type Float = f64;

  pub type Char = char;

  lazy_static! {
      pub static ref S_ASSOC: Intern<String> = Intern::new("association".to_string());
      pub static ref S_BOOLEAN: Intern<String> = Intern::new("boolean".to_string());
      pub static ref S_BYTES: Intern<String> = Intern::new("bytes".to_string());
      pub static ref S_CHAR: Intern<String> = Intern::new("character".to_string());
      pub static ref S_DISPENSER: Intern<String> = Intern::new("dispenser".to_string());
      pub static ref S_ENVIRONMENT: Intern<String> = Intern::new("environment".to_string());
      pub static ref S_ERROR: Intern<String> = Intern::new("error".to_string());
      pub static ref S_FLOAT: Intern<String> = Intern::new("float".to_string());
      pub static ref S_INTEGER: Intern<String> = Intern::new("integer".to_string());
      pub static ref S_ITEM: Intern<String> = Intern::new("item".to_string());
      pub static ref S_LIST: Intern<String> = Intern::new("list".to_string());
      pub static ref S_NUMBER: Intern<String> = Intern::new("number".to_string());
      pub static ref S_ORDERED: Intern<String> = Intern::new("ordered".to_string());
      pub static ref S_PIPE: Intern<String> = Intern::new("pipe".to_string());
      pub static ref S_PROGRAM: Intern<String> = Intern::new("program".to_string());
      pub static ref S_RECEPTACLE: Intern<String> = Intern::new("receptacle".to_string());
      pub static ref S_SIZED: Intern<String> = Intern::new("sized".to_string());
      pub static ref S_STRING: Intern<String> = Intern::new("string".to_string());
      pub static ref S_WORD: Intern<String> = Intern::new("word".to_string());
  }

  #[derive(Debug, Clone)]
  pub enum Item {
      Int(Int),
      Float(Float),
      Word(Word),
      Char(Char),
      Dispenser(coll::Dispenser),
      Receptacle(coll::Receptacle),
  }

  pub type Future<T> = Pin<Box<dyn std::future::Future<Output = T> + Send>>;
  pub type StepFn = dyn Fn(env::Environment) -> Future<env::Environment> + Sync + Send;

  impl PartialEq for Item {
      fn eq(&self, other: &Self) -> bool {
          match (self, other) {
              // same types, just use their own eq
              (Item::Int(a), Item::Int(b)) => a == b,
              (Item::Float(a), Item::Float(b)) => a == b,
              (Item::Float(a), Item::Int(b)) => *a == *b as Float,
              (Item::Int(a), Item::Float(b)) => *a as Float == *b,
              (Item::Word(a), Item::Word(b)) => a == b,
              (
                  Item::Dispenser(coll::Dispenser::Sized(a)),
                  Item::Receptacle(coll::Receptacle::Sized(b)),
              ) => a == b,
              (
                  Item::Receptacle(coll::Receptacle::Sized(a)),
                  Item::Dispenser(coll::Dispenser::Sized(b)),
              ) => a == b,
              (Item::Dispenser(a), Item::Dispenser(b)) => a == b,
              (Item::Char(a), Item::Char(b)) => a == b,
              _ => false,
          }
      }
  }

  // The default Item is empty list.
  impl Default for Item {
      fn default() -> Self {
          coll::Dispenser::default().into()
      }
  }

  pub fn wrap(i: Item) -> coll::List {
      coll::List::from_iter([i])
  }

  impl TryFrom<Item> for Int {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Int(i) => Ok(i),
              i => Err(Error::expected("integer", i)),
          }
      }
  }

  impl TryFrom<Item> for Float {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Float(i) => Ok(i),
              i => Err(Error::expected("float", i)),
          }
      }
  }

  impl TryFrom<Item> for String {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;
          match s {
              coll::Sized::String(i) => Ok(i),
              i => Err(Error::expected("string", i.into())),
          }
      }
  }

  impl TryFrom<Item> for Word {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Word(i) => Ok(i),
              i => Err(Error::expected("word", i)),
          }
      }
  }

  impl TryFrom<Item> for Bytes {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;
          match s {
              coll::Sized::Bytes(b) => Ok(b),
              b => Err(Error::expected("bytes", b.into())),
          }
      }
  }

  // impl TryFrom<Item> for Association {
  //     type Error = Error;
  //     fn try_from(i: Item) -> Result<Self, Self::Error> {
  //         match i {
  //             Item::Assoc(a) => Ok(a),
  //             Item::List(l) => Ok(to_hash(l)?),
  //             Item::Nothing => Ok(Arc::new(AssociationContent::new())),
  //             Item::DerivedDef(d) => Ok(Association::from(d)),
  //             Item::AxiomDef(a) => Ok(Association::from(a)),
  //             Item::Env(e) => Ok(Association::from(e)),
  //             Item::Error(e) => Ok(Association::from(e)),
  //             _ => Err(Error::expected("association")),
  //         }
  //     }
  // }

  // As there are no real booleans, we use the word 'yes' but literally
  // any value except empty containers is truthy. If we read a value
  // 'false' in edn, that's not actually a boolean, it's just the
  // symbol/word false.
  impl From<bool> for Item {
      fn from(b: bool) -> Item {
          if b {
              "yes".into()
          } else {
              Item::default()
          }
      }
  }

  // impl From<Environment> for Association {
  //     fn from(env: Environment) -> Association {
  //         let mut a = AssociationContent::new();
  //         a.insert(word_key("stack"), Item::List(env.stack.clone()));
  //         a.insert(word_key("program"), Item::List(env.program.clone()));
  //         a.insert(word_key("dictionary"), Item::Assoc(env.dictionary.clone()));
  //         Arc::new(a)
  //     }
  // }

  impl From<std::io::Error> for Error {
      fn from(err: std::io::Error) -> Error {
          Error::create(wrap("io".into()), &err.to_string(), None)
      }
  }

  impl From<dynfmt::Error<'_>> for Error {
      fn from(err: dynfmt::Error) -> Error {
          Error::create(wrap("format".into()), &err.to_string(), None)
      }
  }

  impl From<&str> for Item {
      fn from(i: &str) -> Self {
          Item::Word(Word::from(i))
      }
  }

  impl From<String> for Item {
      fn from(i: String) -> Self {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(i)))
      }
  }

  impl From<Bytes> for Item {
      fn from(b: Bytes) -> Self {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(b)))
      }
  }

  impl From<Char> for Item {
      fn from(c: Char) -> Self {
          Item::Char(c)
      }
  }

  impl From<Int> for Item {
      fn from(c: Int) -> Self {
          Item::Int(c)
      }
  }

  impl<T> From<Option<T>> for Item
  where
      Item: From<T>,
  {
      fn from(opt: Option<T>) -> Item {
          match opt {
              Some(t) => Item::from(t),
              None => Item::default(),
          }
      }
  }

  mod serde {
      use super::Item;
      use crate::types::associative as assoc;
      use crate::types::collection as coll;
      use crate::types::{wrap, Error};
      use serde::de::{self, Deserialize, Deserializer, Visitor};
      use serde::ser::{Serialize, Serializer};
      use std::collections::HashMap;
      use std::fmt;

      struct ItemVisitor;

      impl<'de> Visitor<'de> for ItemVisitor {
          type Value = Item;

          fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
              formatter.write_str("expected a specific representation for Item")
          }

          fn visit_i64<E>(self, value: i64) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::Int(value))
          }

          fn visit_u64<E>(self, value: u64) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::Int(value as i64))
          }

          fn visit_f64<E>(self, value: f64) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::Float(value))
          }

          fn visit_none<E>(self) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::default())
          }

          fn visit_bool<E>(self, v: bool) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::from(v))
          }

          fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::Dispenser(coll::Dispenser::Sized(
                  coll::Sized::String(v.to_string()),
              )))
          }

          fn visit_byte_buf<E>(self, v: Vec<u8>) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(
                  v,
              ))))
          }

          fn visit_map<A>(self, mut ma: A) -> Result<Self::Value, A::Error>
          where
              A: de::MapAccess<'de>,
          {
              let mut map = HashMap::new();
              while let Some((key, value)) = ma.next_entry::<assoc::KeyItem, Item>()? {
                  map.insert(key, value);
              }
              Ok(Item::Dispenser(coll::Dispenser::Sized(
                  coll::Sized::Associative(assoc::Associative::Assoc(map.into())),
              )))
          }

          fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
          where
              A: de::SeqAccess<'de>,
          {
              let mut items = Vec::new();
              while let Some(item) = seq.next_element::<Item>()? {
                  items.push(item);
              }
              Ok(coll::List::from(items).into())
          }
      }

      impl<'de> Deserialize<'de> for Item {
          fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
          where
              D: Deserializer<'de>,
          {
              deserializer.deserialize_any(ItemVisitor)
          }
      }

      impl From<serde_json::Error> for Error {
          fn from(err: serde_json::Error) -> Error {
              Error::create(wrap("serialize".into()), &err.to_string(), None)
          }
      }

      impl Serialize for Item {
          fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
          where
              S: Serializer,
          {
              match *self {
                  Item::Int(i) => serializer.serialize_i64(i),
                  Item::Float(f) => serializer.serialize_f64(f),
                  Item::Char(c) => serializer.serialize_char(c),
                  Item::Word(w) => serializer.serialize_str(w.as_str()),

                  // Handle other variants
                  Item::Dispenser(ref dispenser) => dispenser.serialize(serializer),
                  Item::Receptacle(ref receptacle) => receptacle.serialize(serializer),
              }
          }
      }
  }
#+end_src
**** Collection types
#+begin_src rust :tangle src/types/collection.rs :mkdirp yes
  use futures::FutureExt;

  use crate::pipes as pipe;
  use crate::types::associative as assoc;
  use crate::types::*;
  use std::{collections::HashSet, future, sync};

  pub type Arc<T> = Newtype<sync::Arc<T>>;
  pub type Listy<I> = Newtype<VecDeque<I>>;
  pub type Setty<I> = Newtype<HashSet<I>>;
  // impl<T: PartialEq> PartialEq for Newtype<Arc<T>> {
  //     fn eq(&self, other: &Self) -> bool {
  //         **self.0 == **other.0
  //     }
  // }

  impl<T: Clone> Arc<T> {
      pub fn make_mut(&mut self) -> &mut T {
          sync::Arc::make_mut(&mut self.0)
      }

      pub fn inner(&self) -> T {
          sync::Arc::try_unwrap(self.0.clone()).unwrap_or_else(|rc| (*rc).clone())
      }

      pub fn wrap(inner: T) -> Self {
          Self(sync::Arc::new(inner))
      }
  }

  pub type ListContent = Listy<Item>;
  pub type List = Arc<ListContent>;
  pub type Set = Arc<Setty<assoc::KeyItem>>;

  impl Set {
      pub fn from(h: HashSet<assoc::KeyItem>) -> Set {
          Newtype(sync::Arc::new(Newtype(h)))
      }
  }

  impl FromIterator<Item> for List {
      fn from_iter<I>(iter: I) -> Self
      where
          I: IntoIterator<Item = Item>,
      {
          Newtype(sync::Arc::new(Newtype(
              iter.into_iter().collect::<VecDeque<Item>>(),
          )))
      }
  }

  impl FromIterator<assoc::KeyItem> for Set {
      fn from_iter<I>(iter: I) -> Self
      where
          I: IntoIterator<Item = assoc::KeyItem>,
      {
          Newtype(sync::Arc::new(Newtype(
              iter.into_iter().collect::<HashSet<assoc::KeyItem>>(),
          )))
      }
  }

  // Most generic collection type, all we know is it can contain
  // multiple items.
  #[derive(Debug, Clone, PartialEq)]
  pub enum Dispenser {
      Sized(Sized),
      Out(pipe::Out),
      Tunnel(pipe::Tunnel),
  }

  #[derive(Debug, Clone, PartialEq)]
  pub enum Receptacle {
      Sized(Sized),
      In(pipe::In),
      Tunnel(pipe::Tunnel),
  }

  // Collection that has a definite size that we can access. Implies
  // that it can also be appended to.
  #[derive(Debug, Clone)]
  pub enum Sized {
      Associative(assoc::Associative),
      List(List),
      Set(Set),
      String(String),
      Bytes(Bytes),
  }

  impl PartialEq for Sized {
      fn eq(&self, other: &Self) -> bool {
          if self.is_empty() && other.is_empty() {
              return true;
          }
          match (self, other) {
              (Sized::Associative(a), Sized::Associative(b)) => a == b,
              (Sized::List(a), Sized::List(b)) => a == b,
              (Sized::String(a), Sized::String(b)) => a == b,
              (Sized::Bytes(a), Sized::Bytes(b)) => a == b,
              (Sized::Set(a), Sized::Set(b)) => a == b,
              _ => false,
          }
      }
  }

  impl Dispenser {
      pub fn take(self) -> Future<(Dispenser, Option<Item>)> {
          match self {
              Dispenser::Sized(s) => {
                  let (s, item) = s.take();

                  Box::pin(future::ready((Dispenser::Sized(s), item)))
              }
              Dispenser::Out(mut o) => Box::pin({
                  let i = o.take();
                  i.map(|r| {
                      (
                          Dispenser::Out(o),
                          match r {
                              Ok(Some(i)) => Some(i),
                              Ok(None) => None,
                              Err(e) => Some(Item::from(e)),
                          },
                      )
                  })
              }),
              Dispenser::Tunnel(mut t) => Box::pin({
                  let i = t.take();
                  i.map(|r| {
                      (
                          Dispenser::Tunnel(t),
                          match r {
                              Ok(Some(i)) => Some(i),
                              Ok(None) => None,
                              Err(e) => Some(Item::from(e)),
                          },
                      )
                  })
              }),
          }
      }
  }

  impl Sized {
      pub fn is_empty(&self) -> bool {
          self.len() == 0
      }

      pub fn len(&self) -> usize {
          match self {
              Sized::Associative(a) => a.len(),
              Sized::List(l) => l.len(),
              Sized::String(s) => s.len(),
              Sized::Bytes(b) => b.len(),
              Sized::Set(s) => s.len(),
          }
      }

      pub fn take(self) -> (Self, Option<Item>) {
          match self {
              Sized::Associative(a) => {
                  let (a, i) = a.take();
                  (Sized::Associative(a), i)
              }
              Sized::List(mut l) => {
                  let lm = l.make_mut();
                  let i = lm.pop_front();
                  (Sized::List(l), i)
              }
              Sized::String(mut s) => {
                  // TODO: this may perform badly
                  let first_char = s.chars().next();
                  s.drain(..first_char.map(|s| s.len_utf8()).unwrap_or(0));
                  let i = first_char.map(Item::Char);
                  (Sized::String(s), i)
              }
              Sized::Bytes(mut b) => {
                  if b.is_empty() {
                      (Sized::Bytes(b), None)
                  } else {
                      let i = Some(Item::Int(b[0] as Int));
                      b.drain(..1);
                      (Sized::Bytes(b), i)
                  }
              }
              Sized::Set(mut s) => {
                  let i = s.iter().next().cloned();
                  let sm = s.make_mut();
                  if let Some(i) = i.clone() {
                      sm.take(&i);
                  }
                  (Sized::Set(s), i.map(Item::from))
              }
          }
      }

      pub fn pop(self) -> (Self, Option<Item>) {
          match self {
              Sized::Associative(a) => {
                  let (a, i) = a.take();
                  (Sized::Associative(a), i)
              }
              Sized::List(mut l) => {
                  let lm = l.make_mut();
                  let i = lm.pop_back();
                  (Sized::List(l), i)
              }
              Sized::String(mut s) => s
                  .pop()
                  .map(|c| (Sized::String(s), Some(c.into())))
                  .unwrap_or((Sized::String(String::new()), None)),
              Sized::Bytes(mut b) => b
                  .pop()
                  .map(|c| (Sized::Bytes(b), Some((c as Int).into())))
                  .unwrap_or((Sized::Bytes(vec![]), None)),
              Sized::Set(mut s) => {
                  let i = s.iter().next().cloned();
                  let sm = s.make_mut();
                  if let Some(i) = i.clone() {
                      sm.take(&i);
                  }
                  (Sized::Set(s), i.map(Item::from))
              }
          }
      }

      pub fn put(self, other: Item) -> Result<Sized, Error> {
          match (self, other) {
              (Sized::List(mut c), i) => {
                  c.make_mut().push_back(i);
                  Ok(Sized::List(c))
              }
              (Sized::Associative(a), l) => Ok(Sized::Associative(a.put(l)?)),
              (Sized::Set(mut s), i) => {
                  s.make_mut().insert(assoc::KeyItem::try_from(i)?);
                  Ok(Sized::Set(s))
              }
              (Sized::Bytes(mut b), Item::Int(i)) => {
                  b.push(i as u8);
                  Ok(Sized::Bytes(b))
              }
              (Sized::Bytes(_), i) => Err(Error::expected("integer", i)),
              (Sized::String(mut s), Item::Char(c)) => Ok(Sized::String({
                  s.push(c);
                  s
              })),
              (Sized::String(_), i) => Err(Error::expected("char", i)),
          }
      }

      pub fn join(self, other: Sized) -> Result<Sized, Error> {
          Ok(match (self, other) {
              (Sized::Associative(a), Sized::List(l)) => Sized::Associative({
                  let mut a: assoc::Association = a.into();
                  let more = assoc::Association::try_from_iter(l.clone().inner().into_iter())?;
                  let am = a.make_mut();
                  am.extend(more.inner());
                  assoc::Associative::Assoc(a)
              }),
              (Sized::List(l), Sized::Associative(a)) => {
                  let a: assoc::Association = a.into();
                  let mut la = assoc::Association::try_from_iter(l.clone().inner().into_iter())?;
                  let lam = la.make_mut();
                  lam.extend(a.inner());
                  Sized::Associative(assoc::Associative::Assoc(la))
              }
              (Sized::Associative(a), Sized::Associative(b)) => Sized::Associative(a.join(b)),
              (Sized::List(mut a), Sized::List(b)) => {
                  let am = a.make_mut();
                  am.extend(b.inner());
                  Sized::List(a)
              }
              (Sized::Set(mut a), Sized::Set(b)) => {
                  let am = a.make_mut();
                  am.extend(b.inner());
                  Sized::Set(a)
              }
              (Sized::List(a), Sized::Set(mut b)) => {
                  let bm = b.make_mut();

                  bm.extend(
                      a.inner()
                          .into_iter()
                          .map(assoc::KeyItem::try_from)
                          .collect::<Result<Vec<assoc::KeyItem>, Error>>()?,
                  );
                  Sized::Set(b)
              }
              (Sized::Set(mut a), Sized::List(b)) => {
                  let am = a.make_mut();

                  am.extend(
                      b.inner()
                          .into_iter()
                          .map(assoc::KeyItem::try_from)
                          .collect::<Result<Vec<assoc::KeyItem>, Error>>()?,
                  );
                  Sized::Set(a)
              }
              (Sized::String(mut a), Sized::String(b)) => {
                  a.push_str(&b);
                  Sized::String(a)
              }
              (Sized::Bytes(mut a), Sized::Bytes(b)) => {
                  a.extend(b);
                  Sized::Bytes(a)
              }
              (s, other) => {
                  if s.is_empty() {
                      other
                  } else if other.is_empty() {
                      s
                  } else {
                      Err(Error::expected(
                          "joinable",
                          List::from(vec![Item::from(s), Item::from(other)]).into(),
                      ))?
                  }
              }
          })
      }

      pub fn contains(&self, other: &Item) -> bool {
          match (self, other) {
              (Sized::Associative(a), other) => {
                  assoc::KeyItem::try_from(other.clone()).map_or(false, |k| a.contains_key(&k))
              }
              (Sized::List(l), other) => l.contains(other),
              (Sized::Set(s), Item::Dispenser(Dispenser::Sized(Sized::Set(other)))) => {
                  other.is_subset(s)
              }
              (Sized::Set(s), Item::Receptacle(Receptacle::Sized(Sized::Set(other)))) => {
                  other.is_subset(s)
              }
              (Sized::Set(s), other) => {
                  assoc::KeyItem::try_from(other.clone()).map_or(false, |k| s.contains(&k))
              }
              (Sized::String(container), other) => match other {
                  Item::Char(c) => container.contains(*c),
                  i => {
                      let s = String::try_from(i.clone());
                      match s {
                          Ok(s) => container.contains(&s),
                          Err(_) => false,
                      }
                  }
              },
              _ => false,
          }
      }

      pub fn empty(&self) -> Sized {
          match self {
              Sized::Associative(_) => {
                  Sized::Associative(assoc::Associative::Assoc(assoc::Association::new()))
              }
              Sized::List(_) => Sized::List(List::default()),
              Sized::Set(_) => Sized::Set(Set::default()),
              Sized::String(_) => Sized::String(String::new()),
              Sized::Bytes(_) => Sized::Bytes(vec![]),
          }
      }
  }

  impl Receptacle {
      pub fn put(self, i: Item) -> Future<Result<Receptacle, Error>> {
          match self {
              Receptacle::Sized(s) => Box::pin(future::ready(s.put(i).map(Receptacle::Sized))),
              Receptacle::In(mut p) => Box::pin(p.put(i).map(|r| r.map(|_| Receptacle::In(p)))),
              Receptacle::Tunnel(mut t) => {
                  let p = t.put(i);
                  Box::pin(p.map(|r| r.map(|_| Receptacle::Tunnel(t))))
              }
          }
      }
  }

  impl IntoIterator for Sized {
      type Item = Item;
      type IntoIter = Box<dyn Iterator<Item = Item>>;

      fn into_iter(self) -> Self::IntoIter {
          match self {
              Sized::Associative(map) => Box::new(map.into_iter().map(|kv| kv.into())),
              Sized::List(list) => Box::new(list.inner().into_iter()),
              Sized::String(s) => {
                  let chars: Vec<char> = s.chars().collect();
                  Box::new(chars.into_iter().map(|c| c.into()))
              }
              Sized::Bytes(b) => {
                  let vec: Vec<Item> = b.into_iter().map(|byte| Item::from(byte as Int)).collect();
                  Box::new(vec.into_iter())
              }
              Sized::Set(s) => Box::new(s.inner().into_iter().map(|i| i.into())),
          }
      }
  }

  impl TryFrom<Dispenser> for Sized {
      type Error = Error;

      fn try_from(c: Dispenser) -> Result<Self, Self::Error> {
          //println!("from iterable {:?}", c);
          match c {
              Dispenser::Sized(s) => Ok(s),
              i => Err(Error::expected("sized", i.into())),
          }
      }
  }

  impl TryFrom<Receptacle> for Sized {
      type Error = Error;

      fn try_from(c: Receptacle) -> Result<Self, Self::Error> {
          match c {
              Receptacle::Sized(s) => Ok(s),
              i => Err(Error::expected("sized", Item::Receptacle(i))),
          }
      }
  }

  impl TryFrom<Sized> for List {
      type Error = Error;

      fn try_from(s: Sized) -> Result<Self, Self::Error> {
          match s {
              Sized::List(l) => Ok(l),
              Sized::Associative(a) => Ok(List::from_iter(a.into_iter().map(Item::from))),
              i => Err(Error::expected("list", i.into())),
          }
      }
  }

  impl From<VecDeque<Item>> for List {
      fn from(v: VecDeque<Item>) -> Self {
          List::from_iter(v)
      }
  }

  impl From<Vec<Item>> for List {
      fn from(v: Vec<Item>) -> Self {
          List::from_iter(v)
      }
  }

  impl TryFrom<Item> for List {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Dispenser(l) => Sized::try_from(l).and_then(List::try_from),
              Item::Receptacle(l) => Sized::try_from(l).and_then(List::try_from),
              i => Err(Error::expected("list", i)),
          }
      }
  }

  impl TryFrom<Item> for Sized {
      type Error = Error;

      fn try_from(item: Item) -> Result<Self, Self::Error> {
          match item {
              Item::Dispenser(c) => c.try_into(),
              Item::Receptacle(p) => Dispenser::try_from(p)?.try_into(),
              i => {
                  // let bt = backtrace::Backtrace::new();
                  // println!("try from item {:?},\n {:?}", i, bt);
                  Err(Error::expected("sized", i))
              }
          }
      }
  }

  impl TryFrom<Item> for Receptacle {
      type Error = Error;

      fn try_from(item: Item) -> Result<Self, Self::Error> {
          match item {
              Item::Receptacle(p) => Ok(p),
              Item::Dispenser(c) => c.try_into(),
              i => Err(Error::expected("packable", i)),
          }
      }
  }

  impl TryFrom<Dispenser> for Receptacle {
      type Error = Error;

      fn try_from(c: Dispenser) -> Result<Self, Self::Error> {
          match c {
              Dispenser::Sized(s) => Ok(Receptacle::Sized(s)),
              Dispenser::Tunnel(t) => Ok(Receptacle::Tunnel(t)),
              i => Err(Error::expected("packable", i.into())),
          }
      }
  }

  impl TryFrom<Receptacle> for Dispenser {
      type Error = Error;

      fn try_from(c: Receptacle) -> Result<Self, Self::Error> {
          match c {
              Receptacle::Sized(s) => Ok(Dispenser::Sized(s)),
              Receptacle::Tunnel(t) => Ok(Dispenser::Tunnel(t)),
              i => Err(Error::expected("iterable", Item::Receptacle(i))),
          }
      }
  }

  impl TryFrom<Item> for Box<dyn Iterator<Item = Item>> {
      type Error = Error;

      fn try_from(item: Item) -> Result<Self, Self::Error> {
          Ok(Sized::try_from(item)?.into_iter())
      }
  }

  impl From<Sized> for Box<dyn Iterator<Item = Item>> {
      fn from(sized: Sized) -> Self {
          Box::new(sized.into_iter())
      }
  }

  impl From<List> for Sized {
      fn from(l: List) -> Self {
          Sized::List(l)
      }
  }

  impl From<Sized> for Dispenser {
      fn from(s: Sized) -> Self {
          Dispenser::Sized(s)
      }
  }

  impl From<List> for Item {
      fn from(l: List) -> Self {
          Item::Dispenser(Dispenser::Sized(Sized::List(l)))
      }
  }

  impl From<Set> for Item {
      fn from(l: Set) -> Self {
          Item::Dispenser(Dispenser::Sized(Sized::Set(l)))
      }
  }

  impl From<Dispenser> for Item {
      fn from(c: Dispenser) -> Self {
          Item::Dispenser(c)
      }
  }

  impl From<Sized> for Item {
      fn from(s: Sized) -> Self {
          Dispenser::Sized(s).into()
      }
  }

  impl TryFrom<Item> for Dispenser {
      type Error = Error;

      fn try_from(item: Item) -> Result<Self, Self::Error> {
          match item {
              Item::Dispenser(c) => Ok(c),
              Item::Receptacle(p) => Ok(Dispenser::try_from(p)?),
              i => Err(Error::expected("iterable", i)),
          }
      }
  }

  impl TryFrom<Item> for Set {
      type Error = Error;

      fn try_from(item: Item) -> Result<Self, Self::Error> {
          let s = Sized::try_from(item)?;
          let hs: HashSet<assoc::KeyItem> = s
              .into_iter()
              .map(|i| i.try_into())
              .collect::<Result<HashSet<assoc::KeyItem>, Error>>()?;
          Ok(Set::from(hs))
      }
  }

  impl Default for List {
      fn default() -> Self {
          Newtype(sync::Arc::new(Newtype(VecDeque::new())))
      }
  }

  impl Default for Set {
      fn default() -> Self {
          Set::from(HashSet::new())
      }
  }

  impl Default for Sized {
      fn default() -> Self {
          Sized::List(List::default())
      }
  }

  impl Default for Dispenser {
      fn default() -> Self {
          Dispenser::Sized(Sized::default())
      }
  }

  impl Default for Receptacle {
      fn default() -> Self {
          Receptacle::Sized(Sized::default())
      }
  }

  mod serde {
      use super::{Dispenser, Receptacle, Sized};
      use crate::serialize::Display;
      use crate::types::associative as assoc;
      use serde::ser::{Serialize, SerializeMap, SerializeSeq};

      impl Serialize for Dispenser {
          fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
          where
              S: serde::Serializer,
          {
              match self {
                  Dispenser::Out(o) => o.representation().serialize(serializer),
                  Dispenser::Tunnel(t) => t.representation().serialize(serializer),
                  Dispenser::Sized(s) => s.serialize(serializer),
              }
          }
      }

      impl Serialize for Receptacle {
          fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
          where
              S: serde::Serializer,
          {
              match self {
                  Receptacle::In(i) => i.representation().serialize(serializer),
                  Receptacle::Tunnel(t) => t.representation().serialize(serializer),
                  Receptacle::Sized(s) => s.serialize(serializer),
              }
          }
      }

      impl Serialize for Sized {
          fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
          where
              S: serde::Serializer,
          {
              match self {
                  Sized::Associative(a) => {
                      // Start serializing a map
                      let assoc = assoc::Association::from(a.clone());
                      let mut map = serializer.serialize_map(Some(assoc.len()))?;
                      for (key, value) in assoc.inner() {
                          // Serialize each entry in the map
                          map.serialize_entry(&key, &value)?;
                      }
                      // Finish serializing the map
                      map.end()
                  }

                  Sized::List(ref l) => {
                      // Serialize a list (sequence)
                      let mut seq = serializer.serialize_seq(Some(l.len()))?;
                      for element in l.inner() {
                          seq.serialize_element(&element)?;
                      }
                      seq.end()
                  }
                  Sized::Bytes(b) => serializer.serialize_bytes(b.as_slice()),
                  Sized::Set(s) => {
                      // Serialize a list (sequence)
                      let mut seq = serializer.serialize_seq(Some(s.len()))?;
                      for element in s.inner() {
                          seq.serialize_element(&element)?;
                      }
                      seq.end()
                  }
                  Sized::String(s) => serializer.serialize_str(s.as_str()),
              }
          }
      }
  }
#+end_src
**** Associative types
#+begin_src rust :tangle src/types/associative.rs :mkdirp yes
  use crate::types::collection as coll;
  use crate::types::dictionary as dict;
  use crate::types::environment as env;
  use crate::types::*;
  use std::iter::FromIterator;
  use std::sync;
  pub type Associationy<K, V> = Newtype<HashMap<K, V>>;
  pub type AssociationContent = Associationy<KeyItem, Item>;
  pub type Association = coll::Arc<AssociationContent>;

  #[derive(Debug, Clone, Eq, PartialEq, Hash, PartialOrd, Ord)]
  pub enum KeyItem {
      // Order matters here, for comparison purposes - changing the
      // order will change the result of how eg int compares to word.
      Int(Int),
      Char(Char),
      Word(Word),
      Bytes(Bytes),
      String(String),
      List(KeyList),
  }

  impl KeyList {
      pub fn try_from_iter<I>(l: I) -> Result<Self, Error>
      where
          I: IntoIterator<Item = Item>,
      {
          Ok(coll::Arc::wrap(Newtype(
              l.into_iter()
                  .map(KeyItem::try_from)
                  .collect::<Result<VecDeque<KeyItem>, Error>>()?,
          )))
      }
  }

  impl From<KeyItem> for Item {
      fn from(i: KeyItem) -> Self {
          match i {
              KeyItem::Int(i) => Item::Int(i),
              KeyItem::String(i) => i.into(),
              KeyItem::List(l) => coll::List::from_iter(l.inner().into_iter().map(Item::from)).into(),
              KeyItem::Word(w) => Item::Word(w),
              KeyItem::Bytes(bs) => bs.into(),
              KeyItem::Char(c) => Item::Char(c),
          }
      }
  }

  impl From<&str> for KeyItem {
      fn from(i: &str) -> Self {
          KeyItem::Word(Word::from(i))
      }
  }

  impl From<Word> for KeyItem {
      fn from(i: Word) -> Self {
          KeyItem::Word(i)
      }
  }

  impl TryFrom<Item> for KeyItem {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Error> {
          match i {
              Item::Int(i) => Ok(KeyItem::Int(i)),
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(i))) => {
                  Ok(KeyItem::String(i))
              }
              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::String(i))) => {
                  Ok(KeyItem::String(i))
              }
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(i))) => Ok(KeyItem::Bytes(i)),
              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(i))) => {
                  Ok(KeyItem::Bytes(i))
              }
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(l))) => Ok(KeyItem::List(
                  KeyList::try_from_iter(l.inner().into_iter())?,
              )),
              Item::Word(w) => Ok(KeyItem::Word(w)),
              Item::Char(c) => Ok(KeyItem::Char(c)),

              i => Err(Error::expected("KeyItem", i)),
          }
      }
  }

  impl TryFrom<KeyItem> for Word {
      type Error = Error;
      fn try_from(k: KeyItem) -> Result<Self, Self::Error> {
          match k {
              KeyItem::Word(w) => Ok(w),
              i => Err(Error::expected("word", i.into())),
          }
      }
  }

  pub type Entry = (KeyItem, Item);

  pub type KeyListContent = coll::Listy<KeyItem>;
  pub type KeyList = coll::Arc<KeyListContent>;

  #[derive(Debug, Clone)]
  pub enum Associative {
      Assoc(Association),
      DictEntry(dict::Entry),
      Env(env::Environment),
      Error(Error),
      Dictionary(dict::Dictionary),
      Nothing,
  }

  impl PartialEq for Associative {
      fn eq(&self, other: &Self) -> bool {
          match (self, other) {
              (Associative::Assoc(a), Associative::Assoc(b)) => a == b,
              (Associative::DictEntry(a), Associative::DictEntry(b)) => a == b,
              (Associative::Env(a), Associative::Env(b)) => a == b,
              (Associative::Error(a), Associative::Error(b)) => a == b,
              (Associative::Dictionary(a), Associative::Dictionary(b)) => a == b,
              (Associative::Nothing, Associative::Nothing) => true,
              //(Associative::Assoc(a), b) => Association::from(a) == Association::from(b),
              //(a, Associative::Assoc(b)) => Association::from(a) == Association::from(b),
              _ => false,
          }
      }
  }

  impl Associative {
      pub fn len(&self) -> usize {
          match self {
              Associative::Assoc(a) => a.len(),
              Associative::DictEntry(a) => a.len(),
              Associative::Env(e) => e.len(),
              Associative::Error(e) => e.len(),
              Associative::Dictionary(d) => d.len(),
              Associative::Nothing => 0,
          }
      }

      pub fn is_empty(&self) -> bool {
          self.len() == 0
      }

      pub fn insert(self, k: KeyItem, v: Item) -> (Associative, Option<Item>) {
          match self {
              Associative::Assoc(mut a) => {
                  let am = coll::Arc::make_mut(&mut a);
                  let e = am.insert(k, v);
                  (Associative::Assoc(a), e)
              }
              Associative::Dictionary(mut d) => match (k, v) {
                  (KeyItem::Word(w), e) => {
                      let e2 = e.clone();
                      if let Ok(e) = dict::Entry::try_from(e) {
                          let dm = coll::Arc::make_mut(&mut d);
                          let e = dm.insert(w, e).map(Item::from);
                          (Associative::Dictionary(d), e)
                      } else {
                          // TODO silently failing to insert here is bad
                          println!("Warning, failed to insert into dictionary: {:?}", e2);
                          (Associative::Dictionary(d), None)
                      }
                  }
                  _ => (Associative::Dictionary(d), None),
              },
              Associative::Env(e) => e.insert(k, v),
              _ => todo!("insert Implementations for error, env etc"),
          }
      }

      pub fn put(self, other: Item) -> Result<Associative, Error> {
          let entry: (KeyItem, Item) = other.try_into()?;
          Ok(self.insert(entry.0, entry.1).0)
      }

      pub fn join(self, other: Associative) -> Associative {
          match (self, other) {
              // same type means 2nd one wins.
              //TODO: a little more complex for types that can be extended
              (Associative::DictEntry(_), Associative::DictEntry(other)) => {
                  Associative::DictEntry(other)
              }
              (Associative::Dictionary(mut this), Associative::Dictionary(other)) => {
                  let thism = coll::Arc::make_mut(&mut this);
                  thism.extend(other.inner());
                  Associative::Dictionary(this)
              }
              (Associative::Error(_), Associative::Error(other)) => Associative::Error(other),
              (Associative::Env(_), Associative::Env(other)) => Associative::Env(other),
              (Associative::Nothing, Associative::Nothing) => Associative::Nothing,
              (Associative::Assoc(mut this), other) => {
                  let thism = coll::Arc::make_mut(&mut this);
                  thism.extend(other);
                  Associative::Assoc(this)
              }
              (this, other) => {
                  let thisa: Association = this.into();
                  (Associative::Assoc(thisa)).join(other)
              }
          }
      }

      pub fn get(&self, k: &KeyItem) -> Option<Item> {
          match self {
              Associative::Assoc(a) => a.get(k).cloned(),
              Associative::Error(e) => e.data.get(k).cloned(),
              Associative::Env(e) => match k {
                  KeyItem::Word(s) => e.get(s.as_str()),
                  _ => None,
              },
              Associative::DictEntry(d) => match k {
                  KeyItem::Word(s) => d.get(s.as_str()),
                  _ => None,
              },
              Associative::Dictionary(d) => match k {
                  KeyItem::Word(w) => d.get(w).map(|x| x.clone().into()),
                  _ => None,
              },
              &Associative::Nothing => None,
          }
      }

      pub fn contains_key(&self, k: &KeyItem) -> bool {
          match self {
              Associative::Assoc(a) => a.contains_key(k),
              Associative::Error(e) => e.data.contains_key(k),
              Associative::Env(e) => e.contains_key(k),
              Associative::DictEntry(d) => d.contains_key(k),
              Associative::Dictionary(d) => match k {
                  KeyItem::Word(w) => d.contains_key(w),
                  _ => false,
              },
              &Associative::Nothing => false,
          }
      }

      //TODO remove
      pub fn remove(self, k: &KeyItem) -> (Associative, Option<Item>) {
          match self {
              Associative::Assoc(mut a) => {
                  let am = coll::Arc::make_mut(&mut a);
                  let v = am.remove(k);
                  (Associative::Assoc(a), v)
              }
              Associative::Dictionary(mut d) => {
                  let dm = coll::Arc::make_mut(&mut d);
                  let v = dm.remove(&Word::try_from(k.clone()).unwrap_or_default());
                  (Associative::Dictionary(d), v.map(|v| v.into()))
              }
              _ => todo!("Removing from other associative types"),
          }
      }

      pub fn take(self) -> (Self, Option<Item>) {
          match self {
              Associative::Assoc(mut a) => {
                  let maybe_key = a.inner().keys().next().cloned();
                  let am = a.make_mut();
                  let maybe_value = maybe_key.as_ref().and_then(|key| am.remove(key));
                  (
                      Associative::Assoc(a),
                      maybe_key.map(|key| {
                          coll::List::from_iter(vec![
                              Item::from(key),
                              maybe_value.unwrap_or_default(),
                          ])
                          .into()
                      }),
                  )
              }
              Associative::Dictionary(mut d) => {
                  let maybe_key = d.inner().keys().next().cloned();
                  let dm = d.make_mut();
                  let maybe_value = maybe_key.and_then(|key| dm.remove(&key));
                  (
                      Associative::Dictionary(d),
                      maybe_key.map(|key| {
                          coll::List::from_iter(vec![
                              Item::Word(key),
                              maybe_value.map(Item::from).unwrap_or(Item::default()),
                          ])
                          .into()
                      }),
                  )
              }
              _ => todo!("taking from assoc Requires insert/remove impl"),
          }
      }
  }

  impl IntoIterator for Associative {
      type Item = Entry;
      type IntoIter = Box<dyn Iterator<Item = Entry>>;

      fn into_iter<'a>(self) -> Self::IntoIter {
          match self {
              Associative::Assoc(a) => Box::new(a.inner().into_iter()),
              Associative::DictEntry(e) => Box::new(e.into_iter()),
              Associative::Dictionary(d) => {
                  Box::new(d.inner().into_iter().map(|(k, v)| (k.into(), v.into())))
              }
              Associative::Error(e) => e.into_iter(),
              Associative::Env(e) => e.into_iter(),
              Associative::Nothing => Box::new(std::iter::empty()),
          }
      }
  }

  impl From<Associative> for coll::List {
      fn from(a: Associative) -> Self {
          coll::List::from_iter(a)
      }
  }

  impl TryFrom<coll::Sized> for Associative {
      type Error = Error;
      fn try_from(s: coll::Sized) -> Result<Self, Error> {
          match s {
              coll::Sized::Associative(a) => Ok(a),
              coll::Sized::String(i) => Err(Error::expected("associative", i.into())),
              coll::Sized::Bytes(i) => Err(Error::expected("associative", i.into())),
              s => Ok(Associative::Assoc(Association::try_from_iter(s)?)),
          }
      }
  }

  impl TryFrom<Item> for Associative {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Error> {
          let s = coll::Sized::try_from(i)?;
          Associative::try_from(s)
      }
  }

  // Convert anything that can be iterated over as Items, to an
  // Association. The items must be pairs that are
  // convertable to Entry, otherwise it will return an error.
  impl Association {
      pub fn new() -> Association {
          coll::Arc::wrap(Newtype(HashMap::new()))
      }

      pub fn try_from_iter<I>(l: I) -> Result<Self, Error>
      where
          I: IntoIterator<Item = Item>,
      {
          Ok(coll::Arc::wrap(Newtype(
              l.into_iter()
                  .map(|i| Entry::try_from(i.clone()))
                  .collect::<Result<HashMap<KeyItem, Item>, Error>>()?,
          )))
      }
  }

  impl From<HashMap<KeyItem, Item>> for Association {
      fn from(h: HashMap<KeyItem, Item>) -> Self {
          coll::Arc::wrap(Newtype(h))
      }
  }

  impl FromIterator<Entry> for Association {
      fn from_iter<I>(iter: I) -> Self
      where
          I: IntoIterator<Item = Entry>,
      {
          coll::Arc::wrap(Newtype(
              iter.into_iter().collect::<HashMap<KeyItem, Item>>(),
          ))
      }
  }

  impl FromIterator<Entry> for coll::List {
      fn from_iter<I>(iter: I) -> Self
      where
          I: IntoIterator<Item = Entry>,
      {
          coll::Arc::wrap(Newtype(
              iter.into_iter()
                  .map(|e| e.into())
                  .collect::<VecDeque<Item>>(),
          ))
      }
  }

  impl FromIterator<KeyItem> for KeyList {
      fn from_iter<I>(iter: I) -> Self
      where
          I: IntoIterator<Item = KeyItem>,
      {
          Newtype(sync::Arc::new(Newtype(
              iter.into_iter().collect::<VecDeque<KeyItem>>(),
          )))
      }
  }

  impl From<Entry> for Item {
      fn from(e: Entry) -> Item {
          coll::List::from_iter([Item::from(e.0), e.1]).into()
      }
  }

  impl TryFrom<Item> for Entry {
      type Error = Error;

      fn try_from(i: Item) -> Result<Self, Error> {
          let s = coll::Sized::try_from(i)?;
          if s.len() != 2 {
              Err(Error::expected("pair", s.into()))
          } else {
              let mut iter = s.into_iter();
              let key: KeyItem = iter.next().unwrap().try_into()?;
              let value = iter.next().unwrap();
              Ok((key, value))
          }
      }
  }

  impl From<Associative> for Association {
      fn from(a: Associative) -> Association {
          match a {
              Associative::Assoc(a) => a,
              a => a.into_iter().collect::<Association>(),
          }
      }
  }

  impl From<AssociationContent> for Item {
      fn from(a: AssociationContent) -> Item {
          coll::Arc::wrap(a).into()
      }
  }

  impl From<Association> for Item {
      fn from(a: Association) -> Item {
          Associative::Assoc(a).into()
      }
  }

  impl From<Associative> for Item {
      fn from(a: Associative) -> Item {
          coll::Sized::Associative(a).into()
      }
  }

  mod serde {
      use super::{KeyItem, KeyList};
      use serde::de::{self, Deserialize, Deserializer, Visitor};
      use serde::ser::{Serialize, SerializeSeq};
      use std::fmt;

      struct KeyItemVisitor;

      impl<'de> Visitor<'de> for KeyItemVisitor {
          type Value = KeyItem;

          fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
              formatter.write_str("expected a specific representation for Item")
          }

          fn visit_i64<E>(self, value: i64) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(KeyItem::Int(value))
          }

          fn visit_u64<E>(self, value: u64) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(KeyItem::Int(value as i64))
          }

          fn visit_str<E>(self, v: &str) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(KeyItem::String(v.to_string()))
          }

          fn visit_byte_buf<E>(self, v: Vec<u8>) -> Result<Self::Value, E>
          where
              E: de::Error,
          {
              Ok(KeyItem::Bytes(v))
          }

          fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>
          where
              A: de::SeqAccess<'de>,
          {
              let mut items: Vec<KeyItem> = Vec::new();
              while let Some(item) = seq.next_element::<KeyItem>()? {
                  items.push(item);
              }
              Ok(KeyItem::List(KeyList::from_iter(items)))
          }
      }

      impl<'de> Deserialize<'de> for KeyItem {
          fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
          where
              D: Deserializer<'de>,
          {
              deserializer.deserialize_any(KeyItemVisitor)
          }
      }

      impl Serialize for KeyItem {
          fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
          where
              S: serde::Serializer,
          {
              match self {
                  KeyItem::Int(i) => serializer.serialize_i64(*i),
                  KeyItem::Word(w) => serializer.serialize_str(w.as_str()),
                  KeyItem::Char(c) => serializer.serialize_char(*c),
                  KeyItem::Bytes(b) => serializer.serialize_bytes(b.as_slice()),
                  KeyItem::List(ref l) => {
                      // Serialize a list (sequence)
                      let mut seq = serializer.serialize_seq(Some(l.len()))?;
                      for element in l.inner() {
                          seq.serialize_element(&element)?;
                      }
                      seq.end()
                  }
                  KeyItem::String(s) => serializer.serialize_str(s.as_str()),
              }
          }
      }
  }
#+end_src
**** Error types
#+begin_src rust :tangle src/types/error.rs :mkdirp yes
  use crate::types;
  use crate::types::associative as assoc;
  use crate::types::collection as coll;
  use crate::types::{Int, Item, Word};

  #[derive(Clone, PartialEq)]
  pub struct Error {
      pub data: assoc::Association,
      pub is_handled: bool,
  }

  impl Error {
      pub fn create(asked: coll::List, reason: &str, actual: Option<Item>) -> Error {
          // let bt = backtrace::Backtrace::new();
          let mut data: Vec<(assoc::KeyItem, Item)> = vec![
              ("type".into(), "error".into()),
              ("asked".into(), asked.into()),
              ("reason".into(), reason.to_string().into()),
              //("backtrace".into(), Item::String(format!("{:?}", bt))),
          ];
          if let Some(actual) = actual {
              data.push(("actual".into(), actual));
          }
          Error {
              is_handled: false,

              data: assoc::Association::from_iter(data),
          }
      }

      pub fn stack_underflow() -> Error {
          Error::create(
              types::wrap("consume".into()),
              "not enough items on stack",
              None,
          )
      }

      pub fn overflow() -> Error {
          Error::create(types::wrap("arithmetic".into()), "number overflow", None)
      }

      pub fn undefined(w: Word) -> Error {
          Error::create(types::wrap(Item::Word(w)), "word is not defined", None)
      }

      pub fn type_mismatch(asked: coll::List, actual: Option<Item>) -> Error {
          Error::create(asked, "type mismatch", actual)
      }

      pub fn division_by_zero() -> Error {
          Error::create(types::wrap("/".into()), "division by zero", None)
      }

      pub fn expected(typestr: &str, actual: Item) -> Error {
          Error::type_mismatch(types::wrap(typestr.into()), Some(actual))
      }

      pub fn short_list(expected: Int) -> Error {
          Error::create(
              coll::List::from_iter(["count".into(), Item::Int(expected), ">=".into()]),
              "list had too few items",
              None,
          )
      }

      pub fn list_count(expected: Int) -> Error {
          Error::create(
              coll::List::from_iter(["count".into(), Item::Int(expected), "=".into()]),
              "list had wrong number of items",
              None,
          )
      }

      pub fn negative(actual: Int) -> Error {
          Error::too_small(actual, 0)
      }

      pub fn too_small(actual: Int, expected: Int) -> Error {
          Error::create(
              coll::List::from_iter([Item::Int(expected), Item::from(">=")]),
              "number too small",
              Some(Item::Int(actual)),
          )
      }

      pub fn too_large(actual: Int, expected: Int) -> Error {
          Error::create(
              coll::List::from_iter([Item::Int(expected), Item::from("<=")]),
              "number too large",
              Some(Item::Int(actual)),
          )
      }

      pub fn parse(reason: &str) -> Error {
          Error::create(types::wrap("read".into()), reason, None)
      }

      pub fn test_assertion(program: coll::List, expected: coll::List, actual: coll::List) -> Error {
          let mut e = Error::create(program, "assertion failed", Some(actual.into()));
          let d = e.data.make_mut();
          d.insert("expected-program".into(), expected.into());
          e
      }

      pub fn len(&self) -> usize {
          self.data.len()
      }
  }

  impl From<Error> for assoc::Association {
      fn from(e: Error) -> assoc::Association {
          e.data
      }
  }

  impl TryFrom<Item> for Error {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
                  assoc::Associative::Error(e),
              ))) => Ok(e),
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(_)))
              | Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::String(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(_))) => {
                  Err(Error::expected("error", Default::default()))
              }
              Item::Dispenser(coll::Dispenser::Sized(c)) => c.into_iter().try_into(),
              i => Err(Error::expected("error", i)),
          }
      }
  }

  impl TryFrom<Box<dyn Iterator<Item = Item>>> for Error {
      type Error = Error;
      fn try_from(i: Box<dyn Iterator<Item = Item>>) -> Result<Self, Self::Error> {
          //TODO: this can't fail, can just be a From.
          // Really though, Error should have predefined fields like Environment.
          let data = assoc::Association::try_from_iter(i)?;
          Ok(Error {
              data,
              is_handled: false,
          })
      }
  }

  impl TryFrom<assoc::Associative> for Error {
      type Error = Error;
      fn try_from(a: assoc::Associative) -> Result<Self, Self::Error> {
          match a {
              assoc::Associative::Error(e) => Ok(e),
              assoc::Associative::Assoc(a) => {
                  if a.get(&assoc::KeyItem::from("type")) != Some(&Item::from("error")) {
                      Err(Error::expected("error", a.into()))
                  } else {
                      Ok(Error {
                          data: a.clone(),
                          is_handled: true,
                      })
                  }
              }
              i => Err(Error::expected("error", i.into())),
          }
      }
  }

  impl From<Error> for Item {
      fn from(e: Error) -> Item {
          assoc::Associative::Error(e).into()
      }
  }

  impl IntoIterator for Error {
      type Item = assoc::Entry;
      type IntoIter = Box<dyn Iterator<Item = assoc::Entry>>;

      fn into_iter(self) -> Self::IntoIter {
          Box::new(
              self.data
                  .inner()
                  .into_iter()
                  .chain(std::iter::once(("handled".into(), self.is_handled.into()))),
          )
      }
  }
#+end_src
**** Dictionary types
#+begin_src rust :tangle src/types/dictionary.rs :mkdirp yes
  use crate::types::associative as assoc;
  use crate::types::collection as coll;
  use crate::types::*;

  #[derive(Debug, Clone)]
  pub struct Entry {
      pub examples: Option<coll::List>,
      pub spec: Option<coll::List>,
      pub definition: Definition,
  }

  impl Entry {
      pub fn len(&self) -> usize {
          3 // 3 fields
      }

      pub fn get(&self, key: &str) -> Option<Item> {
          match key {
              "spec" => self.spec.clone().map(|x| x.into()),
              "examples" => self.examples.clone().map(|x| x.into()),
              "definition" => Some(match self.definition.clone() {
                  dict::Definition::Axiom(_) => "builtin".into(),
                  dict::Definition::Derived(d) => d.into(),
              }),
              _ => None,
          }
      }

      pub fn contains_key(&self, key: &assoc::KeyItem) -> bool {
          Word::try_from(key.clone()).map_or(false, |w| {
              matches!(w.as_str(), "examples" | "spec" | "definition")
          })
      }
  }

  pub type Dictionary = coll::Arc<HashMap<Word, Entry>>;

  #[derive(Clone)]
  pub enum Definition {
      Axiom(&'static StepFn),
      Derived(coll::List),
  }

  impl PartialEq for Definition {
      fn eq(&self, _: &Self) -> bool {
          // TODO actually implement this
          true
      }
  }

  // dictionary entries are equal if they have the same function reference,
  // no need to compare the function values
  impl PartialEq for Entry {
      fn eq(&self, other: &Self) -> bool {
          self.definition == other.definition
              && self.examples == other.examples
              && self.spec == other.spec
      }
  }

  impl fmt::Debug for Definition {
      fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
          match self {
              Definition::Axiom(_) => f.write_str("Builtin"),
              Definition::Derived(d) => {
                  let mut ds = f.debug_list();
                  ds.entries(d.iter());
                  ds.finish()
              }
          }
      }
  }

  impl IntoIterator for Entry {
      type Item = assoc::Entry;
      type IntoIter = Box<dyn Iterator<Item = assoc::Entry>>;

      fn into_iter(self) -> Self::IntoIter {
          let mut v: Vec<(assoc::KeyItem, Item)> = vec![("definition".into(), {
              match self.definition {
                  dict::Definition::Derived(l) => l.into(),
                  dict::Definition::Axiom(_) => "builtin-function".into(),
              }
          })];
          if let Some(e) = self.examples {
              v.push(("examples".into(), e.into()));
          }
          if let Some(s) = self.spec {
              v.push(("spec".into(), s.into()))
          }
          Box::new(v.into_iter())
      }
  }

  impl TryFrom<Box<dyn Iterator<Item = Item>>> for Entry {
      type Error = Error;
      fn try_from(iter: Box<dyn Iterator<Item = Item>>) -> Result<Self, Error> {
          let mut examples: Option<coll::List> = None;
          let mut definition: Option<Definition> = None;
          let mut spec: Option<coll::List> = None;
          for i in iter {
              let (k, v): (assoc::KeyItem, Item) = i.try_into()?;
              //println!("k: {:?}, v: {:?}", k, v);
              if k == "examples".into() {
                  examples = Some(v.try_into()?);
              } else if k == "definition".into() {
                  definition = Some(v.try_into()?);
              } else if k == "spec".into() {
                  spec = Some(v.try_into()?);
              } else {
                  continue;
              }
          }
          Ok(Entry {
              examples,
              definition: definition.unwrap_or(Definition::Derived(coll::List::default())),
              spec,
          })
      }
  }

  impl TryFrom<Box<dyn Iterator<Item = Item>>> for Dictionary {
      type Error = Error;

      fn try_from(iter: Box<dyn Iterator<Item = Item>>) -> Result<Self, Error> {
          iter.map(<(Word, Entry)>::try_from)
              .collect::<Result<HashMap<Word, Entry>, Error>>()
              .map(coll::Arc::wrap)
      }
  }

  impl TryFrom<Item> for Definition {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          coll::List::try_from(i).map(Definition::Derived)
      }
  }

  impl TryFrom<Item> for Entry {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;
          match s {
              coll::Sized::Associative(assoc::Associative::DictEntry(d)) => Ok(d),
              c => c.into_iter().try_into(),
          }
      }
  }

  impl From<Entry> for assoc::Associative {
      fn from(d: Entry) -> assoc::Associative {
          let mut assoc = assoc::Association::new();
          let a = assoc.make_mut();
          d.examples
              .and_then(|l| a.insert("examples".into(), l.into()));
          d.spec.and_then(|l| a.insert("spec".into(), l.into()));

          if let Definition::Derived(d) = d.definition {
              a.insert("definition".into(), d.into());
          }

          assoc::Associative::Assoc(assoc)
      }
  }

  // impl TryFrom<Associative> for Entry {
  //     type Error = Error;
  //     fn try_from(d: Associative) -> Result<Self, Error> {
  //         // TODO: This should handle cases where there's no def present
  //         // and return error
  //         let (d, def) = d.remove(&"definition".into());
  //         let (d, examples) = d.remove(&"examples".into());
  //         let (_, spec) = d.remove(&"spec".into());

  //         Ok(Entry {
  //             definition: if let Some(d) = def {
  //                 Definition::Derived(List::try_from(d).unwrap())
  //             } else {
  //                 //Err(Error::expected("definition field"))?  use a
  //                 // dummy value, presumably if this is during
  //                 // bootstrap,the definition will be replaced later.
  //                 Definition::Derived(Arc::new(ListContent::new()))
  //             },

  //             // {Box::leak(Box::new(move |env: Environment| {
  //             //    env.push(Item::Error(Error::undefined(w)))
  //             //}))}
  //             examples: examples.and_then(|i| List::try_from(i).ok()),
  //             spec: spec.and_then(|i| List::try_from(i).ok()),
  //         })
  //     }
  // }

  // impl TryFrom<List> for Entry {
  //     type Error = Error;
  //     fn try_from(l: List) -> Result<Self, Error> {
  //         let a: Associative = l.try_into()?;
  //         a.try_into()
  //     }
  // }

  // impl TryFrom<assoc::Associative> for Dictionary {
  //     type Error = Error;
  //     fn try_from(a: assoc::Associative) -> Result<Self, Self::Error> {
  //         match a {
  //             assoc::Associative::Dictionary(e) => Ok(e),
  //             assoc::Associative::Assoc(a) => {
  //                 let h = rc_inner(&a)
  //                     .into_iter()
  //                     .map(|(k, v)| {
  //                         let e: (Word, Entry) = (k.try_into()?, v.try_into()?);
  //                         Ok(e)
  //                     })
  //                     .collect::<Result<HashMap<Word, Entry>, Error>>()?;
  //                 Ok(Arc::new(h))
  //             }
  //             _ => Err(Error::expected("dictionary")),
  //         }
  //     }
  // }

  // impl From<Dictionary> for assoc::Associative {
  //     fn from(d: Dictionary) -> Self {
  //         Associative::Assoc(Arc::new(
  //             rc_inner(&d)
  //                 .into_iter()
  //                 .map(|(k, v)| (assoc::KeyItem::Word(k), Item::Entry(v)))
  //                 .collect(),
  //         ))
  //     }
  // }

  impl TryFrom<Item> for Dictionary {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;
          match s {
              coll::Sized::Associative(assoc::Associative::Dictionary(d)) => Ok(d),
              c => c.into_iter().try_into(),
          }
      }
  }

  impl From<Entry> for Item {
      fn from(e: Entry) -> Self {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::DictEntry(e),
          )))
      }
  }

  impl From<Dictionary> for Item {
      fn from(d: Dictionary) -> Self {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Dictionary(d),
          )))
      }
  }

  impl From<(Word, Entry)> for Item {
      fn from((k, v): (Word, Entry)) -> Item {
          coll::List::from_iter([Item::Word(k), Item::from(v.clone())]).into()
      }
  }

  impl TryFrom<Item> for (Word, Entry) {
      type Error = Error;

      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;
          if s.len() != 2 {
              Err(Error::expected("pair", s.into()))
          } else {
              let mut iter = s.into_iter();
              let key: Word = iter.next().unwrap().try_into()?;
              let value: Entry = iter.next().unwrap().try_into()?;
              Ok((key, value))
          }
      }
  }
#+end_src
**** Environment types
#+begin_src rust :tangle src/types/environment.rs :mkdirp yes
  use crate::axiom;
  use crate::serialize;
  use crate::types::*;
  use crate::types::{associative as assoc, collection as coll, dictionary as dict};
  use std::future;

  #[derive(Clone, PartialEq)]
  pub struct Environment {
      pub stack: Stack,
      pub program: Stack,
      pub dictionary: dict::Dictionary,
  }

  impl Environment {
      pub fn push(mut self, i: Item) -> Environment {
          coll::Arc::make_mut(&mut self.stack).push_front(i);
          self
      }

      pub fn pop(&mut self) -> Item {
          coll::Arc::make_mut(&mut self.stack).pop_front().unwrap()
      }

      pub fn push_expr(mut self, i: Item) -> Environment {
          coll::Arc::make_mut(&mut self.program).push_front(i);
          self
      }

      pub fn pop_expr(&mut self) -> Item {
          coll::Arc::make_mut(&mut self.program).pop_front().unwrap()
      }

      pub fn append_program(mut self, mut items: coll::List) -> Environment {
          let expr = self.program.make_mut();
          let ct = expr.len();
          expr.append(items.make_mut());
          expr.rotate_left(ct);
          self
      }

      pub fn tos(&self) -> Option<&Item> {
          self.stack.front()
      }

      pub fn len(&self) -> usize {
          3 // 3 fields
      }

      pub fn get(&self, key: &str) -> Option<Item> {
          match key {
              "stack" => Some(self.stack.clone().into()),
              "program" => Some(self.program.clone().into()),
              "dictionary" => Some(self.dictionary.clone().into()),
              _ => None,
          }
      }

      pub fn contains_key(&self, key: &assoc::KeyItem) -> bool {
          Word::try_from(key.clone()).map_or(false, |w| {
              matches!(w.as_str(), "stack" | "program" | "dictionary")
          })
      }

      pub fn insert(mut self, k: assoc::KeyItem, v: Item) -> (assoc::Associative, Option<Item>) {
          match k {
              assoc::KeyItem::Word(w) => match w.as_str() {
                  "stack" => {
                      let l = coll::List::try_from(v.clone());
                      match l {
                          Ok(l) => {
                              let old = self.stack.clone();
                              self.stack = l;
                              (assoc::Associative::Env(self), Some(old.into()))
                          }
                          Err(_) => {
                              let a = assoc::Association::from_iter(self);
                              let old = a.inner().insert(k, v);
                              (assoc::Associative::Assoc(a), old)
                          }
                      }
                  }
                  "program" => {
                      let l = coll::List::try_from(v.clone());
                      match l {
                          Ok(l) => {
                              let old = self.program.clone();
                              self.program = l;
                              (assoc::Associative::Env(self), Some(old.into()))
                          }
                          Err(_) => {
                              let a = assoc::Association::from_iter(self);
                              let old = a.inner().insert(k, v);
                              (assoc::Associative::Assoc(a), old)
                          }
                      }
                  }
                  "dictionary" => {
                      let d = dict::Dictionary::try_from(v.clone());
                      match d {
                          Ok(d) => {
                              let old = self.dictionary.clone();
                              self.dictionary = d;
                              (assoc::Associative::Env(self), Some(old.into()))
                          }
                          Err(_) => {
                              let a = assoc::Association::from_iter(self);
                              let old = a.inner().insert(k, v);
                              (assoc::Associative::Assoc(a), old)
                          }
                      }
                  }
                  k => {
                      let a = assoc::Association::from_iter(self);
                      let old = a.inner().insert(k.into(), v);
                      (assoc::Associative::Assoc(a), old)
                  }
              },
              _ => {
                  let a = assoc::Association::from_iter(self);
                  let old = a.inner().insert(k, v);
                  (assoc::Associative::Assoc(a), old)
              }
          }
      }
  }

  impl TryFrom<Box<dyn Iterator<Item = Item>>> for Environment {
      type Error = Error;
      fn try_from(iter: Box<dyn Iterator<Item = Item>>) -> Result<Self, Error> {
          let mut stack: Option<coll::List> = None;
          let mut program: Option<coll::List> = None;
          let mut dictionary: Option<dict::Dictionary> = None;
          for i in iter {
              let (k, v): (assoc::KeyItem, Item) = i.try_into()?;
              if k == "stack".into() {
                  stack = Some(v.try_into()?)
              } else if k == "program".into() {
                  program = Some(v.try_into()?)
              } else if k == "dictionary".into() {
                  dictionary = Some(v.try_into()?)
              } else {
                  continue;
              }
          }
          let mut env = axiom::standard_env(program, stack);
          if let Some(d) = dictionary {
              let edmut = env.dictionary.make_mut();
              edmut.extend(d.inner());
          }
          Ok(env)
      }
  }
  impl TryFrom<Item> for Environment {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let s = coll::Sized::try_from(i)?;

          match s {
              coll::Sized::Associative(assoc::Associative::Env(e)) => Ok(e),
              l => l.into_iter().try_into(),
          }
      }
  }

  impl From<Environment> for Item {
      fn from(env: Environment) -> Item {
          assoc::Associative::Env(env).into()
      }
  }

  impl From<Environment> for Future<Environment> {
      fn from(env: Environment) -> Future<Environment> {
          Box::pin(future::ready(env))
      }
  }

  impl IntoIterator for Environment {
      type Item = assoc::Entry;
      type IntoIter = Box<dyn Iterator<Item = assoc::Entry>>;

      fn into_iter(self) -> Self::IntoIter {
          let v: Vec<(assoc::KeyItem, Item)> = vec![
              ("stack".into(), self.stack.into()),
              ("program".into(), self.program.into()),
              ("dictionary".into(), self.dictionary.into()),
          ];
          Box::new(v.into_iter())
      }
  }

  impl serialize::Display for Environment {
      fn representation(&self) -> Item {
          let mut assoc = assoc::Association::from_iter(self.clone());
          let am = assoc.make_mut();
          am.remove(&("dictionary".into()));
          assoc.into()
      }
  }
#+end_src
**** Cryptographic primitives
We'll implement certain cryptography functions in rust and make kcats
words for them (hashing, encryption, signing)
#+begin_src rust :tangle src/crypto.rs :mkdirp yes
  use crate::axiom::ItemResult;
  use crate::types::Int;
  use crate::types::{associative as assoc, error::Error, Bytes, Item};
  use core::ops::Deref;
  use ed25519_dalek as signing;
  use ed25519_dalek::{Signer, Verifier};
  use rand::rngs::OsRng; // Import OsRng
  use rand::RngCore as RandRngCore;
  use rand_core::{CryptoRng, RngCore};
  use sha2::{self, Digest}; // Import RngCore for the fill_bytes method

  pub fn hash(i: Item) -> ItemResult {
      let b = Bytes::try_from(i).unwrap();
      Ok(sha2::Sha256::digest(b).deref().to_vec().into())
  }

  type Value = Vec<u8>;

  pub struct SeededRNG {
      seed: Value,
      salt: Value,
  }

  impl SeededRNG {
      // Hash of seed|value
      fn hash(&self) -> Vec<u8> {
          let mut v = self.seed.clone();
          v.extend(self.salt.clone());
          sha2::Sha256::digest(v.as_slice()).deref().to_vec()
      }
  }

  impl RngCore for SeededRNG {
      fn next_u32(&mut self) -> u32 {
          rand_core::impls::next_u32_via_fill(self)
      }

      fn next_u64(&mut self) -> u64 {
          rand_core::impls::next_u64_via_fill(self)
      }

      fn fill_bytes(&mut self, dest: &mut [u8]) {
          let l = dest.len();
          dest.copy_from_slice(&self.hash()[..l]);
      }

      fn try_fill_bytes(&mut self, dest: &mut [u8]) -> Result<(), rand_core::Error> {
          self.fill_bytes(dest);
          Ok(())
      }
  }

  impl CryptoRng for SeededRNG {}

  pub fn key(seed: Item) -> ItemResult {
      let sbs: Bytes = seed.try_into()?;
      let kp = signing::Keypair::generate(&mut SeededRNG {
          seed: vec![],
          salt: sbs,
      });
      Ok(assoc::Association::from_iter([
          ("type".into(), "elliptic-curve-key".into()),
          ("secret".into(), kp.secret.as_ref().to_vec().into()),
          ("public".into(), kp.public.as_ref().to_vec().into()),
      ])
      .into())
  }

  impl TryFrom<Item> for signing::Keypair {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let sk: signing::SecretKey = i.try_into()?;
          let pk: signing::PublicKey = (&sk).into();
          Ok(signing::Keypair {
              secret: sk,
              public: pk,
          })
      }
  }

  impl TryFrom<Item> for signing::SecretKey {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let a = assoc::Associative::try_from(i)?;
          if a.get(&"type".into()) == Some("elliptic-curve-key".into()) {
              let sk = signing::SecretKey::from_bytes(
                  &Bytes::try_from(
                      a.get(&"secret".into())
                          .ok_or_else(|| Error::expected("secret", Default::default()))?,
                  )?[..],
              )
              .map_err(|_e| Error::expected("valid-secret-key", Default::default()))?;
              Ok(sk)
          } else {
              Err(Error::expected("keypair", a.clone().into()))
          }
      }
  }

  impl TryFrom<Item> for signing::PublicKey {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          let a = assoc::Associative::try_from(i)?;
          if a.get(&"type".into()) == Some("elliptic-curve-key".into()) {
              let pk = signing::PublicKey::from_bytes(
                  &Bytes::try_from(
                      a.get(&"public".into())
                          .ok_or_else(|| Error::expected("public", Default::default()))?,
                  )?[..],
              )
              .map_err(|_e| Error::expected("valid-public-key", Default::default()))?;
              Ok(pk)
          } else {
              Err(Error::expected("public-key", a.clone().into()))
          }
      }
  }
  //TODO: we can only call sign from a keypair, so we may want to assume
  // that we have either the kp, or just the secret key.
  pub fn sign(k: Item, m: Item) -> ItemResult {
      let kp: signing::Keypair = k.try_into()?;
      let message: Bytes = m.try_into()?;
      let signature: signing::Signature = kp.sign(&message);
      Ok(signature.as_ref().to_vec().into())
  }

  pub fn verify(k: Item, m: Item, s: Item) -> ItemResult {
      let mret = m.clone();
      let pk: signing::PublicKey = k.try_into()?;
      let mbs: Bytes = m.try_into()?;
      let sbs: Bytes = s.try_into()?;
      let sig = signing::Signature::from_bytes(&sbs)
          .map_err(|_e| Error::expected("signature", Default::default()))?;
      Ok(pk.verify(&mbs, &sig).map(|_| mret).unwrap_or_default())
  }

  fn random_bytes(n: usize) -> Vec<u8> {
      let mut bytes = vec![0u8; n]; // Create a vector of n zeros
      OsRng.fill_bytes(&mut bytes); // Fill the vector with random bytes
      bytes
  }

  pub fn random(n: Item) -> ItemResult {
      let n: Int = n.try_into()?;
      Ok(random_bytes(n as usize).into())
  }
#+end_src
*** Serialization
We'll define how kcats data structure are parsed and written (for
example, in order to read/write to/from disk).
#+begin_src rust :tangle src/serialize.rs :mkdirp yes
  extern crate edn_format;
  use crate::types::environment::Environment;
  use crate::types::{associative as assoc, collection as coll, error::Error, *};
  use std::collections::VecDeque;
  use std::fmt;

  pub trait Display {
      fn representation(&self) -> Item;
  }

  const BYTE_TAG: &str = "b64";

  fn to_item(item: &edn_format::Value) -> Result<Item, Error> {
      //println!("to item {:?}", item);
      match item {
          edn_format::Value::Integer(i) => Ok(Item::Int(*i)),
          edn_format::Value::Vector(v) => Ok({
              coll::List::from_iter(
                  v.iter()
                      .map(to_item)
                      .collect::<Result<VecDeque<Item>, Error>>()?,
              )
              .into()
          }),
          edn_format::Value::Symbol(s) => Ok(Item::Word(s.to_string().into())),
          // we don't have booleans in kcats, so if we see 'false' that
          // is the word false which is not defined in the base
          // language, but might be user-defined later.
          edn_format::Value::Boolean(b) => Ok(if *b { "yes".into() } else { "false".into() }),
          edn_format::Value::String(s) => Ok(s.to_string().into()),
          edn_format::Value::Float(f) => Ok(Item::Float(f.into_inner())),
          edn_format::Value::TaggedElement(tag, e) => {
              if *tag == edn_format::Symbol::from_name(BYTE_TAG) {
                  if let edn_format::Value::String(s) = &**e {
                      Ok(base64::decode(s).unwrap().into())
                  } else {
                      Err(Error::parse("Invalid tag datatype for byte literal"))
                  }
              } else {
                  Err(Error::parse("Unsupported tag"))
              }
          }
          edn_format::Value::Character(c) => Ok(Item::Char(*c)),
          _ => Err(Error::parse("Unsupported data literal")),
      }
  }

  pub fn from_item(item: &Item) -> edn_format::Value {
      match item {
          // dictionaries are big and it's ugly to print them for
          // environments.
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Env(e),
          ))) => from_item(&e.representation()),
          Item::Int(i) => edn_format::Value::Integer(*i),
          Item::Float(f) => edn_format::Value::from(*f),
          Item::Char(c) => edn_format::Value::Character(*c),
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(s))) => {
              edn_format::Value::String(s.to_string())
          }
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(bs))) => {
              edn_format::Value::TaggedElement(
                  edn_format::Symbol::from_name("b64"),
                  Box::new(edn_format::Value::String(base64::encode(bs))),
              )
          }
          Item::Receptacle(coll::Receptacle::Sized(coll::Sized::String(s))) => {
              edn_format::Value::String(s.to_string())
          }
          Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(bs))) => {
              edn_format::Value::TaggedElement(
                  edn_format::Symbol::from_name("b64"),
                  Box::new(edn_format::Value::String(base64::encode(bs))),
              )
          }
          Item::Dispenser(coll::Dispenser::Sized(v)) => edn_format::Value::Vector(
              v.clone()
                  .into_iter()
                  .map(|i| from_item(&i))
                  .collect::<Vec<edn_format::Value>>(),
          ),
          Item::Receptacle(coll::Receptacle::Sized(v)) => {
              from_item(&Item::Dispenser(coll::Dispenser::Sized(v.clone())))
          }
          Item::Word(w) => edn_format::Value::Symbol(edn_format::Symbol::from_name(w)),
          //Item::Entry(w) => edn_format::Value::Symbol(edn_format::Symbol::from_name(&w.word)),
          Item::Dispenser(coll::Dispenser::Out(o)) => from_item(&o.representation()),
          Item::Dispenser(coll::Dispenser::Tunnel(t)) => from_item(&t.representation()),
          Item::Receptacle(coll::Receptacle::In(i)) => from_item(&i.representation()),
          Item::Receptacle(coll::Receptacle::Tunnel(t)) => from_item(&t.representation()),
      }
  }

  pub fn parse(s: String) -> Result<coll::List, Error> {
      let parser = edn_format::Parser::from_iter(s.chars(), edn_format::ParserOptions::default());
      Ok(coll::List::from_iter(
          parser
              .map(move |r| match r {
                  Ok(expr) => Ok(to_item(&expr)?),
                  Err(e) => Err(Error::from(e)),
              })
              .collect::<Result<Vec<Item>, Error>>()?,
      ))
  }

  pub fn emit(item: &Item) -> String {
      edn_format::emit_str(&from_item(item))
  }

  pub fn emit_all(items: &VecDeque<Item>) -> String {
      let mut s: String = String::new();
      for i in items {
          s.push_str(edn_format::emit_str(&from_item(i)).as_str());
          s.push(' ');
      }
      s.pop();
      s.to_string()
  }

  // print out envs in error messages
  impl fmt::Debug for Environment {
      fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
          write!(
              f,
              "{{ stack: {}, program: {} }}",
              emit(&Item::from(self.stack.clone())),
              emit(&Item::from(self.program.clone())),
          )
      }
  }

  impl fmt::Debug for Error {
      fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
          write!(f, "{}", emit(&Item::from(self.data.clone())))
      }
  }

  impl From<edn_format::ParserError> for Error {
      fn from(e: edn_format::ParserError) -> Self {
          Error::parse(e.to_string().as_str())
      }
  }

  fn insert_line_breaks(input: &str, max_items: usize, max_chars: usize) -> String {
      let mut result = String::new();
      let mut current_line_length = 0;
      let mut open_list_stack: Vec<(usize, usize)> = Vec::new();
      open_list_stack.push((0, 0));
      let mut last_char: char = '\n';
      let mut in_string: bool = false;
      let mut in_tag = false;
      let mut chars = input.chars().peekable(); // Convert to a Peekable iterator

      while let Some(c) = chars.next() {
          current_line_length += 1;

          match c {
              '"' => {
                  if last_char != '\\' {
                      in_string = !in_string;
                  }
                  result.push(c);
              }
              '[' => {
                  if !in_string && last_char != '\\' {
                      open_list_stack.push((0, 0)); // Start a new list
                  }
                  result.push(c);
              }
              ']' => {
                  result.push(c);
                  if !in_string && last_char != '\\' {
                      let (last_count, break_count) = open_list_stack.pop().unwrap();
                      //println!("items, breaks: {}, {}", last_count, break_count);
                      if (last_count == 1 || last_count >= 6 || break_count > 0)
                          && chars.peek() != Some(&']')
                      {
                          // Only add a newline if the next character is not a closing bracket
                          result.push('\n');
                          let (_, break_count) = open_list_stack.last_mut().unwrap();
                          ,*break_count += 1;
                          current_line_length = 0;
                      }
                  }
              }
              ' ' => {
                  if !in_string {
                      let (last_count, break_count) = open_list_stack.last_mut().unwrap();
                      if in_tag {
                          in_tag = false;
                      } else {
                          ,*last_count += 1;
                      }
                      if (*last_count > 0 && (*last_count % max_items) == 0)
                          || current_line_length > max_chars
                      {
                          result.push('\n');
                          ,*break_count += 1;
                          current_line_length = 0;
                          //*last_count = 0;
                      }
                  }
                  result.push(c);
              }
              '#' => {
                  if !in_string {
                      in_tag = true;
                  }
                  result.push(c);
              }
              _ => {
                  result.push(c);
              }
          }
          last_char = c;
      }
      if result.ends_with('\n') {
          result.pop();
      }
      //println!("broken output: {:?}", result);
      result
  }

  fn parse_indent(stack: &mut Vec<usize>, input: &str) {
      let mut in_string = false;
      let mut escaped = false;

      for (idx, c) in input.chars().enumerate() {
          if in_string {
              match c {
                  '"' if !escaped => in_string = false,
                  // TODO handle \\ (escaped backslash char)
                  '\\' if !escaped => escaped = true,
                  _ => escaped = false,
              }
          } else {
              match c {
                  '[' if !escaped => {
                      escaped = false;
                      stack.push(idx);
                  }
                  ']' if !escaped => {
                      escaped = false;
                      stack.pop();
                  }
                  '"' => {
                      escaped = false;
                      in_string = true;
                  }
                  ';' => {
                      break;
                  }
                  '\\' => {
                      escaped = true;
                  }
                  _ => {
                      escaped = false;
                  }
              }
          }
      }
  }

  fn format_indentation(input: &str) -> String {
      let mut result = String::new();
      let mut indentations = Vec::<usize>::new();

      for line in input.lines() {
          let trimmed = line.trim();

          // Deduce the new indentation based on the last item in the indentations stack
          let new_indent = indentations.last().copied().map(|x| x + 1).unwrap_or(0);
          let padded_line = format!("{}{}\n", " ".repeat(new_indent), trimmed);
          result.push_str(padded_line.as_str());
          parse_indent(&mut indentations, &padded_line);
          //println!("indentations: {:?}: {:?}", padded_line, indentations);
      }
      result.pop(); // Remove the last newline
      result
  }

  pub fn auto_format(input: &str, max_items: usize, max_chars: usize) -> String {
      let with_breaks = insert_line_breaks(input, max_items, max_chars);
      format_indentation(&with_breaks)
  }

  #[cfg(test)]
  mod tests {
      use super::*;

      #[test]
      fn test_insert_line_breaks() {
          let input = "[[foo bar][baz [[quux floop][toop poop]]]]";
          let expected = "[[foo bar]\n[baz [[quux floop]\n[toop poop]]]]";
          let output = insert_line_breaks(input, 6, 80);
          assert_eq!(output, expected);

          let input = "[[[1 2 3] b][c d]]";
          let expected = "[[[1 2 3] b]\n[c d]]";
          let output = insert_line_breaks(input, 6, 80);
          assert_eq!(output, expected);

          // multiline list
          let input = "[[a b] [c d]] 5";
          let expected = "[[a b]\n [c d]]\n 5";
          let output = insert_line_breaks(input, 6, 80);
          assert_eq!(output, expected);
      }

      #[test]
      fn test_indentation() {
          let input = "[[foo bar]\n[baz [[quux floop]\n[toop poop]]]]";
          let expected = "[[foo bar]\n [baz [[quux floop]\n       [toop poop]]]]";
          let output = format_indentation(input);
          assert_eq!(output, expected);

          let input = "\"hello\" [[a b]\n[c d]]";
          let expected = "\"hello\" [[a b]\n         [c d]]";
          let output = format_indentation(input);
          assert_eq!(output, expected);
      }
  }
#+end_src
*** Builtin words
We'll define some words as axioms (not in terms of other words, only defined in Rust). 
#+begin_src rust :tangle src/axiom.rs :mkdirp yes
  use super::serialize;
  use crate::pipes;
  use crate::pipes::db;
  use crate::types::associative as assoc;
  use crate::types::collection as coll;
  use crate::types::dictionary as dict;
  use crate::types::environment::Environment;
  use crate::types::error::Error;
  use crate::types::*;
  use dynfmt::Format;
  use futures::future::FutureExt;
  use num_integer::Roots;
  use std::collections::HashMap;
  use std::collections::VecDeque;
  use std::ops::Deref;
  //use std::future::Future;
  use std::mem;
  use std::ops::Range;

  pub type ItemResult = Result<Item, Error>;

  impl From<ItemResult> for Item {
      fn from(i: ItemResult) -> Self {
          match i {
              Ok(i) => i,
              Err(e) => e.into(),
          }
      }
  }

  fn f_stack1(f: fn(Item) -> ItemResult) -> impl Fn(Environment) -> Future<Environment> {
      move |mut env: Environment| {
          if let Some(x) = env.tos() {
              let res = f(x.clone());
              if res.is_ok() {
                  env.pop_expr();
                  env.pop();
              }
              env.push(Item::from(res)).into()
          } else {
              env.push(Item::from(Error::stack_underflow())).into()
          }
      }
  }

  fn f_stack2(f: fn(Item, Item) -> ItemResult) -> impl Fn(Environment) -> Future<Environment> {
      move |mut env: Environment| {
          let x = env.tos();
          let y = env.stack.get(1);
          match (x, y) {
              (Some(x), Some(y)) => {
                  let res = f(y.clone(), x.clone());
                  if res.is_ok() {
                      env.pop_expr();
                      env.pop();
                      env.pop();
                  }
                  env.push(Item::from(res)).into()
              }
              _ => env.push(Item::from(Error::stack_underflow())).into(),
          }
      }
  }

  fn f_stack3(f: fn(Item, Item, Item) -> ItemResult) -> impl Fn(Environment) -> Future<Environment> {
      move |mut env: Environment| {
          let x = env.tos();
          let y = env.stack.get(1);
          let z = env.stack.get(2);
          match (x, y, z) {
              (Some(x), Some(y), Some(z)) => {
                  let res = f(z.clone(), y.clone(), x.clone());
                  if res.is_ok() {
                      env.pop_expr();
                      env.pop();
                      env.pop();
                      env.pop();
                  }
                  env.push(Item::from(res)).into()
              }
              _ => env.push(Item::from(Error::stack_underflow())).into(),
          }
      }
  }

  fn f_stack2_async(
      f: fn(Item, Item) -> Future<ItemResult>,
  ) -> impl Fn(Environment) -> Future<Environment> {
      move |mut env: Environment| {
          let x = env.pop();
          let y = env.pop();
          Box::pin(f(x, y).map(|r| {
              if r.is_ok() {
                  env.pop_expr();
              }
              env.push(Item::from(r))
          }))
      }
  }

  fn update_axiom_entries(
      mut d: dict::Dictionary,
      updates: Vec<(&str, &'static StepFn)>,
  ) -> dict::Dictionary {
      let dm = coll::Arc::make_mut(&mut d);
      for (w, f) in updates {
          dm.entry(Word::from(w)).and_modify(|e| {
              e.definition = dict::Definition::Axiom(f);
          });
      }
      d
  }

  pub fn add_builtins(d: dict::Dictionary) -> dict::Dictionary {
      update_axiom_entries(
          d,
          vec![
              ("*", Box::leak(Box::new(f_stack2(mult)))),
              ("+", Box::leak(Box::new(f_stack2(plus)))),
              ("get", Box::leak(Box::new(f_stack2(lookup)))),
              ("sort-indexed", Box::leak(Box::new(f_stack1(sort_by_key)))),
              ("-", Box::leak(Box::new(f_stack2(minus)))),
              ("/", Box::leak(Box::new(f_stack2(div)))),
              ("<", Box::leak(Box::new(f_stack2(lt)))),
              ("<=", Box::leak(Box::new(f_stack2(lte)))),
              ("=", Box::leak(Box::new(f_stack2(eq)))),
              (">", Box::leak(Box::new(f_stack2(gt)))),
              (">=", Box::leak(Box::new(f_stack2(gte)))),
              ("abs", Box::leak(Box::new(f_stack1(abs)))),
              ("and", Box::leak(Box::new(f_stack2(and)))),
              ("animate", Box::leak(Box::new(animate))),
              ("assign", Box::leak(Box::new(f_stack3(assign)))),
              ("association", Box::leak(Box::new(f_stack1(association)))),
              (
                  "association?",
                  Box::leak(Box::new(f_stack1(is_association))),
              ),
              (
                  "attend",
                  Box::leak(Box::new(f_stack1(crate::pipes::channel::select))),
              ),
              ("autoformat", Box::leak(Box::new(f_stack1(autoformat)))),
              ("branch", Box::leak(Box::new(branch))),
              ("bytes?", Box::leak(Box::new(f_stack1(is_bytes)))),
              ("clone", Box::leak(Box::new(clone))),
              ("contains?", Box::leak(Box::new(f_stack2(contains)))),
              ("ceiling", Box::leak(Box::new(f_stack1(ceiling)))),
              ("compare", Box::leak(Box::new(f_stack2(compare)))),
              ("count", Box::leak(Box::new(f_stack1(count)))),
              ("database", Box::leak(Box::new(f_stack1(db::query)))),
              ("dec", Box::leak(Box::new(f_stack1(dec)))),
              ("decide", Box::leak(Box::new(decide))),
              ("decodejson", Box::leak(Box::new(f_stack1(decode_json)))),
              ("dip", Box::leak(Box::new(dip))),
              ("dictionary", Box::leak(Box::new(dictionary))),
              ("dipdown", Box::leak(Box::new(dipdown))),
              ("drop", Box::leak(Box::new(drop))),
              ("emit", Box::leak(Box::new(f_stack1(emit)))),
              ("empty", Box::leak(Box::new(f_stack1(empty)))),
              ("empty?", Box::leak(Box::new(f_stack1(is_empty)))),
              ("encodestring", Box::leak(Box::new(f_stack1(encode_string)))),
              ("encodejson", Box::leak(Box::new(f_stack1(encode_json)))),
              ("environment", Box::leak(Box::new(f_stack1(environment)))),
              ("error?", Box::leak(Box::new(f_stack1(is_error)))),
              ("eval-step", Box::leak(Box::new(eval_step_outer))),
              ("evaluate", Box::leak(Box::new(evaluate))),
              ("even?", Box::leak(Box::new(f_stack1(is_even)))),
              ("evert", Box::leak(Box::new(evert))),
              ("execute", Box::leak(Box::new(execute))),
              ("exp", Box::leak(Box::new(f_stack2(exp)))),
              ("fail", Box::leak(Box::new(f_stack1(fail)))),
              (
                  "file-in",
                  Box::leak(Box::new(f_stack1(crate::pipes::fs::file_in))),
              ),
              (
                  "file-out",
                  Box::leak(Box::new(f_stack1(crate::pipes::fs::file_out))),
              ),
              ("first", Box::leak(Box::new(f_stack1(first)))),
              ("float", Box::leak(Box::new(float))),
              ("floor", Box::leak(Box::new(f_stack1(floor)))),
              ("format", Box::leak(Box::new(f_stack2(format)))),
              ("handle", Box::leak(Box::new(f_stack1(handle)))),
              (
                  "handoff",
                  Box::leak(Box::new(crate::pipes::channel::handoff)),
              ),
              (
                  "hashbytes",
                  Box::leak(Box::new(f_stack1(crate::crypto::hash))),
              ),
              ("inc", Box::leak(Box::new(f_stack1(inc)))),
              ("inspect", Box::leak(Box::new(f_stack1(inspect)))),
              ("join", Box::leak(Box::new(f_stack2(join)))),
              ("key", Box::leak(Box::new(f_stack1(crate::crypto::key)))),
              ("last", Box::leak(Box::new(f_stack1(last)))),
              ("list?", Box::leak(Box::new(f_stack1(is_list)))),
              ("log", Box::leak(Box::new(f_stack2(log)))),
              ("loop", Box::leak(Box::new(loop_))),
              ("mod", Box::leak(Box::new(f_stack2(mod_)))),
              ("not", Box::leak(Box::new(f_stack1(not)))),
              ("number?", Box::leak(Box::new(f_stack1(is_number)))),
              ("odd?", Box::leak(Box::new(f_stack1(is_odd)))),
              ("or", Box::leak(Box::new(f_stack2(or)))),
              ("pop", Box::leak(Box::new(pop))),
              ("put", Box::leak(Box::new(put))),
              ("pipe?", Box::leak(Box::new(f_stack1(is_pipe)))),
              (
                  "random",
                  Box::leak(Box::new(f_stack1(crate::crypto::random))),
              ),
              ("range", Box::leak(Box::new(range))),
              ("read", Box::leak(Box::new(read))),
              (
                  "receiver",
                  Box::leak(Box::new(f_stack1(crate::pipes::channel::receiver))),
              ),
              ("recur", Box::leak(Box::new(recur))),
              ("redefine", Box::leak(Box::new(redefine))),
              ("resume", Box::leak(Box::new(identity))),
              ("reverse", Box::leak(Box::new(f_stack1(reverse)))),
              ("round", Box::leak(Box::new(f_stack1(round)))),
              ("second", Box::leak(Box::new(f_stack1(second)))),
              (
                  "sender",
                  Box::leak(Box::new(f_stack1(crate::pipes::channel::sender))),
              ),
              (
                  "serversocket",
                  Box::leak(Box::new(f_stack2_async(crate::pipes::net::server_socket))),
              ),
              ("set", Box::leak(Box::new(f_stack1(set)))),
              ("set?", Box::leak(Box::new(f_stack1(is_set)))),
              ("sign", Box::leak(Box::new(f_stack2(crate::crypto::sign)))),
              ("sink", Box::leak(Box::new(sink))),
              ("slice", Box::leak(Box::new(f_stack3(slice)))),
              (
                  "socket",
                  Box::leak(Box::new(f_stack2_async(crate::pipes::net::socket))),
              ),
              ("sqrt", Box::leak(Box::new(f_stack1(sqrt)))),
              ("standard", Box::leak(Box::new(standard))),
              ("step", Box::leak(Box::new(step))),
              ("string", Box::leak(Box::new(f_stack1(string)))),
              ("string?", Box::leak(Box::new(f_stack1(is_string)))),
              ("swap", Box::leak(Box::new(swap))),
              ("swapdown", Box::leak(Box::new(swapdown))),
              (
                  "timer",
                  Box::leak(Box::new(f_stack1(crate::pipes::channel::timer))),
              ),
              ("timestamps", Box::leak(Box::new(timestamps))),
              ("unassign", Box::leak(Box::new(f_stack2(unassign)))),
              ("take", Box::leak(Box::new(take))),
              ("unwrap", Box::leak(Box::new(unwrap))),
              (
                  "verify",
                  Box::leak(Box::new(f_stack3(crate::crypto::verify))),
              ),
              ("word?", Box::leak(Box::new(f_stack1(is_word)))),
              ("wrap", Box::leak(Box::new(wrap))),
              ("xor", Box::leak(Box::new(f_stack2(xor)))),
              ("yes", Box::leak(Box::new(yes))),
              ("zero?", Box::leak(Box::new(f_stack1(is_zero)))),
          ],
      )
  }

  pub fn read_lexicon(lexicon: String, mut env: Environment) -> Environment {
      let items = serialize::parse(lexicon).unwrap();
      for r in Box::new(items.inner().into_iter()) {
          let (k, def): (assoc::KeyItem, Item) = r.try_into().unwrap();
          let word: Word = k.try_into().unwrap();
          let iter: Box<dyn Iterator<Item = Item>> = def.try_into().unwrap();
          let new_entry: dict::Entry = iter.try_into().unwrap();
          let new_entry2 = new_entry.clone();
          let dict = coll::Arc::make_mut(&mut env.dictionary);
          dict.entry(word)
              .and_modify(|e| {
                  e.examples = new_entry.examples;
                  e.spec = new_entry.spec;
                  e.definition = new_entry.definition;
              })
              .or_insert(new_entry2);
      }
      env
  }

  pub fn add_standard_dictionary(env: Environment) -> Environment {
      // read builtins
      let builtins = String::from_utf8(include_bytes!("kcats/builtins.kcats").to_vec()).unwrap();
      let mut env = read_lexicon(builtins, env);
      //println!("with builtins {:?}", env.dictionary);
      env.dictionary = add_builtins(env.dictionary);
      //env = add_derivations(env);
      let lexicon = String::from_utf8(include_bytes!("kcats/lexicon.kcats").to_vec()).unwrap();
      read_lexicon(lexicon, env)
  }

  pub fn invalid_type_error(asked: coll::List, actual: Item) -> ItemResult {
      Err(Error::type_mismatch(asked, Some(actual)))
  }

  fn number_type_error(i: Item) -> ItemResult {
      invalid_type_error(crate::types::wrap(Item::Word(*S_NUMBER)), i)
  }

  fn pair(i: Item, j: Item) -> Item {
      coll::List::from_iter([i, j]).into()
  }

  pub fn plus(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::Int(i + j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::Float(i + j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::Float(i as Float + j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::Float(i + j as Float)),
          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn minus(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::Int(i - j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::Float(i - j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::Float(i as Float - j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::Float(i - j as Float)),
          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn mult(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::Int(i * j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::Float(i * j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::Float(i as Float * j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::Float(i * j as Float)),
          (i, j) => number_type_error(pair(i, j)),
      }
  }

  fn divide(i: Float, j: Float) -> ItemResult {
      let q = i / j;
      if q.is_nan() {
          Err(Error::division_by_zero())
      } else {
          Ok(Item::Float(q))
      }
  }

  pub fn div(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => i
              .checked_div(j)
              .ok_or_else(Error::division_by_zero)
              .map(Item::Int),

          (Item::Float(i), Item::Float(j)) => divide(i, j),
          (Item::Int(i), Item::Float(j)) => divide(i as Float, j),
          (Item::Float(i), Item::Int(j)) => divide(i, j as Float),
          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn mod_(i: Item, j: Item) -> ItemResult {
      let i = Int::try_from(i)?;
      let j = Int::try_from(j)?;
      Ok(Item::Int(i % j))
  }

  pub fn floor(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::Int(i)),
          Item::Float(i) => Ok(Item::Int(i.floor() as Int)),
          i => number_type_error(i),
      }
  }

  pub fn ceiling(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::Int(i)),
          Item::Float(i) => Ok(Item::Int(i.ceil() as Int)),
          i => number_type_error(i),
      }
  }

  pub fn round(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::Int(i)),
          Item::Float(i) => Ok(Item::Int(i.round() as Int)),
          i => number_type_error(i),
      }
  }

  pub fn exp(base: Item, exponent: Item) -> ItemResult {
      match (base, exponent) {
          (Item::Int(base), Item::Int(exponent)) => base
              .checked_pow(exponent as u32)
              .ok_or(Error::overflow())
              .map(Item::Int),
          (base, exponent) => number_type_error(pair(base, exponent)),
      }
  }

  pub fn log(value: Item, base: Item) -> ItemResult {
      match (base, value) {
          (Item::Int(base), Item::Int(value)) => {
              if base <= 1 {
                  Err(Error::too_small(base, 1))
              } else if value <= 0 {
                  Err(Error::too_small(value, 0))
              } else {
                  let base = base as Float;
                  let value = value as Float;
                  Ok(Item::Float(value.log(base)))
              }
          }
          (base, value) => number_type_error(pair(base, value)),
      }
  }

  pub fn inc(i: Item) -> ItemResult {
      Ok(Item::Int(Int::try_from(i)? + 1))
  }

  pub fn dec(i: Item) -> ItemResult {
      Ok(Item::Int(Int::try_from(i)? - 1))
  }

  pub fn is_zero(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::from(i == 0)),
          Item::Float(i) => Ok(Item::from(i == 0.0)),
          i => number_type_error(i),
      }
  }

  pub fn is_empty(i: Item) -> ItemResult {
      Ok(Item::from(match i {
          Item::Dispenser(coll::Dispenser::Sized(s)) => s.is_empty(),
          Item::Receptacle(coll::Receptacle::Sized(s)) => s.is_empty(),
          _ => false,
      }))
  }

  pub fn gt(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::from(i > j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::from(i > j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::from(i as Float > j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::from(i > j as Float)),

          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn lt(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::from(i < j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::from(i < j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::from((i as Float) < j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::from(i < j as Float)),

          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn gte(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::from(i >= j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::from(i >= j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::from(i as Float >= j)),
          (Item::Float(i), Item::Int(j)) => Ok(Item::from(i >= j as Float)),

          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn lte(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::from(i <= j)),
          (Item::Float(i), Item::Float(j)) => Ok(Item::from(i <= j)),
          (Item::Int(i), Item::Float(j)) => Ok(Item::from((i as Float).le(&j))),
          (Item::Float(i), Item::Int(j)) => Ok(Item::from(i <= j as Float)),

          (i, j) => number_type_error(pair(i, j)),
      }
  }

  pub fn join(i: Item, j: Item) -> ItemResult {
      let i = coll::Sized::try_from(i)?;
      let j = coll::Sized::try_from(j)?;
      Ok(i.join(j)?.into())
  }

  pub fn put(mut env: Environment) -> Future<Environment> {
      let j = env.pop();
      let i = env.pop();
      let i2 = i.clone();
      let pr = coll::Receptacle::try_from(i);
      match pr {
          Ok(p) => Box::pin(p.put(j).map(|f| match f {
              Ok(p) => {
                  env.pop_expr();
                  env.push(Item::Receptacle(p))
              }
              Err(e) => env.push(i2).push(e.into()),
          })),
          Err(e) => env.push(i2).push(e.into()).into(),
      }
  }

  pub fn clone(mut env: Environment) -> Future<Environment> {
      let clone = env.stack.front().unwrap().clone();
      env.pop_expr();
      env.push(clone).into()
  }

  fn swap2(mut env: Environment, offset: usize) -> Future<Environment> {
      coll::Arc::make_mut(&mut env.stack).swap(offset, offset + 1);
      env.into()
  }

  pub fn swap(mut env: Environment) -> Future<Environment> {
      env.pop_expr();
      swap2(env, 0)
  }

  pub fn swapdown(mut env: Environment) -> Future<Environment> {
      env.pop_expr();
      swap2(env, 1)
  }

  pub fn sink(mut env: Environment) -> Future<Environment> {
      let s = coll::Arc::make_mut(&mut env.stack);
      s.swap(0, 2);
      s.swap(0, 1);
      env.pop_expr();
      env.into()
  }

  pub fn float(mut env: Environment) -> Future<Environment> {
      let s = coll::Arc::make_mut(&mut env.stack);
      s.swap(0, 2);
      s.swap(1, 2);
      env.pop_expr();
      env.into()
  }

  pub fn drop(mut env: Environment) -> Future<Environment> {
      env.pop();
      env.pop_expr();
      env.into()
  }

  pub fn eq(i: Item, j: Item) -> ItemResult {
      Ok(Item::from(i == j))
  }

  pub fn count(i: Item) -> ItemResult {
      match i {
          Item::Dispenser(coll::Dispenser::Sized(i)) => Ok(Item::Int(i.len() as Int)),
          Item::Receptacle(coll::Receptacle::Sized(i)) => Ok(Item::Int(i.len() as Int)),
          i => Err(Error::expected("sized", i)),
      }
  }

  pub fn is_string(i: Item) -> ItemResult {
      Ok(Item::from(matches!(
          i,
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::String(_)))
      )))
  }

  pub fn is_bytes(i: Item) -> ItemResult {
      Ok(Item::from(matches!(
          i,
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(_)))
      )))
  }

  pub fn is_error(i: Item) -> ItemResult {
      Ok(Item::from(matches!(
          i,
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Error(_),
          )))
      )))
  }

  pub fn is_word(i: Item) -> ItemResult {
      Ok(Item::from(match i {
          Item::Word(_) => true,
          //Item::Iterable(Item(_)) => true,
          // TODO maybe also check if it's an associative that looks like a Def?
          _ => false,
      }))
  }

  pub fn is_pipe(i: Item) -> ItemResult {
      Ok(Item::from(matches!(
          i,
          Item::Dispenser(coll::Dispenser::Out(_))
              | Item::Dispenser(coll::Dispenser::Tunnel(_))
              | Item::Receptacle(coll::Receptacle::In(_))
              | Item::Receptacle(coll::Receptacle::Tunnel(_))
      )))
  }
  pub fn is_number(i: Item) -> ItemResult {
      Ok(Item::from(matches!(i, Item::Int(_) | Item::Float(_))))
  }

  pub fn is_list(i: Item) -> ItemResult {
      Ok(coll::Sized::try_from(i)
          .map(|s| matches!(s, coll::Sized::List(_)))
          .unwrap_or(false)
          .into())
  }

  pub fn first(i: Item) -> ItemResult {
      let s = coll::Sized::try_from(i)?;
      let (_, i) = s.take();
      Ok(i.into())
  }

  pub fn second(i: Item) -> ItemResult {
      let l = coll::List::try_from(i)?;
      Ok(l.get(1).cloned().unwrap_or_default())
  }

  pub fn last(i: Item) -> ItemResult {
      let s = coll::Sized::try_from(i)?;
      Ok(s.into_iter().last().unwrap_or_default())
  }

  pub fn loop_(mut env: Environment) -> Future<Environment> {
      let p = coll::List::try_from(env.pop());
      match p {
          Ok(mut p) => {
              env.pop_expr();
              let f = env.pop();
              if is_truthy(f) {
                  let p2 = p.clone();
                  let pm = coll::Arc::make_mut(&mut p);
                  pm.push_back(Item::from(p2));
                  pm.push_back("loop".into());
                  env.append_program(p)
              } else {
                  env
              }
          }
          Err(e) => env.push(Item::from(e)),
      }
      .into()
  }

  pub fn execute(mut env: Environment) -> Future<Environment> {
      let i = env.pop();
      match coll::List::try_from(i) {
          Ok(program) => {
              env.pop_expr();
              env.append_program(program)
          }
          Err(e) => env.push(e.into()),
      }
      .into()
  }

  pub fn wrap(mut env: Environment) -> Future<Environment> {
      let item = env.pop();
      env.pop_expr();
      env.push(coll::List::from_iter([item]).into()).into()
  }

  pub fn unwrap(mut env: Environment) -> Future<Environment> {
      //println!("unwrapping");
      match coll::List::try_from(env.pop()) {
          Ok(l) => {
              env.pop_expr();
              let len = l.len();
              let l2 = (0..len).map(move |i| l[i].clone());
              for i in l2 {
                  env = env.push(i);
              }
              env
          }
          Err(e) => env.push(e.into()),
      }
      .into()
  }

  pub fn dip(mut env: Environment) -> Future<Environment> {
      match coll::List::try_from(env.pop()) {
          Ok(program) => {
              let item = env.pop();
              let expr = env.program.make_mut();
              expr.pop_front();
              expr.push_front("unwrap".into());
              expr.push_front(coll::List::from_iter([item]).into());
              env.append_program(program)
          }
          Err(e) => env.push(e.into()),
      }
      .into()
  }

  pub fn dipdown(mut env: Environment) -> Future<Environment> {
      match coll::List::try_from(env.pop()) {
          Ok(program) => {
              let item1 = env.pop();
              let item2 = env.pop();
              let expr = env.program.make_mut();
              expr.pop_front();
              expr.push_front("unwrap".into());
              expr.push_front(coll::List::from_iter([item2, item1]).into());
              env.append_program(program)
          }
          Err(e) => env.push(e.into()),
      }
      .into()
  }

  pub fn take(mut env: Environment) -> Future<Environment> {
      // TODO: handle Nothing case
      let coll = {
          let stack = env.stack.make_mut();
          stack.pop_front()
      };
      match coll {
          Some(i) => {
              let i2 = i.clone();
              let r = coll::Dispenser::try_from(i);
              match r {
                  Ok(it) => {
                      let f = it.take();
                      Box::pin(async move {
                          let (c, i) = f.await;
                          env.pop_expr();
                          let stack = env.stack.make_mut();
                          stack.push_front(c.into());
                          stack.push_front(i.unwrap_or_default());
                          env
                      })
                  }
                  Err(e) => {
                      let stack = env.stack.make_mut();
                      stack.push_front(i2);
                      stack.push_front(e.into());
                      env.into()
                  }
              }
          }
          None => {
              let stack = env.stack.make_mut();
              stack.push_front(Error::stack_underflow().into());
              env.into()
          }
      }
  }

  pub fn pop(mut env: Environment) -> Future<Environment> {
      let coll = {
          let stack = env.stack.make_mut();
          stack.pop_front()
      };
      match coll {
          Some(i) => {
              let i2 = i.clone();
              let s = coll::Sized::try_from(i);

              match s {
                  Ok(it) => {
                      let (c, i) = it.pop();
                      env.pop_expr();
                      let stack = env.stack.make_mut();
                      stack.push_front(c.into());
                      stack.push_front(i.unwrap_or_default());
                      env.into()
                  }
                  Err(e) => {
                      let stack = env.stack.make_mut();
                      stack.push_front(i2);
                      stack.push_front(e.into());
                      env.into()
                  }
              }
          }
          None => {
              let stack = env.stack.make_mut();
              stack.push_front(Error::stack_underflow().into());
              env.into()
          }
      }
  }

  pub fn is_truthy(i: Item) -> bool {
      coll::Sized::try_from(i).map_or(true, |s| !s.is_empty())
  }

  // fn boolean_value(b: bool) -> Item {
  //     if b {
  //         "true".into()
  //     } else {
  //         coll::Item::default()
  //     }
  // }

  pub fn branch(mut env: Environment) -> Future<Environment> {
      match (
          coll::List::try_from(env.pop()),
          coll::List::try_from(env.pop()),
      ) {
          (Ok(false_branch), Ok(true_branch)) => {
              env.pop_expr();
              let b = env.pop();

              env.append_program(if is_truthy(b) {
                  true_branch
              } else {
                  false_branch
              })
          }
          (Err(e), _) => env.push(e.into()),
          (_, Err(e)) => env.push(e.into()),
      }
      .into()
  }

  pub fn step(mut env: Environment) -> Future<Environment> {
      let p = coll::List::try_from(env.pop()).unwrap();
      let it = coll::Dispenser::try_from(env.pop()).unwrap();
      Box::pin(async move {
          if let (it, Some(litem)) = it.take().await {
              let expr = env.program.make_mut();
              // prepare the next iteration, even if the iterator is now
              // empty. step is still the next instruction.
              expr.push_front(p.clone().into());
              expr.push_front(it.into());
              expr.push_front("execute".into());

              env.push(litem).push(p.into())
          } else {
              env.pop_expr();
              env
          }
      })
  }

  pub fn range(mut env: Environment) -> Future<Environment> {
      let stepby = Int::try_from(env.pop()).unwrap();
      let to = Int::try_from(env.pop()).unwrap();
      let from = Int::try_from(env.pop()).unwrap();
      let mut env =
          env.push(coll::List::from_iter((from..to).step_by(stepby as usize).map(Item::Int)).into());
      env.pop_expr();
      env.into()
  }

  // (effect [rec2 rec1 then pred]
  //                   ['[if]
  //[(concat rec1
  //         [[pred then rec1 rec2 'recur]] rec2)
  // then pred]])

  pub fn recur(mut env: Environment) -> Future<Environment> {
      let mut rec2 = coll::List::try_from(env.pop()).unwrap();
      let mut rec1 = coll::List::try_from(env.pop()).unwrap();
      let then = coll::List::try_from(env.pop()).unwrap();
      let pred = coll::List::try_from(env.pop()).unwrap();
      env.pop_expr();
      env = env.push_expr("if".into());
      let r = coll::List::from_iter([
          Item::from(pred.clone()),
          then.clone().into(),
          rec1.clone().into(),
          rec2.clone().into(),
          "recur".into(),
      ])
      .into();
      // I think i did this right - used to create a new list and extend
      // it with rec1, then push r, then extend again with rec2. now
      // start with rec1 (copied on write), then push r, then extend
      // with rec2.  That should be equivalent.
      let rm = rec1.make_mut();
      rm.push_back(r);
      rm.extend(rec2.make_mut().drain(..));
      //env.pop_expr();
      env.push(pred.into())
          .push(then.into())
          .push(rec1.into())
          .into()
  }

  //(fn [{[l & others] 'stack :as env}]
  //            (assoc env 'stack (apply list (vec others) l)))

  pub fn evert(mut env: Environment) -> Future<Environment> {
      let mut l = coll::List::try_from(env.pop()).unwrap();
      mem::swap(&mut env.stack, &mut l);
      env.pop_expr();
      env.push(l.into()).into()
  }

  fn assoc_vec(mut l: coll::List, ks: &[assoc::KeyItem], k: Int, v: Item) -> Result<Item, Error> {
      let lm = coll::Arc::make_mut(&mut l);
      let idx = k as usize;
      // extend the size of the vector to be big enough to set
      // the given index, pad with 'nothing' values.
      if lm.len() <= idx {
          lm.resize(idx + 1, Item::default());
      }
      let inner = &lm[idx];

      lm[k as usize] = if let [nextk, ..] = ks {
          let i: Item = match (inner, nextk) {
              (
                  Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(l))),
                  assoc::KeyItem::Int(_),
              ) => l.clone().into(),
              (
                  Item::Receptacle(coll::Receptacle::Sized(coll::Sized::List(l))),
                  assoc::KeyItem::Int(_),
              ) => l.clone().into(),
              (_, assoc::KeyItem::Int(_)) => coll::List::default().into(),
              _ => assoc::Association::new().into(),
          };
          assoc_in(i, ks, v)?
      } else {
          v
      };

      //if the inner value isn't a list, overwrite it
      Ok(l.into())
  }

  fn assoc_in(i: Item, ks: &[assoc::KeyItem], v: Item) -> Result<Item, Error> {
      if let [k, ks @ ..] = ks {
          if ks.is_empty() {
              match (i, k) {
                  (
                      Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(mut l))),
                      assoc::KeyItem::Int(k),
                  ) => {
                      // vector set by index
                      let lm = coll::Arc::make_mut(&mut l);
                      let idx = *k as usize;
                      // extend the size of the vector to be big enough to set
                      // the given index, pad with 'nothing' values.
                      if lm.len() <= idx {
                          lm.resize(idx + 1, Item::default());
                      }
                      lm[*k as usize] = v;
                      Ok(l.into())
                  }
                  (
                      Item::Receptacle(coll::Receptacle::Sized(coll::Sized::List(mut l))),
                      assoc::KeyItem::Int(k),
                  ) => {
                      // vector set by index
                      let lm = coll::Arc::make_mut(&mut l);
                      let idx = *k as usize;
                      // extend the size of the vector to be big enough to set
                      // the given index, pad with 'nothing' values.
                      if lm.len() <= idx {
                          lm.resize(idx + 1, Item::default());
                      }
                      lm[*k as usize] = v;
                      Ok(l.into())
                  }
                  (i, k) => {
                      let a = assoc::Associative::try_from(i)?;
                      Ok(a.insert(k.clone(), v).0.into())
                  }
              }
              //hm.insert(k.clone(), v);
          } else {
              match (i, k) {
                  (
                      Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(l))),
                      assoc::KeyItem::Int(k),
                  ) => assoc_vec(l, ks, *k, v),

                  (
                      Item::Receptacle(coll::Receptacle::Sized(coll::Sized::List(l))),
                      assoc::KeyItem::Int(k),
                  ) => assoc_vec(l, ks, *k, v),

                  (i, k) => {
                      let a = assoc::Associative::try_from(i)?;
                      let inner = a.get(k).unwrap_or_default().clone();

                      // if the inner value is a map, recurse. If it's a
                      // list and the next key is a number,
                      // recurse. Otherwise, overwrite the value with a new map.
                      let next_key = ks[0].clone();
                      let i = match (next_key, inner) {
                          (
                              assoc::KeyItem::Int(_),
                              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(l))),
                          ) => l.clone().into(),
                          (
                              assoc::KeyItem::Int(_),
                              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::List(l))),
                          ) => l.clone().into(),
                          (
                              _,
                              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(a))),
                          ) => a.clone().into(),
                          (
                              _,
                              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Associative(a))),
                          ) => a.clone().into(),
                          _ => assoc::Association::new().into(),
                      };
                      Ok(a.insert(k.clone(), assoc_in(i, ks, v)?).0.into())
                  }
              }
          }
      } else {
          Ok(i)
      }
  }

  fn unassoc_in(i: Item, ks: &[assoc::KeyItem]) -> Result<Item, Error> {
      if let [k, ks @ ..] = ks {
          if ks.is_empty() {
              let a = assoc::Associative::try_from(i)?;
              Ok(a.remove(k).0.into())
          } else {
              match (i, k) {
                  (
                      Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(mut l))),
                      assoc::KeyItem::Int(k),
                  ) => {
                      let lm = l.make_mut();
                      let old_value = if let Some(item) = lm.get_mut(*k as usize) {
                          mem::take(item)
                      } else {
                          return Err(Error::short_list(*k)); // replace with your error
                      };
                      let new_value = unassoc_in(old_value, ks)?;
                      lm[*k as usize] = new_value;
                      Ok(l.into())
                  }
                  (a, k) => {
                      let a: assoc::Associative = a.try_into()?;
                      let mut a: assoc::Association = a.into_iter().collect();
                      let am = a.make_mut();
                      let mut res: Option<Result<_, Error>> = None;
                      am.entry(k.clone()).and_modify(|v| {
                          let new_value = unassoc_in(v.clone(), ks);
                          res = Some(new_value.map(|nv| {
                              ,*v = nv;
                          }));
                      });
                      if let Some(Err(e)) = res {
                          return Err(e);
                      }
                      Ok(a.into())
                  }
              }
          }
      } else {
          Ok(i)
      }
  }

  pub fn assign(m: Item, ks: Item, v: Item) -> ItemResult {
      let kit = coll::List::try_from(ks)?;
      let mut ksvec: assoc::KeyList = assoc::KeyList::try_from_iter(kit.inner().into_iter())?;
      ksvec.make_mut().make_contiguous();
      let (ks, _) = ksvec.as_slices();
      assoc_in(m, ks, v)
  }

  pub fn unassign(m: Item, ks: Item) -> ItemResult {
      let kit = coll::List::try_from(ks)?;
      let mut ksvec: assoc::KeyList = assoc::KeyList::try_from_iter(kit.inner().into_iter())?;
      ksvec.make_mut().make_contiguous();
      let (ks, _) = ksvec.as_slices();
      unassoc_in(m, ks)
  }

  pub fn association(m: Item) -> ItemResult {
      match assoc::Associative::try_from(m) {
          Ok(m) => Ok(m.into()),
          Err(e) => Err(e),
      }
  }

  pub fn lookup(i: Item, k: Item) -> ItemResult {
      //println!("lookup {:?} \n {:?}", i, k);
      let k = assoc::KeyItem::try_from(k)?;
      let i = coll::Sized::try_from(i)?;
      match (i, k) {
          (coll::Sized::List(l), assoc::KeyItem::Int(k)) => {
              Ok(l.get(k as usize).cloned().unwrap_or_default())
          }
          (coll::Sized::String(s), assoc::KeyItem::Int(k)) => {
              //let s = s.inner();
              s.chars()
                  .nth(k as usize)
                  .map_or(Ok(Item::default()), |c| Ok(c.into()))
          }
          (coll::Sized::Bytes(b), assoc::KeyItem::Int(k)) => b
              .get(k as usize)
              .cloned()
              .map_or(Ok(Item::default()), |c| Ok(Item::Int(c as i64))),
          (i, k) => {
              let m = assoc::Associative::try_from(i)?;
              Ok(m.get(&k).unwrap_or_default())
          }
      }
  }

  pub fn contains(c: Item, i: Item) -> ItemResult {
      let s = coll::Sized::try_from(c)?;
      Ok(s.contains(&i).into())
  }

  pub fn or(i: Item, j: Item) -> ItemResult {
      Ok(if is_truthy(i.clone()) {
          i
      } else if is_truthy(j.clone()) {
          j
      } else {
          Item::default()
      })
      //Ok(Item::from(is_truthy(i) || is_truthy(j)))
  }

  pub fn and(i: Item, j: Item) -> ItemResult {
      Ok(if is_truthy(i) && is_truthy(j.clone()) {
          j
      } else {
          Item::default()
      })
  }

  pub fn not(i: Item) -> ItemResult {
      Ok(Item::from(!is_truthy(i)))
  }

  pub fn is_association(i: Item) -> ItemResult {
      Ok(coll::Sized::try_from(i)
          .map(|s| matches!(s, coll::Sized::Associative(_)))
          .unwrap_or(false)
          .into())
  }

  pub fn is_set(i: Item) -> ItemResult {
      Ok(coll::Sized::try_from(i)
          .map(|s| matches!(s, coll::Sized::Set(_)))
          .unwrap_or(false)
          .into())
  }

  pub fn is_odd(i: Item) -> ItemResult {
      let i = Int::try_from(i)?;
      Ok(Item::from(i & 1 == 1))
  }

  pub fn is_even(i: Item) -> ItemResult {
      let i = Int::try_from(i)?;
      Ok(Item::from(i & 1 == 0))
  }

  pub fn decide(mut env: Environment) -> Future<Environment> {
      let mut clauses = coll::List::try_from(env.pop()).unwrap();
      let clauses_data = coll::Arc::make_mut(&mut clauses);
      let clause = clauses_data.pop_front();

      if let Some(clause) = clause {
          let clause: Result<coll::List, Error> = clause.try_into();
          match clause {
              Ok(mut clause) => {
                  if clause.len() != 2 {
                      env.push(Error::list_count(2).into()).into()
                  } else {
                      let clause_data = clause.make_mut();
                      let test: Result<coll::List, Error> = clause_data
                          .pop_front()
                          .ok_or(Error::list_count(2))
                          .and_then(|i| i.try_into());
                      let expr: Result<coll::List, Error> = clause_data
                          .pop_front()
                          .ok_or(Error::list_count(2))
                          .and_then(|i| i.try_into());

                      match (test, expr) {
                          (Ok(test), Ok(expr)) => {
                              // construct if
                              let testp = coll::List::from_iter([Item::from(test), "shield".into()]);
                              let elsep =
                                  coll::List::from_iter([Item::from(clauses), "decide".into()]);
                              let newexpr = coll::List::from_iter([
                                  Item::from(testp),
                                  expr.into(),
                                  elsep.into(),
                                  "if".into(),
                              ]);
                              env.pop_expr();
                              env.append_program(newexpr).into()
                          }
                          (Err(test), _) => env.push(test.into()).into(),
                          (_, Err(expr)) => env.push(expr.into()).into(),
                      }
                  }
              }
              Err(e) => env.push(e.into()).into(),
          }
      } else {
          // clauses empty, return nothing
          env.pop_expr();
          env.push(Item::default()).into()
      }
  }

  pub fn read(mut env: Environment) -> Future<Environment> {
      let s = String::try_from(env.pop()).unwrap();
      let parsed = serialize::parse(s);
      let r = match parsed {
          Ok(l) => {
              env.pop_expr();
              l.into()
          }
          Err(e) => e.into(),
      };
      env.push(r).into()
  }

  pub fn emit(i: Item) -> ItemResult {
      Ok(Item::Dispenser(coll::Dispenser::Sized(
          coll::Sized::String(serialize::emit(&i)),
      )))
  }

  pub fn autoformat(i: Item) -> ItemResult {
      let s = String::try_from(i)?;
      Ok(Item::Dispenser(coll::Dispenser::Sized(
          coll::Sized::String(serialize::auto_format(s.as_str(), 20, 80)),
      )))
  }

  fn check_type(i: &Item, w: Word) -> Result<(), Error> {
      match (w, i) {
          (w, _) if w == *S_ITEM => Ok(()),
          (w, Item::Dispenser(_) | Item::Receptacle(_)) if w == *S_DISPENSER => Ok(()),
          (w, Item::Receptacle(_) | Item::Dispenser(_)) if w == *S_RECEPTACLE => Ok(()),
          (w, Item::Int(_)) if w == *S_INTEGER || w == *S_NUMBER => Ok(()),
          (w, Item::Float(_)) if w == *S_FLOAT || w == *S_NUMBER => Ok(()),
          // TODO: also handle cases where bytes/string is a list
          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(_))),
          ) if w == *S_BYTES || w == *S_ORDERED => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::String(_))),
          ) if w == *S_STRING => Ok(()),
          (w, Item::Word(_)) if w == *S_WORD => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Out(_))
              | Item::Dispenser(coll::Dispenser::Tunnel(_))
              | Item::Receptacle(coll::Receptacle::Tunnel(_))
              | Item::Receptacle(coll::Receptacle::In(_)),
          ) if w == *S_PIPE => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::List(_))),
          ) if w == *S_LIST || w == *S_PROGRAM => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(_)))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Associative(_))),
          ) if w == *S_ASSOC => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
                  assoc::Associative::Error(_),
              )))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Associative(
                  assoc::Associative::Error(_),
              ))),
          ) if w == *S_ERROR => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(_))
              | Item::Receptacle(coll::Receptacle::Sized(_)),
          ) if w == *S_SIZED || w == *S_ORDERED => Ok(()),

          (
              w,
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
                  assoc::Associative::Env(_),
              )))
              | Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Associative(
                  assoc::Associative::Env(_),
              ))),
          ) if w == *S_ENVIRONMENT => Ok(()),
          (w, i) => {
              //println!("Type check failed! wanted {} got {:?}", w, i);
              Err(Error::expected(&w, i.clone()))
          }
      }
  }

  fn check_stack_depth(env: &Environment, min_depth: usize) -> Result<(), Error> {
      //println!("Checking stack has at least {} items", min_depth);
      if env.stack.len() < min_depth {
          Err(Error::stack_underflow())
      } else {
          Ok(())
      }
  }

  fn check_input_spec(spec: &coll::List, env: &Environment) -> Result<(), Error> {
      let specs: coll::List = spec
          .front()
          .ok_or_else(|| Error::expected("specs", Default::default()))
          .and_then(|i| i.clone().try_into())?;

      check_stack_depth(env, specs.len())?;
      let indexes = Range {
          start: 0,
          end: specs.len(),
      };

      indexes.into_iter().try_for_each(|i| {
          let item = env.stack.get(i).unwrap();
          let spec = specs.get(i).unwrap();

          match spec {
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::List(named))) => {
                  match named.get(0).unwrap() {
                      Item::Word(w) => check_type(item, *w),
                      i => Err(Error::expected("list", i.clone())),
                  }
              }
              Item::Word(w) => check_type(item, *w),
              // the type might happen to also be a defined
              // word, like 'association'
              i => Err(Error::expected("list", i.clone())),
          }
      })
  }

  pub fn eval_step(mut env: Environment) -> Future<Environment> {
      //println!("{:?}", env);
      let next_item = env.program.front();

      if let Some(val) = next_item {
          match val {
              Item::Word(word) => {
                  if let Some(dfn) = env.dictionary.get(word) {
                      {
                          if let Some(spec) = &dfn.spec {
                              if let Err(e) = check_input_spec(spec, &env) {
                                  env = env.push(e.into());
                                  return env.into();
                              }
                          } else {
                              println!("No spec for {}!", word);
                          }
                          match &dfn.definition {
                              dict::Definition::Axiom(a) => (*a)(env),
                              dict::Definition::Derived(d) => {
                                  let items = d.clone();
                                  env.pop_expr();
                                  env.append_program(items).into()
                              }
                          }
                      }
                  } else {
                      let w = *word;
                      env.push(Error::undefined(w).into()).into()
                  }
              }
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
                  assoc::Associative::DictEntry(entry),
              ))) => {
                  if let Some(spec) = &entry.spec {
                      if let Err(e) = check_input_spec(spec, &env) {
                          env = env.push(e.into());
                          return env.into();
                      }
                  }
                  //let expr = coll::Arc::make_mut(&mut env.program);
                  //let e: dict::Entry = expr.front().clone().unwrap().try_into().unwrap();
                  let e: dict::Entry = env.program.front().unwrap().clone().try_into().unwrap();
                  match e.definition {
                      dict::Definition::Axiom(builtin) => (builtin)(env),
                      dict::Definition::Derived(d) => {
                          let d = d.clone();
                          env.pop_expr();
                          env.append_program(d).into()
                      }
                  }
              }
              _ => {
                  // not a word, just push onto stack
                  let i = env.pop_expr();
                  env.push(i).into()
              }
          }
      } else {
          env.push(Error::short_list(1).into()).into()
      }
  }

  fn reverse(i: Item) -> ItemResult {
      let s = coll::Sized::try_from(i)?;
      match s {
          coll::Sized::List(l) => Ok(coll::List::from_iter(l.inner().into_iter().rev()).into()),
          coll::Sized::String(s) => Ok(s.chars().rev().collect::<String>().into()),
          coll::Sized::Bytes(b) => Ok(b.into_iter().rev().collect::<Vec<u8>>().into()),
          s => Err(Error::expected("ordered", s.into())),
      }
  }

  fn encode_string(i: Item) -> ItemResult {
      Ok(String::try_from(i)?.as_bytes().to_vec().into())
  }

  fn string(i: Item) -> ItemResult {
      match i {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(b))) => {
              Ok(Item::Dispenser(coll::Dispenser::Sized(
                  coll::Sized::String(std::str::from_utf8(&b).unwrap().to_string()),
              )))
          }
          Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(b))) => {
              Ok(Item::Receptacle(coll::Receptacle::Sized(
                  coll::Sized::String(std::str::from_utf8(&b).unwrap().to_string()),
              )))
          }
          i => Ok(Item::Dispenser(coll::Dispenser::Sized(
              coll::Sized::String(serialize::emit(&i)),
          ))),
      }
  }

  fn get_error(env: &Environment) -> Option<Error> {
      env.stack.front().and_then(|i| match i {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Error(e),
          ))) => Some(e.clone()),
          Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Associative(
              assoc::Associative::Error(e),
          ))) => Some(e.clone()),
          _ => None,
      })
  }

  fn unwind(mut env: Environment) -> Environment {
      let err = env.pop();
      let w: &Item = &"handle".into();

      let err = match err {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Error(mut e),
          ))) => {
              let mut next = env.program.front();
              let mut unwound = Vec::<Item>::new();
              while next.is_some() && next.unwrap() != w {
                  let i = env.pop_expr();
                  unwound.push(i);
                  next = env.program.front();
              }
              if next.is_some() {
                  env.pop_expr();
              }
              // set the is_handled bit
              e.is_handled = true;
              let em = coll::Arc::make_mut(&mut e.data);
              em.insert("unwound".into(), coll::List::from_iter(unwound).into());
              e.into()
          }
          i => i,
      };
      env = env.push(err);
      env
  }

  pub async fn eval(mut env: Environment) -> Environment {
      loop {
          if let Some(err) = get_error(&env) {
              if !err.is_handled {
                  env = unwind(env); // TODO: this should be done in eval_step
              };
          }
          if !env.program.is_empty() {
              env = eval_step(env).await;
          } else {
              break;
          }
      }
      env
  }

  pub fn standard_env(program: Option<coll::List>, stack: Option<coll::List>) -> Environment {
      let prog_expr = match program {
          Some(p) => Stack::from(p),
          _ => Stack::default(),
      };

      let env = Environment {
          stack: stack.unwrap_or_default(),
          program: prog_expr,
          dictionary: coll::Arc::wrap(HashMap::<Word, dict::Entry>::new()),
      };
      add_standard_dictionary(env)
  }

  fn environment(p: Item) -> ItemResult {
      Environment::try_from(p).map(|e| e.into())
  }

  pub fn eval_step_outer(mut env: Environment) -> Future<Environment> {
      let tos = env.pop();
      let inner_env = Environment::try_from(tos);

      match inner_env {
          Ok(inner) => {
              env.pop_expr();
              if inner.program.is_empty() {
                  Box::pin(async move { env.push(Item::default()) })
              } else {
                  Box::pin(eval_step(inner).map(|inner_next| env.push(inner_next.into())))
              }
          }
          Err(e) => env.push(e.into()).into(),
      }
  }

  pub fn evaluate(mut env: Environment) -> Future<Environment> {
      let tos = env.pop();
      let inner_env = Environment::try_from(tos);
      match inner_env {
          Ok(inner) => Box::pin(eval(inner).map(|inner_done| {
              env.pop_expr();
              env.push(inner_done.into())
          })),
          Err(e) => env.push(e.into()).into(),
      }
  }

  pub fn identity(mut env: Environment) -> Future<Environment> {
      env.pop_expr();
      env.into()
  }

  pub fn dictionary(mut env: Environment) -> Future<Environment> {
      let d = env.dictionary.clone();
      env.pop_expr();
      env.push(d.into()).into()
  }

  fn sqrt(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::Int(i.sqrt())),
          Item::Float(f) => Ok(Item::Float(f.sqrt())),
          i => number_type_error(i),
      }
  }

  fn abs(i: Item) -> ItemResult {
      match i {
          Item::Int(i) => Ok(Item::Int(i.abs())),
          Item::Float(f) => Ok(Item::Float(f.abs())),
          i => number_type_error(i),
      }
  }

  fn handle(i: Item) -> ItemResult {
      match i {
          Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Associative(
              assoc::Associative::Error(mut e),
          ))) => Ok({
              e.is_handled = true;
              e.into()
          }),
          i => Ok(i),
      }
  }

  // fn inscription(env: &mut Environment) -> Result<(Word, dict::Entry), Error> {
  //     let d = env.pop();
  //     let mut wl = coll::List::try_from(env.pop())?;
  //     let w1 = coll::Arc::make_mut(&mut wl).pop_front();
  //     let x = w1.ok_or(Error::short_list(1))?;
  //     let w = Word::try_from(x.clone())?;
  //     Ok((w, dict::Entry::try_from(d)?))
  // }

  // pub fn inscribe(mut env: Environment) -> Environment {
  //     let r = inscription(&mut env);
  //     match r {
  //         Ok((w, def)) => {
  //             let d = coll::Arc::make_mut(&mut env.dictionary);
  //             d.insert(assoc::KeyItem::Word(w), Item::Entry(def));
  //             env
  //         }
  //         Err(e) => env.push(e.into()),
  //     }
  // }

  // make 'yes' a word that doesn't have to be quoted, just pushes
  // itself onto the stack.
  pub fn yes(mut env: Environment) -> Future<Environment> {
      let t = env.pop_expr();
      env.push(t).into()
  }

  pub fn fail(e: Item) -> ItemResult {
      let mut e: Error = e.try_into().unwrap();
      e.is_handled = false;
      Err(e)
  }

  // fn normalize_dictionary(mut d: dict::Dictionary) -> Result<dict::Dictionary, Error> {
  //     let dm = coll::Arc::make_mut(&mut d);
  //     for (k, v) in dm.iter_mut() {
  //         match v {
  //             Item::Assoc(a) => {
  //                 let aa = a.clone();
  //                 let (aa, _) = aa.insert("word".into(), Item::try_from(k.clone()).unwrap());
  //                 *v = Item::Entry(aa.try_into()?)
  //             }
  //             Item::List(l) => {
  //                 let a: assoc::Associative = l.clone().try_into()?;
  //                 let (a, _) = a.insert("word".into(), Item::try_from(k.clone()).unwrap());
  //                 *v = Item::Entry(a.try_into()?)
  //             }
  //             Item::Entry(_) => {}
  //             _ => {
  //                 return Err(Error::expected("dictionary"));
  //             }
  //         }
  //     }
  //     Ok(d)
  // }

  pub fn redefine(mut env: Environment) -> Future<Environment> {
      let d = dict::Dictionary::try_from(env.pop());
      match d {
          Ok(d) => {
              env.dictionary = d;
              env.pop_expr();
              env
          }
          Err(e) => {
              env = env.push(e.into());
              env
          }
      }
      .into()
  }

  // Takes an inner environment from the top of the stack, and spawns a
  // tokio task to evaluate that environment.
  pub fn animate(mut env: Environment) -> Future<Environment> {
      let tos = env.pop();
      let inner_env = Environment::try_from(tos);
      match inner_env {
          Ok(inner) => {
              env.pop_expr();
              tokio::spawn(async move { eval(inner).await });
              env.into()
          }
          Err(e) => env.push(e.into()).into(),
      }
  }
  fn xor_(i: Bytes, j: Bytes) -> Bytes {
      let len = std::cmp::max(i.len(), j.len());
      let mut result = Vec::with_capacity(len);
      for (byte_i, byte_j) in i
          .iter()
          .chain(std::iter::repeat(&0).take(len - i.len()))
          .zip(j.iter().chain(std::iter::repeat(&0).take(len - j.len())))
      {
          result.push(byte_i ^ byte_j);
      }
      result
  }
  pub fn xor(i: Item, j: Item) -> ItemResult {
      match (i, j) {
          (Item::Int(i), Item::Int(j)) => Ok(Item::Int(i ^ j)),
          (
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(i))),
              Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(j))),
          ) => Ok(xor_(i, j).into()),
          (
              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(i))),
              Item::Receptacle(coll::Receptacle::Sized(coll::Sized::Bytes(j))),
          ) => Ok(xor_(i, j).into()),
          (i, j) => Err(Error::expected("integers", pair(i, j))),
      }
  }

  pub fn inspect(i: Item) -> ItemResult {
      let s = format!("{:?}", i);
      Ok(Item::Dispenser(coll::Dispenser::Sized(
          coll::Sized::String(s),
      )))
  }

  pub fn timestamps(mut env: Environment) -> Future<Environment> {
      env.pop_expr();
      env.push(Item::Dispenser(coll::Dispenser::Out(pipes::Out::Time)))
          .into()
  }

  pub fn standard(mut env: Environment) -> Future<Environment> {
      env.pop_expr();
      env.push(Item::Dispenser(coll::Dispenser::Tunnel(
          pipes::Tunnel::Standard,
      )))
      .into()
  }

  pub fn set(i: Item) -> ItemResult {
      coll::Set::try_from(i).map(|s| Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Set(s))))
  }

  pub fn compare(i: Item, j: Item) -> ItemResult {
      let ki = assoc::KeyItem::try_from(i)?;
      let kj = assoc::KeyItem::try_from(j)?;
      match ki.partial_cmp(&kj) {
          Some(std::cmp::Ordering::Less) => Ok("less".into()),
          Some(std::cmp::Ordering::Equal) => Ok("equal".into()),
          Some(std::cmp::Ordering::Greater) => Ok("greater".into()),
          None => Err(Error::expected("comparable", pair(ki.into(), kj.into()))),
      }
  }

  fn as_pair(i: Item) -> Result<(Item, assoc::KeyItem), Error> {
      let mut i = coll::List::try_from(i)?;
      let im = i.make_mut();
      let j = im.pop_front().ok_or(Error::short_list(1))?;
      let k = im
          .pop_front()
          .ok_or(Error::short_list(2))
          .and_then(assoc::KeyItem::try_from)?;
      Ok((j, k))
  }

  pub fn sort_by_key(i: Item) -> ItemResult {
      let l = coll::List::try_from(i)?;
      let it = l.inner().into_iter().map(as_pair);
      let mut it = it.collect::<Result<Vec<(Item, assoc::KeyItem)>, Error>>()?;
      it.sort_unstable_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Less));
      Ok(coll::List::from_iter(it.into_iter().map(|(k, _)| k)).into())
  }

  fn slice(arr: Item, start: Item, end: Item) -> ItemResult {
      //println!("Start: {:?}, End: {:?}", start, end);
      let arr = coll::Sized::try_from(arr)?;
      let mut start = Int::try_from(start)?;
      let mut end = Int::try_from(end)?;
      if start < 0 {
          start += arr.len() as i64;
      }
      if end <= 0 {
          end += arr.len() as i64;
      }
      if start < 0 {
          return Err(Error::negative(start));
      }
      if end < 0 {
          return Err(Error::negative(end));
      }
      if start > end {
          return Err(Error::create(
              crate::types::wrap("<=".into()),
              "invalid index range",
              Some(pair(start.into(), end.into())),
          ));
      }
      match arr {
          coll::Sized::Bytes(arr) => Ok(arr
              .get(start as usize..end as usize)
              .map(|a| a.to_vec())
              .into()),
          coll::Sized::String(arr) => Ok(arr
              .get(start as usize..end as usize)
              .map(|a| a.to_string())
              .into()),
          coll::Sized::List(arr) => {
              let owned_subset: VecDeque<Item> = arr
                  .iter()
                  .skip(start as usize)
                  .take(end as usize - start as usize)
                  .cloned()
                  .collect();
              Ok(coll::List::from(owned_subset).into())
          }
          i => Err(Error::expected("ordered", i.into())),
      }
  }

  fn empty(s: Item) -> ItemResult {
      let s = coll::Sized::try_from(s)?;
      Ok(s.empty().into())
  }

  fn format(fstr: Item, items: Item) -> ItemResult {
      let fstr = String::try_from(fstr)?;
      let items = coll::List::try_from(items)?;
      let strings = items
          .inner()
          .into_iter()
          .map(String::try_from)
          .collect::<Result<Vec<String>, Error>>()?;
      Ok(dynfmt::SimpleCurlyFormat
          .format(fstr.as_str(), strings)?
          .deref()
          .to_string()
          .into())
  }

  fn decode_json(s: Item) -> ItemResult {
      let s = String::try_from(s)?;
      Ok(serde_json::from_str::<Item>(s.as_str())?)
  }

  fn encode_json(i: Item) -> ItemResult {
      Ok(Item::from(serde_json::to_string(&i)?))
  }
#+end_src
*** Top level execution
We'll define the main module which reads input for the kcats
interpreter process, and prints output.

We'll also define how to run unit tests.
#+begin_src rust :tangle src/main.rs :mkdirp yes
  mod axiom;
  mod crypto;
  mod pipes;
  mod serialize;
  mod types;

  use crate::types::{environment::Environment, error};
  use std::io::{self, BufRead, Read, Write};
  use std::sync::Arc;

  fn print_result(env: Environment) {
      if env.program.is_empty() {
          println!(
              "{}",
              serialize::auto_format(serialize::emit_all(&env.stack).as_str(), 20, 80)
          );
      } else {
          println!(
              "stack: {}\nprogram: {}",
              serialize::auto_format(serialize::emit_all(&env.stack).as_str(), 20, 80),
              serialize::auto_format(serialize::emit_all(&env.program).as_str(), 20, 80)
          )
      }
  }

  fn get_stdin() -> String {
      let mut buf = String::new();
      for line in io::stdin().lock().lines() {
          buf.push_str(&line.unwrap());
          buf.push('\n');
      }
      buf
  }

  // A function that takes a handle to stdin. It reads a length from
  // stdin, then reads that many bytes and returns a string.
  async fn read_input() -> Option<String> {
      //spawn a thread to read from stdin
      //println!("Reading input");
      tokio::spawn(async move {
          let mut stdin = io::stdin().lock();
          let mut buf = String::new();
          if let Err(e) = stdin.read_line(&mut buf) {
              println!("Error reading content length {:?}", e);
              return None;
          }
          // parse an integer from buf
          let read_len = buf.trim();
          //println!("Read length {}", read_len);
          let len = read_len.parse::<usize>().unwrap_or_default();
          if len == 0 {
              return None;
          }
          // read len bytes from stdin
          let mut buf = vec![0; len];
          stdin.read_exact(&mut buf).unwrap();

          // convert the bytes to a string
          Some(String::from_utf8(buf).unwrap())
      })
      .await
      .unwrap()
  }

  async fn print_with_length(env: &Environment) {
      let result = serialize::auto_format(serialize::emit_all(&env.stack).as_str(), 20, 80);

      // first print the length of the result
      println!("{}\n{}", result.len(), result);
  }

  async fn print(env: &Environment) {
      let result = serialize::auto_format(serialize::emit_all(&env.stack).as_str(), 20, 80);
      println!("{}", result);
  }

  // a function that takes an env, and an input string. Parses the
  // string, if it parses, returns the env with the input added to the
  // program. Otherwise returns Error.
  fn parse_input(mut env: Environment, input: String) -> Result<Environment, error::Error> {
      let mut parsed = serialize::parse(input)?;
      let expr = Arc::make_mut(&mut env.program);
      expr.extend(Arc::make_mut(&mut parsed).drain(..));
      Ok(env)
  }

  //It converts the bytes to a
  // string, and then evaluates that string as a kcats program. It then
  // prints the length of the result, and then the result itself.
  async fn interactive_mode() {
      let mut env = axiom::standard_env(None, None);

      loop {
          if let Some(program) = read_input().await {
              match parse_input(env, program) {
                  Ok(parsed_env) => {
                      env = axiom::eval(parsed_env).await;
                      print_with_length(&env).await;
                  }
                  Err(e) => {
                      println!("Error: {:?}", e);
                      break;
                  }
              }
          } else {
              //println!("Blank input received, exiting");
              continue;
          }
      }
  }

  async fn repl() {
      let mut env = axiom::standard_env(None, None);

      loop {
          // Print the prompt and flush it to stdout immediately
          print!("kcats> ");
          io::stdout().flush().unwrap();

          // Read a line from stdin
          let mut line = String::new();
          io::stdin().read_line(&mut line).unwrap();

          // Check if the input is empty, if so, continue to the next loop iteration
          if line.trim().is_empty() {
              continue;
          }

          // Parse and evaluate the input, then print the result
          match parse_input(env, line) {
              Ok(parsed_env) => {
                  env = axiom::eval(parsed_env).await;
                  print(&env).await;
              }
              Err(e) => {
                  println!("Error: {:?}", e);
                  break;
              }
          }
      }
  }

  async fn read_eval_print(program: String) {
      // otherwise, read from stdin
      match parse_input(axiom::standard_env(None, None), program) {
          Ok(env) => {
              print_result(axiom::eval(env).await);
          }
          Err(e) => {
              println!("Error parsing input: {:?}", e);
          }
      }
  }

  #[tokio::main]
  async fn main() {
      // read command line options, to look for -i switch
      let args: Vec<String> = std::env::args().collect();
      // if args contains "-i", read via handle_stdin
      if args.contains(&"-i".to_string()) {
          interactive_mode().await;
      } else if args.contains(&"-r".to_string()) {
          repl().await;
      } else if args.contains(&"-f".to_string()) {
          let filename = args.get(2).unwrap();
          let mut file = std::fs::File::open(filename).unwrap();
          let mut buf = String::new();
          file.read_to_string(&mut buf).unwrap();
          read_eval_print(buf).await;
      } else if args.contains(&"-p".to_string()) {
          let program = args.get(2).unwrap();
          read_eval_print(program.clone()).await;
      } else {
          // otherwise, read from stdin
          read_eval_print(get_stdin()).await;
      }
  }

  #[cfg(test)]
  mod tests {
      // Note this useful idiom: importing names from outer (for mod tests) scope.
      use super::error::Error;
      use super::*;
      use crate::types::collection as coll;
      use crate::types::{Item, Word};
      use internment::Intern;
      use std::borrow::Borrow;
      use test_case::test_case;

      pub fn get_item(i: Item, index: usize) -> Option<Item> {
          coll::List::try_from(i)
              .ok()
              .and_then(|l| l.get(index).cloned())
      }

      #[tokio::main]
      async fn test_example(
          mut prog_env: Environment,
          program: coll::List,
          expected: coll::List,
      ) -> Option<Error> {
          let mut exp_env = prog_env.clone();
          prog_env = prog_env.append_program(program.clone());
          exp_env = exp_env.append_program(expected.clone());

          let p_fut = tokio::spawn(async move { axiom::eval(prog_env).await });

          let exp_fut = tokio::spawn(async move { axiom::eval(exp_env).await });
          let (prog_env, exp_env) = tokio::join!(p_fut, exp_fut);
          let prog_env = prog_env.unwrap();
          let exp_env = exp_env.unwrap();

          if prog_env.stack == exp_env.stack {
              println!(
                  "Nice expected {} got {}",
                  serialize::emit_all(exp_env.stack.borrow()),
                  serialize::emit_all(prog_env.stack.borrow())
              );
              None
          } else {
              println!(
                  "uh oh expected {} got {}",
                  serialize::emit_all(exp_env.stack.borrow()),
                  serialize::emit_all(prog_env.stack.borrow())
              );
              // println!(
              //     "Debug: expected {:?} got {:?}",
              //     exp_env.stack, prog_env.stack
              // );
              Some(Error::test_assertion(program, expected, prog_env.stack))
          }
      }

      fn test_word(standard_env: Environment, w: Word) -> Vec<Error> {
          if let Some(d) = standard_env.dictionary.get(&w) {
              d.examples
                  .clone()
                  .unwrap()
                  .iter()
                  .filter_map(|ex| {
                      let p = coll::List::try_from(get_item(ex.clone(), 0).unwrap());
                      let exp = coll::List::try_from(get_item(ex.clone(), 1).unwrap());
                      match (p, exp) {
                          (Ok(p), Ok(exp)) => {
                              test_example(standard_env.clone(), p.clone(), exp.clone())
                          }
                          (Err(e), _) => Some(e),
                          (_, Err(e)) => Some(e),
                      }
                  })
                  .collect::<Vec<Error>>()
          } else {
              println!("Empty!");
              Vec::new()
          }
      }

      #[test_case("+" ; "plus")]
      #[test_case("-" ; "minus")]
      #[test_case("=" ; "eq")]
      #[test_case(">" ; "gt")]
      #[test_case(">=" ; "gte")]
      #[test_case("<" ; "lt")]
      #[test_case("<=" ; "lte")]
      #[test_case("*" ; "mult")]
      #[test_case("/" ; "divide")]
      #[test_case("abs")]
      #[test_case("addmethod")]
      #[test_case("and")]
      #[test_case("any?" ; "is_any")]
      #[test_case("assemble")]
      #[test_case("assign")]
      #[test_case("association")]
      #[test_case("association?" ; "is_association")]
      #[test_case("bail")]
      #[test_case("bind")]
      #[test_case("binddown")]
      #[test_case("binddeep")]
      #[test_case("bits")]
      #[test_case("both?" ; "is_both")]
      #[test_case("branch")]
      #[test_case("breaker")]
      #[test_case("butlast")]
      #[test_case("bytes?" ; "is_bytes")]
      #[test_case("capture")]
      #[test_case("catcher")]
      #[test_case("ceiling")]
      #[test_case("clone")]
      #[test_case("clonedown")]
      #[test_case("clonedeep")]
      #[test_case("collect")]
      #[test_case("compare")]
      #[test_case("contains?" ; "contains")]
      #[test_case("count")]
      #[test_case("cram")]
      #[test_case("cut")]
      #[test_case("dec")]
      #[test_case("decide")]
      #[test_case("decodejson")]
      #[test_case("decorate")]
      #[test_case("decorated")]
      #[test_case("dip")]
      #[test_case("dipdown")]
      #[test_case("dipdeep")]
      #[test_case("dive")]
      #[test_case("divedown")]
      #[test_case("divedeep")]
      #[test_case("drop")]
      #[test_case("dropdown")]
      #[test_case("dropdeep")]
      #[test_case("dropper")]
      #[test_case("each")]
      #[test_case("emit")]
      #[test_case("ends?" ; "is_ends")]
      #[test_case("encode")]
      #[test_case("encodejson")]
      #[test_case("encodestring")]
      #[test_case("environment")]
      #[test_case("evaluate")]
      #[test_case("eval-step")]
      #[test_case("even?" ; "is_even")]
      #[test_case("evert")]
      #[test_case("every?" ; "is_every")]
      #[test_case("execute")]
      #[test_case("exp")]
      #[test_case("filter")]
      #[test_case("first")]
      #[test_case("float")]
      #[test_case("floor")]
      #[test_case("fold")]
      #[test_case("format")]
      #[test_case("functional")]
      #[test_case("future")]
      #[test_case("get")]
      #[test_case("generate")]
      #[test_case("group")]
      #[test_case("hashbytes")]
      #[test_case("if")]
      #[test_case("inc")]
      #[test_case("indexed")]
      #[test_case("inject")]
      #[test_case("inscribe")]
      #[test_case("into")]
      #[test_case("join")]
      #[test_case("joiner")]
      #[test_case("keep")]
      #[test_case("label")]
      #[test_case("let")]
      #[test_case("lingo")]
      #[test_case("list?" ; "is_list")]
      #[test_case("lookup")]
      #[test_case("loop")]
      #[test_case("log")]
      #[test_case("map")]
      #[test_case("max")]
      #[test_case("min")]
      #[test_case("mod")]
      #[test_case("not")]
      #[test_case("empty?" ; "is_empty")]
      #[test_case("number?" ; "is_number")]
      #[test_case("odd?" ; "is_odd")]
      #[test_case("or")]
      #[test_case("over")]
      #[test_case("pad")]
      #[test_case("pair?" ; "is_pair")]
      #[test_case("partition")]
      #[test_case("pipe?" ; "is_pipe")]
      #[test_case("put")]
      #[test_case("prepend")]
      #[test_case("primrec")]
      #[test_case("radix")]
      #[test_case("range")]
      #[test_case("recover")]
      #[test_case("recur")]
      #[test_case("repeat")]
      #[test_case("rest")]
      #[test_case("restore")]
      #[test_case("retry")]
      #[test_case("reverse")]
      #[test_case("round")]
      #[test_case("set")]
      #[test_case("set?" ; "is_set")]
      #[test_case("shield")]
      #[test_case("shielddown")]
      #[test_case("shielddowndown")]
      #[test_case("sink")]
      #[test_case("siphon")]
      #[test_case("skipper")]
      #[test_case("slice")]
      #[test_case("snapshot")]
      #[test_case("something?" ; "is_something")]
      #[test_case("sqrt")]
      #[test_case("starts?" ; "is_starts")]
      #[test_case("step")]
      #[test_case("string")]
      #[test_case("string?" ; "is_string")]
      #[test_case("spawn")]
      #[test_case("split")]
      #[test_case("swap")]
      #[test_case("swapdown")]
      #[test_case("take")]
      #[test_case("taker")]
      #[test_case("template")]
      #[test_case("times")]
      #[test_case("type")]
      #[test_case("unassign")]
      #[test_case("under")]
      #[test_case("until")]
      #[test_case("unwrap")]
      #[test_case("update")]
      #[test_case("value")]
      #[test_case("when")]
      #[test_case("while")]
      #[test_case("within?" ; "is_within")]
      #[test_case("word?")]
      #[test_case("wrap")]
      #[test_case("xor")]
      #[test_case("zero?" ; "is_zero")]
      #[test_case("zip")]
      fn test_lexicon(word: &str) {
          let e = axiom::standard_env(None, None);

          let r = test_word(e.clone(), Intern::new(word.to_string()));
          assert!(r.is_empty(), "{:?}", r);
      }
  }

  // if let (Item::List(program), Item::List(expected)) = (program, expected) {

  //     } else {
  //         Err(Error::from("Example should be a pair"))
  //     }

  // for ex in d.examples().iter() {
  //             let e = List::try_from(*ex).ok().unwrap();
  //             let p = List::try_from(*e.get(0).unwrap()).ok().unwrap();
  //             let exp = List::try_from(*e.get(1).unwrap()).ok().unwrap();

  //             test_example(axiom::standard_env.clone(), w, p,exp)
  //         }.retain(|i| i.is_some()).collect::<Vec<Error>>()
#+end_src
*** Pipes (input/output)
Kcats will confine all i/o to pipes. You can put values into pipes and
they emerge elsewhere. Words that act on pipes are the only ones that
can be impure. Everything else is a value.
***** Basic Types
The basic pipe contracts.
#+begin_src rust :tangle src/pipes.rs :mkdirp yes
  use crate::types::collection as coll;
  use crate::types::error::Error;
  use crate::types::{self, Item};
  use std::sync::Arc;
  use tokio::sync::RwLock;

  use futures::executor;
  pub mod channel;
  pub mod db;
  pub mod fs;
  pub mod net;
  pub mod standard;
  pub mod time;

  #[derive(Debug, Clone)]
  pub enum In {
      StaticFile(Arc<RwLock<fs::StaticFile>>),
      Socket(Arc<RwLock<net::Socket>>),
      Handoff(channel::Handoff<Item>),
      Standard,
  }

  impl PartialEq for In {
      fn eq(&self, other: &Self) -> bool {
          match (self, other) {
              (In::StaticFile(s1), In::StaticFile(s2)) => Arc::ptr_eq(s1, s2),
              (In::Socket(s1), In::Socket(s2)) => Arc::ptr_eq(s1, s2),
              (In::Handoff(h1), In::Handoff(h2)) => h1 == h2,
              _ => false,
          }
      }
  }

  #[derive(Debug, Clone)]
  pub enum Out {
      StaticFile(Arc<RwLock<fs::StaticFile>>),
      Socket(Arc<RwLock<net::Socket>>),
      ServerSocket(Arc<RwLock<net::ServerSocket>>),
      Handoff(channel::Handoff<Item>),
      Timer(channel::Timer<Item>),
      Time,
      Standard,
  }

  impl PartialEq for Out {
      fn eq(&self, other: &Self) -> bool {
          match (self, other) {
              (Out::StaticFile(s1), Out::StaticFile(s2)) => Arc::ptr_eq(s1, s2),
              (Out::Socket(s1), Out::Socket(s2)) => Arc::ptr_eq(s1, s2),
              (Out::ServerSocket(s1), Out::ServerSocket(s2)) => Arc::ptr_eq(s1, s2),
              (Out::Handoff(h1), Out::Handoff(h2)) => h1 == h2,
              (Out::Time, Out::Time) => true,
              (Out::Standard, Out::Standard) => true,
              _ => false,
          }
      }
  }

  #[derive(Debug, Clone)]
  pub enum Tunnel {
      StaticFile(Arc<RwLock<fs::StaticFile>>),
      Socket(Arc<RwLock<net::Socket>>),
      Handoff(channel::Handoff<Item>),
      Standard,
  }

  impl PartialEq for Tunnel {
      fn eq(&self, other: &Self) -> bool {
          match (self, other) {
              (Tunnel::StaticFile(s1), Tunnel::StaticFile(s2)) => Arc::ptr_eq(s1, s2),
              (Tunnel::Socket(s1), Tunnel::Socket(s2)) => Arc::ptr_eq(s1, s2),
              (Tunnel::Handoff(h1), Tunnel::Handoff(h2)) => h1 == h2,
              (Tunnel::Standard, Tunnel::Standard) => true,
              _ => false,
          }
      }
  }

  impl From<Tunnel> for Out {
      fn from(t: Tunnel) -> Self {
          match t {
              Tunnel::StaticFile(f) => Out::StaticFile(f),
              Tunnel::Socket(s) => Out::Socket(s),
              Tunnel::Handoff(h) => Out::Handoff(h),
              Tunnel::Standard => Out::Standard,
          }
      }
  }

  impl From<Tunnel> for In {
      fn from(t: Tunnel) -> Self {
          match t {
              Tunnel::StaticFile(f) => In::StaticFile(f),
              Tunnel::Socket(s) => In::Socket(s),
              Tunnel::Handoff(h) => In::Handoff(h),
              Tunnel::Standard => In::Standard,
          }
      }
  }

  impl In {
      pub fn put(&mut self, i: Item) -> types::Future<Result<(), Error>> {
          match self {
              In::StaticFile(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.put(i).await })
              }
              In::Socket(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.put(i).await })
              }
              In::Handoff(ref mut h) => Box::pin(h.put(i)), //_ => Err(Error::expected("foo")),
              In::Standard => standard::put(i),
          }
      }
  }

  impl Tunnel {
      pub fn put(&mut self, i: Item) -> types::Future<Result<(), Error>> {
          match self {
              Tunnel::StaticFile(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.put(i).await })
              }
              Tunnel::Socket(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.put(i).await })
              }
              Tunnel::Handoff(ref mut h) => Box::pin(h.put(i)),
              Tunnel::Standard => standard::put(i),
          }
      }

      pub fn take(&mut self) -> types::Future<Result<Option<Item>, Error>> {
          match self {
              Tunnel::StaticFile(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.take().await })
              }
              Tunnel::Socket(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.take().await })
              }
              Tunnel::Handoff(ref mut h) => Box::pin(h.take()),
              Tunnel::Standard => standard::take(),
          }
      }
  }

  impl Out {
      pub fn take(&mut self) -> types::Future<Result<Option<Item>, Error>> {
          match self {
              Out::StaticFile(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.take().await })
              }
              Out::Socket(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.take().await })
              }
              Out::ServerSocket(f) => {
                  let f = f.clone();
                  Box::pin(async move { f.write().await.take().await })
              }
              Out::Handoff(ref mut h) => Box::pin(h.take()),
              Out::Timer(ref mut t) => Box::pin(t.take()),
              Out::Time => Box::pin(time::take()),
              Out::Standard => standard::take(),
          }
      }
  }

  impl crate::serialize::Display for In {
      fn representation(&self) -> Item {
          match self {
              In::StaticFile(f) => executor::block_on(async move { f.read().await.representation() }),
              In::Socket(f) => executor::block_on(async move { f.read().await.representation() }),
              In::Handoff(h) => h.representation(),
              In::Standard => standard::representation(),
          }
      }
  }

  impl crate::serialize::Display for Out {
      fn representation(&self) -> Item {
          match self {
              Out::StaticFile(f) => {
                  executor::block_on(async move { f.read().await.representation() })
              }
              Out::Socket(f) => executor::block_on(async move { f.read().await.representation() }),
              Out::ServerSocket(f) => {
                  executor::block_on(async move { f.read().await.representation() })
              }
              Out::Handoff(h) => h.representation(),
              Out::Timer(t) => t.representation(),
              Out::Time => time::representation(),
              Out::Standard => standard::representation(),
          }
      }
  }

  impl crate::serialize::Display for Tunnel {
      fn representation(&self) -> Item {
          match self {
              Tunnel::StaticFile(f) => {
                  executor::block_on(async move { f.read().await.representation() })
              }
              Tunnel::Socket(f) => executor::block_on(async move { f.read().await.representation() }),
              Tunnel::Handoff(h) => h.representation(),
              Tunnel::Standard => standard::representation(),
          }
      }
  }
  /* Pipes can be "closed", from either end to signal that either the
   ,* putter or taker has gone away. Sometimes the type of pipe
   ,* may not really support this concept but an implementation is
   ,* required.  For example, files. When you open a file for writing and
   ,* then "close" it, that doesn't really do anything. Rust doesn't have
   ,* an explicit file close. You have to drop the reference to it, which
   ,* in kcats you can do by popping the pipe off the stack. Rust will
   ,* clean up automatically, other impls might have to reference count.
   ,*
   ,* The contract here is as follows:
   ,* 1. After calling close, put on the pipe returns an error
   ,*
   ,* 2. After calling close, take on the pipe will return still-buffered
   ,* items (if the pipe has a buffer), but once buffer is exhausted it
   ,* will return error.
   ,*
   ,* 2. Errors cannot be put into a pipe (the taker can't distinguish
   ,* between io error and an error value). To work around this, wrap the
   ,* error value in a list to quote it. Putting error into a pipe will
   ,* return an io error.
   ,*
   ,* 3. Once closed pipes cannot be ever be put into again. closed? will always
   ,* return true thereafter.
   ,*
   ,* One use case that has to be handled specially is a file we've fully
   ,* read but later someone else might write more bytes to the end. Does
   ,* the pipe close when we reach EOF? I think we might need to support
   ,* both types (a type that closes when hitting eof and one that
   ,* doesn't). The former is the "normal" use case, which will be the
   ,* default.
   ,*
   ,* These two types are basically static vs dynamic content. Either all
   ,* the content is known now, or it isn't.
   ,*
  ,*/

  fn closed_error(on_take: bool) -> Error {
      Error::create(
          coll::List::from_iter([
              Item::from("close"),
              if on_take { "take" } else { "put" }.into(),
          ]),
          "attempt to use closed pipe",
          None,
      )
  }

  impl From<Tunnel> for Item {
      fn from(t: Tunnel) -> Self {
          Item::Dispenser(coll::Dispenser::Tunnel(t))
      }
  }

  impl From<Out> for Item {
      fn from(t: Out) -> Self {
          Item::Dispenser(coll::Dispenser::Out(t))
      }
  }

  impl From<In> for Item {
      fn from(t: In) -> Self {
          Item::Receptacle(coll::Receptacle::In(t))
      }
  }

  impl TryFrom<Item> for In {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Receptacle(coll::Receptacle::In(i)) => Ok(i),
              Item::Receptacle(coll::Receptacle::Tunnel(t)) => Ok(t.into()),
              Item::Dispenser(coll::Dispenser::Tunnel(t)) => Ok(t.into()),
              i => Err(Error::expected("pipe", i)),
          }
      }
  }

  impl TryFrom<Item> for Out {
      type Error = Error;
      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Dispenser(coll::Dispenser::Out(o)) => Ok(o),
              Item::Dispenser(coll::Dispenser::Tunnel(t)) => Ok(t.into()),
              Item::Receptacle(coll::Receptacle::Tunnel(t)) => Ok(t.into()),
              i => Err(Error::expected("pipe", i)),
          }
      }
  }
#+end_src
***** Files
How to interact with files on disk
#+begin_src rust :tangle src/pipes/fs.rs :mkdirp yes
  use crate::axiom::ItemResult;
  use crate::types::associative as assoc;
  use crate::types::error::Error;
  use crate::types::*;
  use std::future;
  use std::pin::Pin;
  use std::ptr;
  use std::sync::Arc;
  use tokio::fs::File;
  use tokio::io::{AsyncReadExt, AsyncWriteExt};
  use tokio::sync::RwLock;

  use super::closed_error;

  #[derive(Debug)]
  pub struct StaticFile {
      pub file: Option<File>,
      pub path: String,
  }

  impl PartialEq for StaticFile {
      fn eq(&self, other: &Self) -> bool {
          // Check if the 'file' fields of both structs are the same by reference
          ptr::eq(&self.file, &other.file)
      }
  }

  impl StaticFile {
      pub fn put<'a>(
          &'a mut self,
          i: Item,
      ) -> Pin<Box<dyn std::future::Future<Output = Result<(), Error>> + Send + 'a>> {
          match self.file.as_mut() {
              Some(f) => {
                  let b = Bytes::try_from(i);

                  match b {
                      Ok(bs) => Box::pin(async move { f.write_all(&bs).await.map_err(|e| e.into()) }),
                      Err(e) => Box::pin(future::ready(Err(e))),
                  }
              }
              None => Box::pin(future::ready(Err(closed_error(false)))),
          }
      }

      pub fn take<'a>(
          &'a mut self,
      ) -> Pin<Box<dyn std::future::Future<Output = Result<Option<Item>, Error>> + Send + 'a>> {
          match self.file.as_mut() {
              Some(f) => {
                  let mut bs = [0u8; 1024];
                  Box::pin(async move {
                      let ct = f.read(&mut bs).await?;
                      if ct == 0 {
                          // EOF, no more takes since it's static
                          Ok(None)
                      } else {
                          Ok(Some(bs[0..ct].to_vec().into()))
                      }
                  })
              }
              None => Box::pin(future::ready(Err(closed_error(false)))),
          }
      }
  }

  impl crate::serialize::Display for StaticFile {
      fn representation(&self) -> Item {
          assoc::Association::from_iter([
              ("type".into(), "tunnel".into()),
              (
                  "values".into(),
                  assoc::Association::from_iter([("type".into(), "bytes".into())]).into(),
              ),
              (
                  "to".into(),
                  assoc::Association::from_iter([("file".into(), self.path.clone().into())]).into(),
              ),
          ])
          .into()
      }
  }

  pub fn file_in(i: Item) -> ItemResult {
      let path = String::try_from(i)?;
      let file = std::fs::File::options()
          .read(true)
          .write(true)
          .create_new(true)
          .open(path.clone())?;
      Ok(super::In::StaticFile(Arc::new(RwLock::new(StaticFile {
          file: Some(File::from_std(file)),
          path,
      })))
      .into())
  }

  pub fn file_out(i: Item) -> ItemResult {
      let path = String::try_from(i)?;
      let file = std::fs::File::open(path.clone())?;
      Ok(super::Out::StaticFile(Arc::new(RwLock::new(StaticFile {
          file: Some(File::from_std(file)),
          path,
      })))
      .into())
  }

  impl From<StaticFile> for Item {
      fn from(f: StaticFile) -> Self {
          super::Out::StaticFile(Arc::new(RwLock::new(f))).into()
      }
  }
#+end_src
***** Network
How to interact with the network (TCP/IP sockets)
#+begin_src rust :tangle src/pipes/net.rs :mkdirp yes
  use crate::axiom::ItemResult;
  use crate::types::associative as assoc;
  use crate::types::error::Error;
  use crate::types::{self, wrap, Int, Item};
  use futures::future::FutureExt;
  use std::future::{self};
  use std::net::{Ipv4Addr, SocketAddrV4};
  use std::pin::Pin;
  use std::ptr;
  use std::str::FromStr;
  use std::sync::Arc;
  use tokio::io::{AsyncReadExt, AsyncWriteExt};
  use tokio::net::{TcpListener, TcpStream};
  use tokio::sync::RwLock;

  #[derive(Debug)]
  pub struct Socket {
      pub socket: TcpStream,
      pub addr: (String, u16),
  }

  impl PartialEq for Socket {
      fn eq(&self, other: &Self) -> bool {
          // Check if the 'socket' fields of both structs are the same by reference
          ptr::eq(&self.socket, &other.socket)
      }
  }

  impl Socket {
      pub fn put<'a>(
          &'a mut self,
          i: Item,
      ) -> Pin<Box<dyn std::future::Future<Output = Result<(), Error>> + Send + 'a>> {
          //println!("Putting {:?}", i);
          let b = types::Bytes::try_from(i);
          match b {
              Ok(bs) => {
                  Box::pin(async move { self.socket.write_all(&bs).await.map_err(|e| e.into()) })
              }
              Err(e) => Box::pin(future::ready(Err(e))),
          }
      }

      pub fn take<'a>(
          &'a mut self,
      ) -> Pin<Box<dyn std::future::Future<Output = Result<Option<Item>, Error>> + Send + 'a>> {
          let mut bs = [0u8; 1024];
          Box::pin(async move {
              let n = self.socket.read(&mut bs).await?;
              if n == 0 {
                  Ok(None)
              } else {
                  Ok(Some(bs[..n].to_vec().into()))
              }
          })
      }
  }

  impl crate::serialize::Display for Socket {
      fn representation(&self) -> Item {
          assoc::Association::from_iter([
              ("type".into(), "tunnel".into()),
              ("realm".into(), "tcp".into()),
              ("address".into(), self.addr.0.to_string().into()),
              ("port".into(), self.addr.1.to_string().into()),
          ])
          .into()
      }
  }

  // Server sockets
  #[derive(Debug)]
  pub struct ServerSocket {
      pub socket: TcpListener,
  }

  impl PartialEq for ServerSocket {
      fn eq(&self, other: &Self) -> bool {
          // Check if the 'socket' fields of both structs are the same by reference
          ptr::eq(&self.socket, &other.socket)
      }
  }

  impl ServerSocket {
      pub fn take<'a>(
          &'a mut self,
      ) -> Pin<Box<dyn std::future::Future<Output = Result<Option<Item>, Error>> + Send + 'a>> {
          Box::pin(async move {
              let (socket, addr) = self.socket.accept().await?;

              Ok(Some(
                  super::Tunnel::Socket(Arc::new(RwLock::new(Socket {
                      socket,
                      addr: (addr.ip().to_string(), addr.port()),
                  })))
                  .into(),
              ))
          })
      }
  }

  impl crate::serialize::Display for ServerSocket {
      fn representation(&self) -> Item {
          assoc::Association::from_iter([
              ("type".into(), "pipe".into()),
              (
                  "serversocket".into(),
                  "todo: fix serversocket local addr async issue".into(), //Item::String(self.socket.lock().await.local_addr().unwrap().to_string()),
              ),
          ])
          .into()
      }
  }

  fn socket_addr(i: Item, j: Item) -> Result<SocketAddrV4, Error> {
      //println!("socket: {:?} {:?}", i, j);
      let addr = Ipv4Addr::from_str(String::try_from(j)?.as_str())?;
      let port = Int::try_from(i)? as u16;
      Ok(SocketAddrV4::new(addr, port))
  }

  fn host_addr(i: Item, j: Item) -> Result<(String, u16), Error> {
      //println!("socket: {:?} {:?}", i, j);
      let addr = String::try_from(j)?;
      let port = Int::try_from(i)? as u16;
      Ok((addr, port))
  }

  pub fn server_socket(i: Item, j: Item) -> types::Future<ItemResult> {
      match socket_addr(i, j) {
          Ok(addr) => {
              Box::pin(TcpListener::bind(addr).map(|l| {
                  Ok(super::Out::ServerSocket(Arc::new(RwLock::new(ServerSocket {
                      socket: l.unwrap(),
                  })))
                  .into())
              }))
          }
          Err(e) => Box::pin(future::ready(Err(e))),
      }
  }

  pub fn socket(i: Item, j: Item) -> types::Future<ItemResult> {
      match host_addr(i, j) {
          Ok(addr) => Box::pin(TcpStream::connect(addr.clone()).map(move |s| {
              Ok(super::Tunnel::Socket(Arc::new(RwLock::new(Socket {
                  socket: s.unwrap(),
                  addr,
              })))
              .into())
          })),
          Err(e) => Box::pin(future::ready(Err(e))),
      }
  }

  // pub fn server_socket(env: Environment) -> environment::Future {
  //     let addr = env.pop();

  //     let inner_env = Environment::try_from(tos);
  //     match inner_env {
  //         Ok(inner) => Box::pin(eval_step(inner).map(|inner_next| env.push(Item::Env(inner_next)))),
  //         Err(e) => env.push(Item::Error(e)).into(),
  //     }
  // }

  impl From<std::net::AddrParseError> for Error {
      fn from(err: std::net::AddrParseError) -> Error {
          Error::create(wrap("addrparse".into()), &err.to_string(), None)
      }
  }
#+end_src
***** Time
#+begin_src rust :tangle src/pipes/time.rs :mkdirp yes
  use crate::types::associative as assoc;
  use crate::types::error::Error;
  use crate::types::*;
  use std::{
      future,
      time::{SystemTime, UNIX_EPOCH},
  };

  pub fn take() -> Future<Result<Option<Item>, Error>> {
      let t = SystemTime::now()
          .duration_since(UNIX_EPOCH)
          .unwrap()
          .as_millis() as Int;
      Box::pin(future::ready(Ok(Some(Item::Int(t)))))
  }

  pub fn representation() -> Item {
      assoc::Association::from_iter([
          ("type".into(), "out".into()),
          ("from".into(), "systemtime".into()),
          (
              "values".into(),
              assoc::Association::from_iter([
                  ("type".into(), "integer".into()),
                  ("units".into(), "milliseconds".into()),
              ])
              .into(),
          ),
      ])
      .into()
  }
#+end_src
***** Standard in/out
#+begin_src rust :tangle src/pipes/standard.rs :mkdirp yes
  use crate::types::associative as assoc;
  use crate::types::error::Error;
  use crate::types::{self, *};
  use std::future;
  use std::io::{self, Read, Write};

  pub fn take() -> Future<Result<Option<Item>, Error>> {
      let mut buf = [0u8];
      let n = io::stdin().read(&mut buf);
      let f = match n {
          Ok(0) => Ok(None),
          Ok(n) => Ok(Some(buf[..n].to_vec().into())),
          Err(e) => Err(e.into()),
      };
      Box::pin(future::ready(f))
  }

  pub fn put(i: Item) -> types::Future<Result<(), Error>> {
      let bs = Bytes::try_from(i);
      match bs {
          Ok(bs) => {
              let f = io::stdout().write(&bs);
              Box::pin(future::ready(f.map_err(|e| e.into()).map(|_| ())))
          }
          Err(e) => Box::pin(future::ready(Err(e))),
      }
  }

  pub fn representation() -> Item {
      assoc::Association::from_iter([
          ("type".into(), "tunnel".into()),
          ("peer".into(), "standard".into()),
      ])
      .into()
  }
#+end_src
***** Channels
Implement the =handoff= type
#+begin_src rust :tangle src/pipes/channel.rs :mkdirp yes
  use crate::axiom;
  use crate::pipes;
  use crate::types::associative as assoc;
  use crate::types::collection as coll;
  use crate::types::environment::Environment;
  use crate::types::error;
  use crate::types::{self, Int, Item};
  use flume;
  use std::future;
  use std::ptr;
  use std::sync::atomic::{AtomicUsize, Ordering};
  use std::sync::Arc;
  use tokio::task::JoinHandle;
  use tokio::time::{sleep, Duration};

  #[derive(Debug, Clone)]
  // Use Option because we want to be able to drop senders/receivers to
  // close the channel
  pub struct Handoff<T> {
      pub receiver: Option<flume::Receiver<T>>,
      pub sender: Option<flume::Sender<T>>,
      pub bidirectional: bool,
      pub id: usize,
  }

  impl<T> PartialEq for Handoff<T> {
      fn eq(&self, other: &Self) -> bool {
          match (&self.receiver, &other.receiver, &self.sender, &other.sender) {
              (Some(sr), Some(or), Some(ss), Some(os)) => ptr::eq(&sr, &or) && ptr::eq(&ss, &os),
              _ => false,
          }
      }
  }

  static ID: AtomicUsize = AtomicUsize::new(0);

  impl Handoff<Item> {
      pub fn new(bidirectional: bool) -> Handoff<Item> {
          let (sender, receiver) = flume::bounded::<Item>(0);
          let id = ID.fetch_add(1, Ordering::Relaxed);
          Handoff::<Item> {
              sender: Some(sender),
              receiver: Some(receiver),
              bidirectional,
              id,
          }
      }

      pub fn put(&mut self, i: Item) -> types::Future<Result<(), error::Error>> {
          // println!(
          //     "Putting into channel: {} into {:?} on {:?}",
          //     i.clone(),
          //     self,
          //     thread::current().id()
          // );
          if !self.bidirectional {
              self.close_take()
          };
          if let Some(ch) = self.sender.clone() {
              if axiom::is_truthy(i.clone()) {
                  Box::pin(async move {
                      ch.send_async(i)
                          .await
                          .map_err(|_| pipes::closed_error(false))
                  })
              } else {
                  // If we're putting 'nothing', that indicates end of
                  // input, so we drop the sender.
                  self.close_put();
                  Box::pin(future::ready(Ok(())))
              }
          } else {
              Box::pin(future::ready(Err(pipes::closed_error(false))))
          }
      }

      pub fn take(&mut self) -> types::Future<Result<Option<Item>, error::Error>> {
          // println!(
          //     "Taking from channel: {:?} on {:?}",
          //     self,
          //     thread::current().id()
          // );
          if !self.bidirectional {
              self.close_put();
          }
          if let Some(ch) = self.receiver.clone() {
              Box::pin(async move { ch.recv_async().await.map(Some).or_else(|_| Ok(None)) })
          } else {
              Box::pin(future::ready(Ok(None)))
          }
      }

      pub fn close_take(&mut self) {
          if self.receiver.is_some() {
              //println!("Dropping receiver");
              self.receiver = None;
          }
      }

      pub fn close_put(&mut self) {
          if self.sender.is_some() {
              //println!("Dropping sender");
              self.sender = None;
          }
      }
  }

  impl crate::serialize::Display for Handoff<Item> {
      fn representation(&self) -> Item {
          let t = match (&self.sender, &self.receiver) {
              (Some(_), Some(_)) => "tunnel",
              (Some(_), None) => "in",
              (None, Some(_)) => "out",
              (None, None) => "closed",
          };
          assoc::Association::from_iter([
              ("type".into(), t.into()),
              ("handoff".into(), (self.id as Int).into()),
          ])
          .into()
      }
  }

  pub fn handoff(mut env: Environment) -> types::Future<Environment> {
      env.pop_expr();
      env.push(pipes::Tunnel::Handoff(Handoff::new(false)).into())
          .into()
  }

  impl From<flume::RecvError> for error::Error {
      fn from(_: flume::RecvError) -> Self {
          pipes::closed_error(false) // todo fix this
      }
  }

  impl From<flume::SendError<Item>> for error::Error {
      fn from(_: flume::SendError<Item>) -> Self {
          pipes::closed_error(false)
      }
  }

  enum ChannelOp<T> {
      Send(Arc<flume::Sender<T>>, usize, T),
      Receive(Arc<flume::Receiver<T>>, usize),
  }
  // Given a list of pipes (channels) on top of stack, use flume's
  // selector to choose the next ready pipe.  A pipe means it's a
  // receive, a pipe/item pair means it's a send.
  pub fn select(i: Item) -> axiom::ItemResult {
      let l = coll::List::try_from(i)?;
      let original = l.clone();

      //Create references out of any [pipe item] pairs
      let lr = l
          .inner()
          .into_iter()
          .enumerate()
          .map(move |(idx, i)| match i {
              Item::Dispenser(coll::Dispenser::Out(pipes::Out::Handoff(p))) => {
                  Ok(ChannelOp::Receive(Arc::new(p.receiver.unwrap()), idx))
              }
              Item::Dispenser(coll::Dispenser::Tunnel(pipes::Tunnel::Handoff(p))) => {
                  Ok(ChannelOp::Receive(Arc::new(p.receiver.unwrap()), idx))
              }
              // Handle timeout channels - start the timer and add receive op
              Item::Dispenser(coll::Dispenser::Out(pipes::Out::Timer(t))) => {
                  let mut t = t.clone();
                  t.start();
                  Ok(ChannelOp::Receive(Arc::new(t.receiver.unwrap()), idx))
              }
              i => {
                  let l = coll::List::try_from(i.clone())?;
                  let p = l.get(0);
                  let i = l.get(1);
                  match (p, i) {
                      (Some(p), Some(i)) => match (p, i) {
                          (Item::Receptacle(coll::Receptacle::In(pipes::In::Handoff(p))), i) => Ok(
                              ChannelOp::Send(Arc::new(p.sender.clone().unwrap()), idx, i.clone()),
                          ),
                          (
                              Item::Receptacle(coll::Receptacle::Tunnel(pipes::Tunnel::Handoff(p))),
                              i,
                          ) => Ok(ChannelOp::Send(
                              Arc::new(p.sender.clone().unwrap()),
                              idx,
                              i.clone(),
                          )),
                          (p, _i) => Err(error::Error::expected("handoff", p.clone())),
                      },
                      _ => Err(error::Error::short_list(2)),
                  }
              }
          })
          .collect::<Result<Vec<ChannelOp<Item>>, error::Error>>()?;

      let (res, idx) = {
          let mut selector = flume::Selector::new();

          // loop over the operations and add them to the selector. Each one
          // returns the original index in the list, so we can use that to
          // fetch the original item from the list.
          for (idx, item) in lr.iter().enumerate() {
              let idx_clone = idx;
              match &item {
                  ChannelOp::Receive(r, _) => {
                      selector = selector.recv(&**r, move |i| {
                          (i.map(Some).map_err(error::Error::from), idx_clone)
                      });
                  }
                  ChannelOp::Send(s, _, i) => {
                      selector = selector.send(&**s, i.clone(), move |i| {
                          (i.map(|_| None).map_err(error::Error::from), idx)
                      });
                  }
              }
          }

          selector.wait()
      };
      let selected = original.get(idx).unwrap().clone();
      match res {
          Ok(Some(i)) => {
              let l: Item = coll::List::from_iter(vec![selected, i]).into();
              Ok(l)
          }
          Ok(None) => Ok(selected),
          Err(e) => Err(e),
      }
  }

  impl TryFrom<Item> for Handoff<Item> {
      type Error = error::Error;

      fn try_from(i: Item) -> Result<Self, Self::Error> {
          match i {
              Item::Dispenser(coll::Dispenser::Out(pipes::Out::Handoff(p))) => Ok(p),
              Item::Receptacle(coll::Receptacle::In(pipes::In::Handoff(p))) => Ok(p),
              Item::Receptacle(coll::Receptacle::Tunnel(pipes::Tunnel::Handoff(p))) => Ok(p),
              Item::Dispenser(coll::Dispenser::Tunnel(pipes::Tunnel::Handoff(p))) => Ok(p),
              i => Err(error::Error::expected("handoff", i)),
          }
      }
  }

  // drop the receiver side of the handoff and return the handoff item
  pub fn sender(i: Item) -> axiom::ItemResult {
      let mut h = Handoff::try_from(i)?;
      h.close_take();
      Ok(Item::Receptacle(coll::Receptacle::In(pipes::In::Handoff(
          h,
      ))))
  }

  // drop the sender side of the handoff and return the handoff item
  pub fn receiver(i: Item) -> axiom::ItemResult {
      let mut h = Handoff::try_from(i)?;
      h.close_put();
      Ok(Item::Dispenser(coll::Dispenser::Out(pipes::Out::Handoff(
          h,
      ))))
  }

  #[derive(Debug)]
  pub struct Timer<T> {
      receiver: Option<flume::Receiver<T>>,
      handle: Option<JoinHandle<()>>,
      duration: Duration,
  }

  // Cloning a timeout makes a new one, clears state
  impl Clone for Timer<Item> {
      fn clone(&self) -> Self {
          Self {
              receiver: None,
              handle: None,
              duration: self.duration,
          }
      }
  }

  impl Timer<Item> {
      fn new(duration: Duration) -> Timer<Item> {
          Timer {
              receiver: None,
              handle: None,
              duration,
          }
      }

      fn start(&mut self) {
          if self.handle.is_none() {
              let (sender, receiver) = flume::bounded(1);
              let duration = self.duration;
              self.receiver = Some(receiver);
              self.handle = Some(tokio::spawn(async move {
                  sleep(duration).await;
                  //TODO handle error condition on send
                  let _ = sender.send(Item::default());
              }));
          }
      }

      pub fn take(&mut self) -> types::Future<Result<Option<Item>, error::Error>> {
          self.start();
          let receiver = self.receiver.clone().unwrap();
          Box::pin(async move {
              //println!("Receiving");
              receiver.recv_async().await.map(Some).or_else(|_| Ok(None))
          })
      }
  }

  impl From<Timer<Item>> for Item {
      fn from(t: Timer<Item>) -> Self {
          Item::Dispenser(coll::Dispenser::Out(pipes::Out::Timer(t)))
      }
  }

  impl crate::serialize::Display for Timer<Item> {
      fn representation(&self) -> Item {
          assoc::Association::from_iter([
              ("type".into(), "pipe".into()),
              ("timeout".into(), (self.duration.as_millis() as Int).into()),
          ])
          .into()
      }
  }

  pub fn timer(i: Item) -> axiom::ItemResult {
      let ms = Int::try_from(i)?;
      //TODO: check for negative values
      Ok(Timer::new(Duration::from_millis(ms as u64)).into())
  }
#+end_src
***** Database
#+begin_src rust :tangle src/pipes/db.rs :mkdirp yes
  use crate::axiom;
  use crate::types::associative as assoc;
  use crate::types::collection as coll;
  use crate::types::error::Error;
  use crate::types::{self, Item};

  use std::collections::VecDeque;
  use std::sync::OnceLock;

  fn db() -> &'static cozo::DbInstance {
      static DB: OnceLock<cozo::DbInstance> = OnceLock::new();
      DB.get_or_init(|| {
          cozo::DbInstance::new("sqlite", "/tmp/kcats-database.db", Default::default()).unwrap()
      })
  }

  pub fn query(script: Item) -> axiom::ItemResult {
      Ok(db()
          .run_script(
              String::try_from(script)?.as_str(),
              Default::default(),
              cozo::ScriptMutability::Immutable,
          )?
          .into())
  }

  impl From<cozo::NamedRows> for Item {
      fn from(results: cozo::NamedRows) -> Self {
          let headers = results
              .headers
              .iter()
              .map(|s| Item::from(s.clone()))
              .collect::<coll::List>();
          let mut rows = results
              .rows
              .into_iter()
              .map(|row| Item::from(row.into_iter().map(Item::from).collect::<coll::List>()))
              .collect::<VecDeque<Item>>();
          rows.push_front(Item::from(headers));
          Item::from(coll::List::from(rows))
      }
  }

  impl From<cozo::DataValue> for Item {
      fn from(dv: cozo::DataValue) -> Self {
          match dv {
              cozo::DataValue::Null => Item::default(),
              cozo::DataValue::Num(cozo::Num::Int(i)) => Item::Int(i),
              cozo::DataValue::Num(cozo::Num::Float(f)) => Item::Float(f),
              cozo::DataValue::Str(s) => {
                  Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(s.to_string())))
              }
              cozo::DataValue::Bool(b) => Item::from(b),
              cozo::DataValue::Bytes(b) => Item::from(b),
              cozo::DataValue::Vec(_) => todo!("Support cozodb vector values"),
              cozo::DataValue::Bot => panic!("Bot values are supposed to be internal only"),
              cozo::DataValue::Validity(v) => Item::from(v),
              cozo::DataValue::Uuid(u) => Item::from(u.0.to_string()),
              cozo::DataValue::Regex(_) => todo!("Support cozodb regex values"),
              cozo::DataValue::List(l) => coll::List::from_iter(l.into_iter().map(Item::from)).into(),
              cozo::DataValue::Set(s) => coll::Set::from_iter(
                  s.into_iter()
                      .map(|i| assoc::KeyItem::try_from(Item::from(i)).unwrap()),
              )
              .into(),
              cozo::DataValue::Json(_) => todo!("Support cozodb JSON values"),
          }
      }
  }

  impl From<cozo::Validity> for Item {
      fn from(v: cozo::Validity) -> Self {
          coll::List::from_iter([Item::from(v.timestamp.0 .0), Item::from(v.is_assert.0)]).into()
      }
  }

  // impl Db {
  //     pub fn query(&self, query: &str) -> axiom::ItemResult {
  //         let mut stmt = self.conn.prepare(query)?;

  //         let rows = stmt.query_map([], |row| {
  //             Ok(Item::from(
  //                 (0..row.as_ref().column_count())
  //                     .map(|column_index| {
  //                         let column_name =
  //                             row.as_ref().column_name(column_index).unwrap().to_string();
  //                         let column_value: ValueRef = row.get_ref_unwrap(column_index);
  //                         (assoc::KeyItem::from(column_name), Item::from(column_value))
  //                     })
  //                     .collect::<assoc::Association>(),
  //             ))
  //         })?;
  //         Ok(rows.collect::<Result<coll::List, _>>()?.into())
  //     }
  // }

  // pub fn db(i: Item) -> axiom::ItemResult {
  //     let query: String = i.try_into()?;
  //     let db = Db::new()?;
  //     db.query(&query)
  // }

  // impl From<ValueRef<'_>> for Item {
  //     fn from(value: ValueRef) -> Self {
  //         match value {
  //             ValueRef::Integer(i) => Item::Int(i),
  //             ValueRef::Real(f) => Item::Float(f),
  //             ValueRef::Text(t) => Item::Dispenser(coll::Dispenser::Sized(coll::Sized::String(
  //                 String::from_utf8_lossy(t).into_owned(),
  //             ))),
  //             ValueRef::Blob(b) => {
  //                 Item::Dispenser(coll::Dispenser::Sized(coll::Sized::Bytes(b.to_vec())))
  //             }
  //             ValueRef::Null => Item::default(),
  //         }
  //     }
  // }

  impl From<cozo::Error> for Error {
      fn from(error: cozo::Error) -> Self {
          Error::create(types::wrap("io".into()), error.to_string().as_str(), None)
      }
  }
#+end_src
** Issues
*** INPROGRESS Interactive mode :tools:
run with =kcats -i= for interactive, where you get a repl-like
prompt. Each prompt accepts kcats items as input, and updates the
state accordingly. There are special commands to print the current
state, clear it, write to file, etc.
**** TODO Only print the changed part of the stack
**** TODO Emacs keybindings to send common stack ops
+ swap / swapdown
+ clear ([] evert drop)
+ clone
+ snapshot?
+ drop
+ sink / float
  
*** DONE Install the lexicon in the proper place
Right now it's assumed to be in the src dir, but if we move the binary
it won't be able to find the lexicon file. The build process should be
able to place it in =/usr/share/kcats= or =~/.local/share/kcats= or
whatever the proper place is. Will have to look into how cargo
normally does this sort of thing.

*** CANCELED Add option to read an alternative lexicon file
The builtins can stay inside the binary, but we should have a cmdline
option to start without the usual lexicon. Should probably add a word
'lexicon' to add a parsed object as the lexicon.
*** DONE Package the binary for various platforms
Would be nice to build rpms/debs etc so users can skip the nasty build
process.
*** DONE Optimize memory allocation
**** DONE Lists
#+begin_src kcats
[[a b]] [a] lookup
#+end_src

#+RESULTS:
: b
*** DONE pack and unpack are not inverse
#+begin_src kcats :result code
[1 2 3] unpack pack
#+end_src

#+RESULTS:
: 
: [[2 3 1]]

It should result in [1 2 3], since people would assume unpack just
does the opposite of pack. But it doesn't, it takes items from the
front and pack puts them on the end.

Solution: rename to put take
*** DONE true and false are not words?
#+begin_src kcats :results code
[true] unwrap word?
#+end_src

#+RESULTS:
#+begin_src kcats
true
#+end_src

If you didn't know =true= was a boolean you would think it was a
word. In the general sense it is a word. Should it be one technically
as well? I lean towards yes (return true if word or boolean).

It's messy because true/false are the only "words" you can put onto
the stack without wrapping.

There are several ways to deal with this:

+ just leave as is (these look like words but don't act like them)

+ Use something else for boolean values, like 0b 1b or something (ugly, no)

+ Revert to allowing bare words (that aren't actions) to go onto the
  stack unwrapped, so that true/false aren't different

Right now I'm inclined to leave as-is, as it's the least bad
solution. Allowing undefined words to just go onto the stack is going
to mask all kinds of errors and will cause untold headaches.
*** DONE Division by zero panics
*** INPROGRESS Implement pipes :stdlib:
**** DONE Write to a file
#+begin_src kcats
  [[file "/tmp/bar4"]] pipe-in

  ["hello world!"
   "Nice to meet you!"
   "My name is kcats"]

  ["\n" join bytes put]

  step
#+end_src

#+RESULTS:
: [[asked [pipe]] [unwound [["Nice to meet you!" "My name is kcats"] ["\n" join bytes put] step]] [type error] [reason "type mismatch"]] [[type pipe] [file "/tmp/bar4"]]

#+begin_src kcats
  [[file "/tmp/bar101r7"]] pipe-in

  "hello world!"

  bytes put

#+end_src

#+RESULTS:
: [[type pipe] [file "/tmp/bar101r7"]]

#+begin_src kcats
  [[file "/tmp/bar101r7"]] pipe-out

  take

  string

#+end_src

#+RESULTS:
: "hello world!" [[type pipe] [file "/tmp/bar101r7"]]

**** DONE Read from a file
#+begin_src kcats :results code
"" [string join] [[file "/tmp/bar2"]] pipe-out

collect 
#+end_src

#+RESULTS:
#+begin_src kcats

stack: [[[reason "type mismatch"] [asked [pipe]] [type error]] [[file "/tmp/bar2"] [type pipe]] ""]
program: [swap [string join] dip [closed? not] shield [take swap [string join] dip [closed? not] shield] loop drop]
#+end_src

#+begin_src kcats :results code
dictionary [collect spec] lookup
#+end_src

#+RESULTS:
#+begin_src kcats

[[[type error] [reason "word is not defined"] [asked [fail]]]
 "Lookup attempted on non association value"
 [spec]
 [[definition [swap [take swap] swap put [dip] join [[closed? not]] dip while drop]]
  [spec [[pipe program] [item]]]]]
#+end_src
**** DONE Close a pipe
#+begin_src kcats :results code
[[file "/tmp/foopytoop"]] pipe-in "foo" bytes put close "bar" bytes put
#+end_src

#+RESULTS:
#+begin_src kcats
[[type pipe] [file "/tmp/foopytoop"]]
#+end_src
**** DONE Serialize pipes with something sane
Maybe they can't be easily round-tripped, but at least we can print
something reasonable that will tell human eyes what it is.
something like[[type pipe-in] [file "/tmp/foo"]]
**** DONE Sockets
***** DONE Server Sockets
#+begin_src kcats :results code
[[type ip-host] [address "127.0.0.1"] [port 11211]] pipe-out 
#+end_src

#+RESULTS:
#+begin_src kcats
socket: Int(11211) String("127.0.0.1")
[[type pipe] [serversocket todo: fix serversocket local addr async issue]]
#+end_src

#+begin_src kcats :results code
  "127.0.0.1" 12345 serversocket 
#+end_src

#+RESULTS:
#+begin_src kcats
socket: Int(12345) String("127.0.0.1")
[[type pipe] [serversocket todo: fix serversocket local addr async issue]]
#+end_src

#+begin_src kcats :results code
[[type ip-host] [address "127.0.0.1"] [port 11211]] pipe-out ;; server socket
take ;; accept connection by taking a socket out of the pipe
"foo\n" bytes put ;; write a message to the socket
take string ;; get a message from the socket
[drop ;; close the socket
 drop] ;; close the server socket
dip
#+end_src

#+RESULTS:
#+begin_src kcats
[[asked [string]] [unwound [take "foo\n" bytes put take string [drop drop] dip]] [type error] [reason "type mismatch"]]
#+end_src

***** DONE Sockets

***** CANCELED Assemble is broken when reading files
- State "CANCELED"   from "INPROGRESS" [2023-10-22 Sun 07:55]
I think it's because =closed?= is broken.

#+begin_src kcats :results code
"" [string join] [[file "bar"]] pipe-out assemble
#+end_src

#+begin_src kcats :results code
"" [string join] [[file "bar"]] pipe-out take drop take drop closed? 
#+end_src

#+RESULTS:
#+begin_src kcats
checking file closed false
Got 3 bytes
checking file closed false
Got 0 bytes
Closing!
checking file closed false
[] [string join] ""
#+end_src

I see the problem. When we clone the pipe, we also clone the =closed=
boolean and we shouldn't be doing that. There should only be one copy
of that. The entire struct should be in an Arc<Mutex> and not just the
file field. And when we modify the boolean, we shouldn't 
**** DONE Convert In/Out traits to enums in pipes modules
Enums seem to work well elsewhere, and since pipes are also a closed
set, we can use them here too.

I don't think there will ever be user-created pipe types as it would
have to be done in rust and not in kcats.

**** DONE Composable transforms
There should be some way to compose transforms in a pipe. For example,
we can have a pipe that when you put bytes in it, it gets written to a
certain file on disk. But what we really want is that we put bytes
into it, and they get compressed with lz4 before being written to
disk.

I suppose pump could take an optional transducer-like thing, and *those*
could be composable. The transformations I'm thinking of generally
aren't going to be i/o, it's pure computation. Actually I guess any
pipe could take an optional transform. Clojure.core.async channels do this.

Maybe the first thing to do is implement transducers?
***** DONE Siphon from one pipe to another
A nice primitive would be a word that takes a program (the program
should expect an item on ToS and it should leave a transformed item)
and two pipes, and takes from one pipe, runs the program, and puts the
result back into the 2nd pipe. It should close the output pipe when
the input pipe closes. Should work with generators as input.

This should all work ok except for when programs somewhere in the
generator stack need access to items beneath the generator and we
don't know how to get to them.

The obvious solution to that is to include the needed values in the
program before giving it to the generator. Then the values will be in
a known place on the stack.

This little program will siphon directly from a generator to a
receptacle:
#+begin_src kcats
  integers 5 taker

  [] ;; receptacle
  [] ;; placeholder that gets dropped (next iteration it will hold a
     ;; copy of the last element which is only needed to check if the
     ;; loop continues and can be dropped after)
  [empty?] ;; stop when generator returns nothing
  [drop ;; the last value
   [generate clone] dip
   sink
   [put] dip]
  until
  drop ;; drop the now-empty dispenser
#+end_src

#+RESULTS:
#+begin_src kcats
[0 1 2 3 4 []] [[positive?] [dec [generate] dive] [[]] if] 0 [inc clone]
4
#+end_src

#+begin_src kcats
integers 5 taker [] siphon
#+end_src

#+RESULTS:
#+begin_src kcats
[[type error]
 [actual [[positive?] [dec [generate] dive] [[]] if]]
 [asked [generator]]
 [unwound [siphon]]
 [reason "type mismatch"]
 [handled true]]
[] [[positive?] [dec [generate] dive] [[]] if] 5 [inc clone]
-1
#+end_src

And since pipes can have generator layers put on top of them, I think we're done. 
**** CANCELED Filled pipes
Mostly for testing purposes, takes a list and creates a buffered pipe
that offers list items until the list is exhausted and then returns pipe closed errors.

#+begin_src kcats
[1 2 3] filled take
#+end_src

#+RESULTS:
: 1 [[type pipe] [filled todo: id-or-hash here]]

**** INPROGRESS Object pipes
- State "INPROGRESS" from "TODO"       [2023-10-19 Thu 21:10]
These pipes should send serialized kcats objects and each put/take
should transfer 1 object. Maybe use protocol buffers or similar

This could be done using a network pipe, and an assemble function that
pulls byte chunks and builds objects when there are enough bytes for
one object, and puts them into a handoff pipe.

This should be possible to do entirely in kcats, similar to how the
interactive mode works. Send a length, then send that number of
bytes. Then the receiving transform can track how many bytes it has
left to receive and the partial encoded item it's got so far. It takes
the next chunk, knocks off that many bytes (if it's more than needed
for that item), and calls =read=. If it's still not enough for the full
item, append to the partial encoded item and decrease the 'bytes
needed' number.

This mechanism of using kcats serialization means we can't send
associations and sets over the wire as-is. We'd have to send them as a
list and convert them at the other end.

Let's see if we can make an object serializer that sends the length
first (separated by \n).

#+begin_src kcats
  [1 2 3] emit bytes
  [count] shield
  string "\n" join bytes
  swap join
#+end_src

#+RESULTS:
#+begin_src kcats
#b64 "NwpbMSAyIDNd"
#+end_src

That's pretty easy! The trickier part is a deserializer where we don't
know how many bytes we're going to get in a chunk.

First we might need a generator that divides into lines.
A generic splitter generator would do most of the work.


#+begin_src kcats
  "foo\nbar\nbaz\n\n" [take]
  "\n"  ;; \f
  [empty] shield
  [[[generate] divedown [clone [put] dip] bail]
   [[[] [drop swap ends? not]] [execute] every?]
   [drop] prime
   drop
   [swap ends?]
   [[[count] shield] dive 
    [[count] shield] dive swap - [0] dip slice]
   when
   [empty] shield swap]
  collect
#+end_src

#+RESULTS:
#+begin_src kcats
["foo" "bar" "baz"] [[[generate] divedown [clone [put] dip] bail] [[[] [drop swap
                                                                        ends? not]]
                                                                   [execute] every?]
                     [drop] prime drop [swap ends?]
                     [[[count] shield]
                      dive [[count] shield]
                      dive swap - [0] dip slice]
                     when [empty] shield swap]
"" "\n" [take] ""
#+end_src

#+begin_src kcats
"foo\nbar\nbaz\n\n" [take]
  "\n"  ;; \f
 split collect
#+end_src

#+RESULTS:
#+begin_src kcats
["foo" "bar" "baz"] [[[generate] divedown [clone [put] dip] bail] [[[] [drop swap
                                                                        ends? not]]
                                                                   [execute] every?]
                     [drop] prime drop [swap ends?]
                     [[[count] shield]
                      dive [[count] shield]
                      dive swap - [0] dip slice]
                     when [empty] shield swap]
"" "\n" [take] ""
#+end_src

Ok this works but ultimately what we need is =resplit= which takes a
list of sized (all the same type presumably) and joins and splits
piece by piece.

We could just create something like =atomize= that takes a generator of
lists, and emits single items.
#+begin_src kcats
  ["foo\n" "bar\nba" "z\n\n"]
  [take] []
  [[] [take] [drop generate take] if] 
#+end_src

#+RESULTS:
#+begin_src kcats
"foo\nbar\nbaz\n\n" [[] [take] [drop generate take] if] [] [take] []
#+end_src

Ok the =atomize= is still handy but what I'm going to do is implement
splitter, that takes a string and emits fields. Then i can use that
generator *within* a re-split chunks generator, that keeps partial
content as state.

So here's that split gen:
#+begin_src kcats
  ;"foo\nbar\nbaz\n\n" [take] "\n"
  ;[1 2 3 2 5] [take] [2]
  ["foo\nbeep" "bar\nba" "z\n\n"] [take] "\n"
  [empty] shield

  ;"foo\nbeep"
  ;; while the state has no separator, pull chunks into it
  [yes
   [[[drop swap contains? not] ;; state doesn't have sep?
     []] ;; last item still something
    [execute] every?] 
   [drop ;; the previous chunk
    [generate] divedown clone [[join] dip] bail]
   while
   drop 
   ;; now call the split generator internally
   wrap [take] put [clone] dive put reverse
   [split execute [dropdown] 3 times] inject 
   unwrap swap 

  ]

  collect
#+end_src

#+RESULTS:
#+begin_src kcats
["foo" "beepbar" "baz"] [yes [[[drop swap contains? not] []]
                              [execute] every?]
                         [drop [generate] divedown clone [[join] dip]
                          bail]
                         while drop wrap [take] put [clone] dive put reverse [split execute [dropdown] 3
                                                                              times]
                         inject unwrap swap]
"" "\n" [take] []
#+end_src

This is great and all, but maybe not quite what we need for object
serialization. Objects can have \n embedded within strings, so that
character doesn't necessarily mean "end of object". It's just used to
separate the byte count from the content.

I think we can implement this pretty directly and easily, especially
if we don't have to account for the case where the count is split
across chunks. We can have a generator with the following state: a
count of chars to read, current content.

Generate, read the count, then loop until there is more content left
in buffer than the count says to expect. Slice off [count] characters
from the buffer and return it if there's enough in the buffer,
otherwise generate and repeat. 

#+begin_src kcats
  ;["5\n[1 2]13\n[ooba " "bazquu]11\nboobooboobo"]
  ["3\n" "fpp4\nfoo"]
  ;[bytes] map
  [take]
  ;[string] each
  "" 0
  [[[complete? [swap count <=]]
    [readcount [drop
                [take] "\n" split generate
                [[drop] 4 times] dip
                [read first] bail 0 or]]]
   [[[[[generate] dive]
      [[[] [\newline contains? not]]
       [execute] every?]
      [join [generate] dive]
      prime join] 
     dip
     [swap \newline contains?] [readcount] when]
    ;[dump [generate] dive [] [join] [drop] if readcount]
    [dump complete? not]
    [[generate] divedown  swap [join] dip] prime]
   let dump cut 0 swap]
  [read first] each
  collect
#+end_src

**** DONE Time pipe
Each take from the pipe return the current unix time in ms.  Should be
a "singleton" - probably using Box::leak, so that we can insert a copy
of this pipe whenever we want and it's always a reference to the same
object. Might be an Arc for compatibility even though we don't need to
ref count. (But I suspect we don't need the Arc).

#+begin_src kcats
timestamps take
#+end_src

#+RESULTS:
: 1687273991929 [[from systemtime] [values [[type integer] [units milliseconds]]] [type out]]

**** DONE stdin/stdout pipes
Should also be singleton. Should it always be a tunnel or should we
allow separate access to in or out?

#+begin_src kcats
standard "foo" bytes put
#+end_src

#+RESULTS:
: foo[[type tunnel] [peer standard]]

Stdin is not tested, since currently the interpreter reads the program
from stdin. May need to change that (read the program from filesystem
and let the program itself access stdin).
**** CANCELED Pipe take outcome
- State "CANCELED"   from "TODO"       [2023-09-22 Fri 09:14] \\
  I don't think there's any glaring inconsistency here - indefinite (or
  i guess I might call them 'unsized') dispensers will dispense =nothing=
  when there's nothing left. That means that when you are using one of
  these, =nothing= is not a valid value you can use in the sequence.
  
  That means, for example, that if you wanted to print whether integers
  are odd or not, you can't quite do that. You'd need to use pairs (the
  original value and true/[] for whether it's odd).
  
  Perhaps later we can think about signaling end-of-stream out of
  band. One way to do that is to use an unhandled error value that
  unwinds the stack, and you have to recover to catch it. But that
  introduces a lot of complexity and I think it may be easier to just
  work around the fact that you can't use =nothing= in the data. It's
  possible that maybe the complexity in the out-of-band impl could be
  abstracted away, so it's worth revisiting later.
There is some inconsistency with what happens when there's nothing
left - empty lists just return nothing on take, but closed pipes
return an error. May need to resolve this inconsistency.

|               | List    | Handoff | Socket  | StaticFile |
|---------------+---------+---------+---------+------------|
| take Items    | Item    | Item    | Bytes   | Bytes      |
| take Past EOF | Nothing | Nothing | Nothing | Nothing    |
| step Past EOF | Exit    | Exit    | Exit    | Exit       |
*** DONE 'Fail' is not defined
We need to be able to throw our own errors (eg lookup tries to do this)

#+begin_src kcats
1 2 [1 "two" +] [fail] recover 3 4 
#+end_src

#+RESULTS:
: converting to error: Error([[type error] [asked [number]] [unwound [+]] [reason "type mismatch"]])
: [[type error] [asked [number]] [unwound [3 4]] [reason "type mismatch"]] 2 1

*** DONE 'dictionary' doesn't allow access to the data inside definitions
The definition is just shown as the word itself and we can't access
spec, definition etc.

#+begin_src kcats :results code
dictionary [swap spec] lookup
#+end_src

#+RESULTS:
#+begin_src kcats
[[[item a] [item b]] [[item b] [item a]]]
#+end_src

*** INPROGRESS Use a single word for all derivation/conversion :stdlib:
Right now there's different words for converting bytes to string
(string) or string to bytes (bytes). Proposing a more composable
mechanism here, where there's a single action word that derives one
data structure from another.

Here we use the association shorthand for =[[type bytes]]=
#+begin_src kcats
"foo" [bytes] derive
#+end_src

#+RESULTS:
: No spec for derive!
: 
: [[] [bytes] "foo"]

Here's a typical invocation
#+begin_src kcats
"foo" [[type bytes]] derive
#+end_src

#+RESULTS:
: No spec for derive!
: 
: [[] [[type bytes]] "foo"]

Here's a derivation with two steps: convert string to bytes, then use
the bytes as entropy to generate an AES encryption key.
#+begin_src kcats
"foo"
[[bytes]
 [[type aes-key]
  [length 128]]]
[derive]
step
#+end_src

#+RESULTS:
: No spec for derive!
: No spec for derive!
: 
: [[] [[type aes-key] [length 128]] [] [bytes] "foo"]

This seems like a pretty straightforward syntax and should eliminate
an explosion of new words that just convert one type to another.

The difficulty is how to implement it. A naive way would just make
=derive= a multimethod and add lots of methods. The problem is the
=decide= based multimethods aren't really intended to have lots of
methods because it's inefficient - all the conditions are checked
until one is true. In this case, we can just do a straight lookup by
destination type (if we have different methods depending on input
type, THEN we can use =decide= internally).

But maybe even that isn't ideal - we could also lookup by =[sourcetype
destinationtype]= pairs. However we don't have explicit source
types. We just have a list that may or may not also act as a set or
association.

It should be possible to implement the =destinationtype= based lookup
pretty easily. Make =derive= a lexicon entry but insert it earlier so
that it will have an actual association object. It'll be refcounted or
possibly even static (if we don't care about leaking these - but that
would fail if we run through many envs in the same process).

Actually we can do this in kcats itself but it requires executing
arbitrary code. The lexicon doesn't really do that - it's just a data
file. 
#+begin_src kcats
[derive]
[[[bytes string] [string]]] association wrap
[float type wrap swap join ;; 1 [string] => [number string]
 lookup execute] join
[definition] swap put
wrap
inscribe

"foo" bytes [string] 
derive 
#+end_src

#+RESULTS:
: No spec for derive!
: 
: stack: [[[reason "type mismatch"] [asked [[[list?] [string?]] [execute] any?]] [type error]] [string]]
: program: [lookup execute]


Ok here's the basic impl. Afterward, should change =string= to
=++string= to make them non-public, should use =[string] derive=
instead. The issue here is how do we add new conversions? We could
make the conversions a separate word, like =derivations=, but that
sticks out as different - it's a data structure and not an action
word.
#+begin_src kcats
;; add some conversions
derivations [[bytes string] [string]] assign
;; the list of conversions
[[[bytes string] [string]]] association

"foo" bytes [string]


;; determine the current type and look up the conversion
[[type] shield wrap] dipdown [join wrap] dip 
swap lookup execute
#+end_src

#+RESULTS:
: 
: ["foo"]
#+begin_src kcats
dictionary [assign spec] lookup 
#+end_src

#+RESULTS:
: 
: [[[type error] [reason "word is not defined"] [asked [fail]]] "Lookup attempted on non association value" [spec] assign]

#+begin_src kcats 
[[[a b] c]] [[a b]] lookup
#+end_src

#+RESULTS:
: 
: [c]

#+begin_src kcats
[[string [foo]]] [string] lookup
#+end_src
#+RESULTS:
: 
: [[foo]]

Experiment with whether we can easily determine the 'from' type so
that we can dispatch on both 'from' and 'to'.
#+begin_src kcats :results code
[+] unwrap type
#+end_src

#+RESULTS:
#+begin_src kcats

[[[reason "type mismatch"] [type error] [unwound [count 1 = [[+]] unwrap evert first [[[first [type] unwrap =] [first second] [first first] if] [[]]] unwrap branch [[[[count 1 =] [[first [type] unwrap =] [first second] [first first] if] [[]] if] +]] unwrap evert first swap drop [[[[association] unwrap]]] unwrap swap [[]] unwrap or [[[[empty?] shield] dip swap [or] shielddown] [] [[take swap [[execute] shielddown] dip swap] dip or] [execute] recur] execute swap drop swap drop]] [asked [list]]] +]
#+end_src

#+begin_src kcats
[] [] [] [drop [default] unwrap] if
#+end_src

#+RESULTS:
: 
: [default]

#+begin_src kcats
[[bar 12]]
[
[[foo] lookup]
[[bar] lookup]
[5]
[6]
]
swap [empty?] shield
[[take] dip swap execute [empty?] shield] loop
;;sink drop drop
#+end_src

#+RESULTS:
: 
: [[[bar 12]] [[[foo] lookup] [[bar] lookup] [5] [6]]]

#+begin_src kcats
[[bar 12]]
[[[foo] lookup]
 [[bar] lookup]]
[execute] any?
#+end_src

#+RESULTS:
: 
: [12 [[bar 12]]]

#+begin_src kcats
1 2 or
#+end_src

#+RESULTS:
: 
: [1]

Now that we have a fairly reliable =type= implementation, we can
dispatch on both =to= and =from= types for =derive=.

#+begin_src 

#+end_src
*** DONE Change boolean operators to retain values
=or= and =and= should return the actual value if it is truthy, instead
of =true=. But neither should ever return =[]=, but use =false=
instead.
#+begin_src kcats
2 [] or
#+end_src

#+RESULTS:
: 2

#+begin_src kcats
1 10 inc 1 range take swap [*] step
#+end_src

#+RESULTS:
: 3628800

This does bring up the question of whether the boolean type is really
needed. It may be possible to use =[]= as =false= and anything else as
=true= (=1= for example, or maybe the bare word =true= which then
wouldn't carry any other meaning). Or possible use some other word
than =true=, eg =something=.

Does this make sense when applied to boolean logic?

#+begin_example
something or nothing = something ?
something and something = something ?

"sky is blue" or "moon is made of cheese" = true
#+end_example

I think it doesn't make sense.

Maybe yes/no?

#+begin_example
yes or no = yes ?
#+end_example
#+begin_src kcats
5 3 =
#+end_src

#+RESULTS:
: 
: [[]]

#+begin_src kcats
5 [[[3 =] ["three"]]
                         [[5 =] ["five"]]
                         [[7 =] ["seven"]]
                         [[true] ["something else"]]]
                      decide
#+end_src

#+RESULTS:
: 
: ["five" 5]

#+begin_src kcats
[3 5 7] [even?] any? false =
#+end_src

#+RESULTS:
: 
: stack: [[[reason "word is not defined"] [type error] [asked [false]]] []]
: program: [false =]
*** DONE 'recover' is broken
#+begin_src kcats
[+]
[drop 1
 [+] [drop 2 +]
 recover]
recover
#+end_src

#+RESULTS:
: 
: [3]

#+begin_src kcats
[[program [[+] [3] recover]]] environment advance advance
eval-step
advance
advance
advance
advance
advance
eval-step
advance
advance
advance
#+end_src

*** DONE Fix handle in nested env
=handle= doesn't work properly in a nested environment. That is
because =eval= has some logic to check for uncaught exceptions, but
the =advance= self-hosted evaluator doesn't.

#+begin_src kcats
1 + handle error?
#+end_src

#+RESULTS:
: Env: [Word(0x5d29b8fb5b00 : "handle"), Entry(Entry { word: 0x5d29b8fc2600 : "error?", examples: None, spec: Some([List([Word(0x5d29b8fb6c00 : "item")]), List([Word(0x5d29b8fb6820 : "boolean")])]), serialize: false, definition: Builtin })]
: handle is Word(0x5d29b8fb5b00 : "handle") Word(0x5d29b8fb5b00 : "handle")
: expr contains handle? true
: Word(0x5d29b8fb5b00 : "handle") vs Word(0x5d29b8fb5b00 : "handle")
: 
: [true 1]

#+begin_src kcats
+ handle type
#+end_src

Looks like the word =error?= is shadowed - there's a builtin that's
overwritten by a definition that depends on the builtin (via calling
=type=, which expects the builtin version of =error?=).

#+begin_src kcats
[[program [+]]] environment eval-step 
#+end_src

#+RESULTS:
: 
: [[[stack [[[asked [consume]] [reason "not enough items on stack"] [type error]]]] [program []]]]

#+begin_src kcats
[[program [1 +]]] environment advance advance advance 
#+end_src

#+RESULTS:
: 
: [[[stack [[[asked [consume]] [reason "not enough items on stack"] [type error]] 1]] [program [+]]]]

#+begin_src kcats
[[program [[[3]] [+ handle] dip]]] environment advance advance advance
#+end_src

#+RESULTS:
: 
: [[[stack [[[asked [+_handle]] [reason "word is not defined"] [type error]]]] [program [+_handle [[[3]]] unwrap]]]]

#+begin_src kcats
[[program [+ handle]]] environment eval-step eval-step
#+end_src

#+RESULTS:
: { stack: [], program: [[[program [+ handle]]] environment eval-step eval-step] }
: { stack: [[[program [+ handle]]]], program: [environment eval-step eval-step] }
: { stack: [[[stack []] [program [+ handle]]]], program: [eval-step eval-step] }
: { stack: [], program: [+ handle] }
: { stack: [[[stack [[[asked [consume]] [type error] [reason "not enough items on stack"]]]] [program [+ handle]]]], program: [eval-step] }
: { stack: [[[asked [consume]] [type error] [reason "not enough items on stack"]]], program: [+ handle] }
: 
: [[[stack [[[reason "not enough items on stack"] [type error] [asked [consume]]] [[asked [consume]] [type error] [reason "not enough items on stack"]]]] [program [+ handle]]]]

There is a problem in the design where an error (with no =handle=) is
supposed to halt execution, but later we want to do things with the
environment (like examine objects etc). For example, if we're
executing a nested env and it has an error, we can't even natively
examine it, because as soon as we retrieve it from the inner env, it
is an unhandled error on ToS and it halts the outer env. This is not
what I intended.

A possible solution is to have whatever =eval= we're using halt but
remove the =halt= bit (in the current design it's the =is_handled=
field of the error) on its way out. So that whatever executes next is
presumed to be after some manual intervention has taken place.

Also for nested envs we need several words to help deal with errors:

+ a word that tells whether the env will halt: that there's an error
  on ToS with halt bit set, and =handle= does not appear in the
  program. The word can efficiently return =false= if ToS isn't an
  Error.

+ A word that removes the halt bit - as the last thing to do before
  exiting.

So what about the word =advance= that completely executes a word -
let's say the word errors out and halts. We removed the halt bit first
but how do we know what happened? In =eval= it's pretty obvious if we
halted on error - the program isn't empty (that's the only other
reason to stop). We could see in =advance= that the program got
longer, but isn't very obvious in many cases.

Another possibility is letting the program unwind until it's empty,
which would also halt execution. That's not ideal because we're giving
up the possibility of manually fixing it and continuing. On the other
hand, real programs are probably not going to have universal error
handlers (eg like java's 'catch Exception e'. In other words, the
=recover= is often going to examine the error, see that it's not one
that it knows how to deal with, and re-throw it hoping there's a
recovery further down the program that will know what to do. But
there may not be, and the end result is a major unwind of the
program, at least, all the way to the deepest =recover=. At that
point it's likely too far unwound to do any manual
interventions. We're just not going to know at 'throw time' whether
any of the recoveries can really help. It's possible they'll all look
at the error and pass it on. 

But there's no denying that halting when there's no recovery, is
better than unwinding everything - you find out what went wrong *and*
you get the possibility of continuing. It's just a matter of providing
this feature without making other things more difficult.

Maybe another possibility is unwinding the program **into** the
error object. In other words, whatever program items we lop off, we
save them in the error object, in a field named, say, =unwound= or
something like that. Then the runtime can just exit with the error on
ToS, and if the user wants to manually intervene they can copy the
program from that field. This doesn't solve the problem of 'just
examining an error causes unwind' but it saves us from having to
special case unhandlable errors. Perhaps we could have a word called
=rewind= or something, that restores the program from the error on
ToS and clears the halt bit.

I like this idea more and more - it opens up the possibility of
common-lisp's retry, where you can catch an error thrown from deep
within nested code, twiddle the stack a bit and retry the code
again. We already retain the program item that threw the error so
we would still have it to retry. I'm thinking syntax like this:

#+begin_src kcats
[+] [[1 1] dip retry] recover
#+end_src

In this case we try to add, but there's no numbers on the stack. So we
enter the recovery program that finds the env like this:

#+begin_src kcats
[[stack [[[type error] [asked [consume]] [unwound [+]]]]
 [program [[1 1] dip retry]]]]
#+end_src

So we =dip= the numbers underneath the error, then calling =retry= on
an error will extract the =unwound= field (discarding the rest of the
error) and =execute= it. So then we end up with =1 1 +=.

Ok i actually implemented this (and I don't think it was difficult)
but i don't know what I did with it. I know it worked quite well and I
wanted to keep it. Need to do it again.

#+begin_src kcats
  ;; there needs to be 3 numbers here to add/mult but we forgot!
  + * 1 2 3
  handle ;; catch the error here, stack is empty except the error
  [5 6 7] dip ;; put numbers underneath
  retry ;; rerun what failed before
#+end_src

#+RESULTS:
: 
: [3 2 1 65]

Now put it together using the higher-level =recover=

#+begin_src kcats
  [+ *] [[5 6 7] dip retry] recover
#+end_src

#+RESULTS:
: 
: [65]

*** DONE Lots of association-like objects that aren't
Environment and Error, for example. We can't just treat it like an
assoc, even though it is. I'm not quite sure how to solve this. I
don't think I can make a trait *and* make the trait object part of the
Item enum.

#+begin_src rust
trait Foo {};

struct Quux { }

impl Foo for Quux {}

enum Bar { Int(i32), Foo(Box<dyn Foo>), Quux(Quux) }
#+end_src

#+RESULTS:

Rust doesn't complain if you have an object that can match the enum in
more than one way. I think that's because one is boxed and the other isn't.

#+begin_src rust
trait Foo {};

struct Quux { }

impl Foo for Quux {}

enum Bar<'a> { Int(i32), Foo(&'a dyn Foo), Quux(&'a Quux) }
#+end_src

#+RESULTS:


#+begin_src kcats :results code
  dictionary [advance definition] lookup
#+end_src

#+RESULTS:
#+begin_src kcats

[[[[program] lookup count] shield swap [[program] lookup count [[positive?] [<=]] [execute] every?] [eval-step] while swap drop]]
#+end_src

#+begin_src kcats :results code
  [[program [1 1 +]]] environment eval-step [stack] lookup
#+end_src

#+RESULTS:
#+begin_src kcats
[[1]]
#+end_src

#+begin_src kcats :results code
[] environment association?
#+end_src

#+RESULTS:
#+begin_src kcats
true
#+end_src

#+begin_src kcats
dictionary [fail] lookup
#+end_src

#+RESULTS:
: [[spec [[string] [*]]] [definition []]]

*** DONE scoping of dictionary entries
The original design was to have the dictionary be a single atomic data
structure that code could modify basically at will, with words like
=inscribe= (to add words) etc.

However I think a better design would be something like this:

#+begin_src kcats
  [[add1 [1 +]]] [3 add1] augment
#+end_src

Where the word =augment= takes an association (more specifically, a
dictionary) and overlays that on top of the builtin dictionary. Then
those new words become accessible just as if they were built in, then
the 2nd argument (a program) is executed as usual. After execution,
the learned words are no longer accessible.

It would be possible to nest calls to =augment= (where the program has
its own call to =augment=).

As for implementation, it may be possible to do a kcats-only impl, but
I don't think it's going to perform well. This is going to be the
normal mode of execution. Very few programs will run with only the
builtin words. In fact, it may be a good idea to break up the lexicon
into components - have pipes be a separate library that has to be
loaded with =augment=.

There is some overlap in functionality here, between =decide= and
=augment= - both are designed to provide context. Maybe =decide= provides
context on how a given word (whose overall meaning doesn't change)
applies to a given piece of data. And =augment= provides completely new
words, or provides a new meaning. Probably it's not going to be common
to replace meanings - maybe for security reasons. For example, when
running untrusted code, you may want to eliminate certain words (like
those that have side effects like writing to disk or the
network). That brings up the possible feature of not just merging new
items into the dictionary but doing arbitrary combinators, where =join=
is just a common use case. In that case, maybe =augment= isn't the right
word because you might be actually restricting the dictionary. So we
need a more generic term for "changing the language". Garble? babel?
I like =babel= - it captures the fact that we're moving from one
language (the set of builtin words) to lots of different languages. I also like =lingo=.

#+begin_src kcats
  [[clone *] [square] assign] ;; operate on the dictionary - add word 'square'
  [3 square]
  lingo
#+end_src

would print 9.

The idea here is to have local lingo, possibly down to quite small
pieces of code. I'm thinking on the order of 10 words is probably
enough to have certain words added or changed.

Special care will need to be taken, if you want to change the meaning
of the word, but re-use the old meaning as part of the new
meaning. You can't just overwrite the definition with a new one that
contains the word itself, expecting *that* word to refer to the old
meaning. You'll have to capture the old definition and incorporate
it. =update= should help.
**** What to call this word
+ learn (but unlearn after?)
+ specialize
+ extend
+ adapt
+ augment 
+ refine
+ supplement
+ babel
+ lingo <= front runner.
**** Implementation
It seems viable that we could use the stack to hold dictionary changes.

We'd have to retain a copy of the original dictionary to restore later.

An axiom word like =definitions= or something that sets the dictionary
to ToS would help. I think the rest could be pure kcats.

it'd be something like:

#+begin_src kcats 
  [[square] [[definition [clone *]]
            ; [word square]
             [spec [[number] [number]]]] assign];; ops-dict
  [9 square];; program-to-run
  dictionary ;; fetch the dictionary
  sink ;; p o d
  [clone] dipdown ;; p o d d
  [execute] dip ;; n=new-dict p n d
  float ;; d p n
  swapdown ;; d n p
  [redefine ;; p
   execute]
  dip ;; d
  redefine
#+end_src

#+RESULTS:
: 81

A few problems remaining above:
- [X] Need to specify the word inside the definition.
- [X] Need to explicitly convert the definition to an association.

But I think this proves the concept.

Probably want to eventually make a rust implementation.

#+begin_src kcats 
  [[square] [[definition [clone *]]
            ; [word square]
             [spec [[number] [number]]]] assign];; ops-dict
  [9 square];; program-to-run
  dictionary ;; fetch the dictionary
  sink ;; p o d
  [clone] dipdown ;; p o d d
  [execute] dip ;; n=new-dict p n d
  float
  swapdown
  [redefine] dip dictionary [square] lookup
 
#+end_src

#+begin_src kcats :results code 
  [[square] [[definition [clone *]]
            ; [word square]
             [spec [[number] [number]]]] assign];; ops-dict
  [9 square];; program-to-run
  lingo 
#+end_src

#+begin_src kcats
  dictionary [square] [[definition [clone *]]
                       [spec [[number] [number]]]] assign
  [square] lookup
#+end_src

#+RESULTS:
: Warning, failed to insert into dictionary: List([List([Word(0x5dcc4c2878e0 : "definition"), List([Entry(Entry { word: 0x5dcc4c26dea0 : "clone", examples: Some([List([List([Int(1), Int(2), Int(3), Word(0x5dcc4c26dea0 : "clone")]), List([Int(1), Int(2), Int(3), Int(3)])])]), spec: Some([List([List([Word(0x5dcc4c25ad70 : "item"), Word(0x5dcc4c26d4d0 : "a")])]), List([List([Word(0x5dcc4c25ad70 : "item"), Word(0x5dcc4c26d4d0 : "a")]), List([Word(0x5dcc4c25ad70 : "item"), Word(0x5dcc4c26d4d0 : "a")])])]), serialize: false, definition: Builtin }), Entry(Entry { word: 0x5dcc4c2579c0 : "*", examples: None, spec: Some([List([Word(0x5dcc4c258ab0 : "number"), Word(0x5dcc4c258ab0 : "number")]), List([Word(0x5dcc4c258ab0 : "number")])]), serialize: false, definition: Builtin })])]), List([Word(0x5dcc4c25a6a0 : "spec"), List([List([Word(0x5dcc4c258ab0 : "number")]), List([Word(0x5dcc4c258ab0 : "number")])])])])
: []

*** DONE Move environment stuff into own module
#+begin_src kcats :results code
  [[program [1 2 3]]] environment 
#+end_src

#+RESULTS:
#+begin_src kcats
{ stack: [], program: [[[program [1 2 3]]] environment] }
{ stack: [[[program [1 2 3]]]], program: [environment] }

[[[stack []] [program [1 2 3]]]]
#+end_src

#+begin_src kcats
1 2 +
#+end_src

#+RESULTS:
: 
: [3]

*** DONE When printing results, don't wrap the stack
Evaling =1 1 += should print =2=, not =[2]=. We don't have to wrap the
input, so why wrap the output.

*** DONE Update pipes to use enums instead of traits
It's worked out well for everything else, and I don't think anyone
else will be implementing these traits.

Looking at this I am not in that big a hurry to change it, with traits
at least I can spread out the impls into different modules. with enums
that'd be awkward.

*** CANCELED Recover clears the stack built up in the try program
#+begin_src kcats :results code
 [2 3 "four" * +] [] recover
#+end_src

#+RESULTS:
#+begin_src kcats
[[reason "type mismatch"] [unwound [* +]] [type error] [asked [number]]]
#+end_src

Apparently this was my design. I am not so sure about it now, that we
have =retry=. If an error occurs in the middle of a program, what do we
do with the stack? If the recovery is meant to be "try something else
instead of the entire program" then restoring the stack makes
sense. However then that breaks use of =retry= because the recovery
can't pick up where the program left off.

Maybe =recover= and =retry= are mutually exclusive.

We could also use =retry= with =handle=:

#+begin_src kcats
2 3 "four" * + handle [drop 4] dip retry
#+end_src

#+RESULTS:
: 14

To make this work you have to know which item is the potential problem.

Specifying alternates seems useful, such that it will keep retrying
until it hits an empty alternates object or the program finishes. Each
time an alternate is tried it is removed from the list.

#+begin_src kcats
[2 3 ["four" 4] alternates * +] retry 
#+end_src

*** DONE List access and update by index
I think re-using =lookup= and =assign= for lists, using their index, makes sense here:
#+begin_src kcats
  [5 10 15 20] [1] lookup
#+end_src
should print 10.

#+begin_src kcats
  [5 10 15 20] [1] 30 assign
#+end_src

#+RESULTS:
: [5 30 15 20]

 would leave =[5 30 15 20]=.

 The problem here is that this is ambiguous:

#+begin_src kcats
  [[a b] [c d]] [0] [d e] assign

  ;; is it (assigned as a hashmap by key)
  ;;[[a b] [c d] [0 [d e]]]

  ;; or is it (assigned as a vector by index)
  ;;[[d e] [c d]]
#+end_src

#+RESULTS:
: [[d e] [c d]]

We could clear up the ambiguity by saying that int keys on a list mean
vector behavior. If you want the other you have to specify =association=
first.

lets check some corner cases - creating nested lists
#+begin_src kcats
  [1 2 3] [1 0 0] "foo" assign
;; should be [1 [[foo]] 3]
#+end_src

#+RESULTS:
: [1 [["foo"]] 3]

What do we do when we're requested to assign beyond the end of the
list? We can extend the list and pad it with =Nothing=, although this
seems maybe going a bit too far to honor the user's request that maybe
doesn't make sense.

#+begin_src kcats
  [1 2 3] [1 2] "foo" assign
#+end_src

#+RESULTS:
: [1 [[] [] "foo"] 3]

Now let's test mixed list/assoc

#+begin_src kcats
  [1 2 3] [1 foo baz 0] "bar" assign
#+end_src

#+RESULTS:
: [1 [[foo [[baz [[0 "bar"]]]]]] 3]

Note that here, the last 0 index inserts as a map key because the
object is already an assoc. The contract is basically that once you're
in assoc-land you stay there.

Now check the changes for =lookup=

#+begin_src kcats
[1 4 [34 6 45] 99 23] [2 2] lookup
#+end_src

#+RESULTS:
: 45

make sure update works too

#+begin_src kcats
[1 4 [34 6 45] 99 23] [2 2] [inc] update
#+end_src

#+RESULTS:
: [1 4 [34 6 46] 99 23]

#+begin_src kcats
true not
#+end_src

#+RESULTS:
: []

*** DONE write 'let'
#+begin_src kcats :results code
  [[a [1 1 1]]
   [b [6 7 *]]]
  [a b +]
  [wrap
   [[[1] [shield
          wrap
          [[[spec [[] [item]]]]
           [definition]] dip
          assign] ;; build a full entry
     update]
    map association join]
   join] dip
  lingo
#+end_src

#+RESULTS:
#+begin_src kcats
43
#+end_src

i am not sure if just taking the top value is correct here.


#+begin_src kcats :results code
  dictionary
  [[a [1 1 1]]
   [b [6 7 *]]]
  [[1] [shield] update] map association join
#+end_src

#+RESULTS:
#+begin_src kcats
[[reason "type mismatch"] [type error] [unwound [lingo]] [asked [program]]] [a b +] [[- [[examples [[[2 1 -] [1]] [[1.1 2.2 -] [-1.1]] [[2.2 1 -] [1.2]]]] [spec [[number number] [number]]]]] [read [[spec [[string] [item]]] [examples [[["[1 [2] 3]" read] [[1 [2] 3]]]]]]] [first [[spec [[list] [item]]] [examples [[[[4 5 6] first] [4]]]]]] [close [[spec [[[pipe p]] [[pipe p]]]]]] [if [[definition [[shield] dipdown branch]] [spec [[[program false-branch] [program true-branch] [program condition]] [*]]] [examples [[[5 [5 =] [3 *] [4 +] if] [15]] [[6 [5 =] [3 *] [4 +] if] [10]]]]]] [assemble [[definition [swap [take swap] swap put [dip] join [[closed? not]] dip while drop]] [spec [[pipe program] [item]]]]] [dip [[examples [[[1 8 [inc] dip] [2 8]] [[1 2 [dec] unwrap [+] dip] [3 dec]]]] [spec [[program [item a]] [[item a] *]]]]] [empty? [[examples [[[[] empty?] [true]] [[1 empty?] [false]] [[false empty?] [false]]]] [spec [[item] [boolean]]] [definition [[] =]]]] [sqrt [[spec [[number] [number]]]]] [lookup [[examples [[[[[a b] [c d]] [a] lookup] [[b] unwrap]] [[[[a b] [c d]] [e] lookup] [[]]] [[[[outer [[a b] [c d]]]] [outer c] lookup] [[d] unwrap]]]] [spec [[[list keys] list] [item]]] [definition [[[[swap list?] [something?]] [execute] every?] [take swap [get] dip] while [something?] [[[type error] [asked [association]] [reason "Lookup attempted on non-associative value"]] fail] [drop] if]]]] [filled [[spec [[list] [pipe]]] [definition []]]] [assign [[spec [[[item value] [list keys] association] [association]]] [examples [[[[[a b] [c d]] [a] 5 assign] [[[a 5] [c d]] association]] [[[[a b] [c d]] [e] 5 assign] [[[a b] [c d] [e 5]] association]] [[[[a b] [c [[d e]]]] [c d] 5 assign] [[[a b] [c [[d 5]]]] association]] [[[[a b] [c [[d e]]]] [1 0] 5 assign] [[[a b] [c [5]]]]] [[[1 2 3] [1 0 0] "foo" assign] [[1 [["foo"]] 3]]] [[[1 2 3] [1 2] "foo" assign] [[1 [[] [] "foo"] 3]]] [[[1 2 3] [1 foo baz 0] "bar" assign] [[1 [[foo [[baz [[0 "bar"]]]]]] 3]]]]]]] [pipe-out [[spec [[item] [pipe]]] [definition [[[[type [file] unwrap =] [value file-out]] [[type [ip-host] unwrap =] [clone [address] lookup [[port] lookup] dip serversocket]] [[list?] [+kcats.pipe/->filled]]] decide]]]] [association [[spec [[item] [association]]] [examples [[[[[a b] [c d]] association [[c d] [a b]] association =] [true]] [[[[a b] [c d]] [[c d] [a b]] association =] [false]] [[[[a b] [c d]] [[a b] [c d]] association =] [false]]]]]] [shield [[definition [[snapshot] dip inject first]] [examples [[[1 2 3 [=] shield] [1 2 3 false]]]] [spec [[program] [item]]]]] [< [[spec [[number number] [boolean]]]]] [pair [[examples [[[1 2 pair] [[1 2]]] [[["hi"] ["there" "foo"] pair] [[["hi"] ["there" "foo"]]]]]] [spec [[item item] [list]]] [definition [[wrap] dip put]]]] [buffer [[spec [[integer] [pipe]]] [definition []]]] [swapdown [[examples [[[1 2 3 swapdown] [2 1 3]]]] [spec [[[item a] [item b] [item c]] [[item a] [item c] [item b]]]]]] [string [[examples [[[1 string] ["1"]] [[[1 2 3] string] ["[1 2 3]"]] [[[] string] ["[]"]]]] [spec [[item] [string]]]]] [eval-step [[examples [[[[[program [1 inc]]] environment eval-step eval-step [stack] lookup] [[2]]]]] [spec [[list] [list]]]]] [inject [[examples [[[1 2 3 [4 5 6] [* +] inject] [1 2 3 [26]]]]] [definition [swap evert take dip evert]] [spec [[program list] [list]]]]] [association? [[spec [[item] [boolean]]] [examples [[[[[a b] [c d]] association?] [true]]]]]] [b 42] [serversocket [[spec [[string integer] [pipe]]]]] [every? [[spec [[program list] boolean]] [definition [[shielddown] swap prepend [take swap] swap put [dip swap not] join wrap [dip or] join [[] [[[empty?] shield] dip swap [or] shielddown] [not]] dip [execute] recur swap drop]] [examples [[[[2 4 6] [even?] every?] [true]] [[[2 4 5] [even?] every?] [false]] [[[] [even?] every?] [true]] [[[2 4 6] [] every?] [true]] [[11 [2 4 6] [+ odd?] every?] [true 11]] [[12 [[even?] [positive?] [3 rem 0 =]] [execute] every?] [true 12]]]]]] [both? [[definition [sink pair swap every?]] [examples [[[1 2 [odd?] both?] [false]] [[1 3 [odd?] both?] [true]]]] [spec [[program item item] [boolean]]]]] [filter [[definition [[snapshot [] swap] dipdown [[clone] dip clone wrap swapdown] swap put [join inject first [[put]] [[drop]] branch swapdown dip] join step drop]] [examples [[[[1 2 3] [odd?] filter] [[1 3]]] [[[2 4 6] [odd?] filter] [[]]] [[33 [1 2 3] [+ odd?] filter] [[2] 33]]]] [spec [[program list] [list]]]]] [file-in [[spec [[string] [pipe]]]]] [shielddowndown [[definition [shield [drop drop] dip]] [spec [[[program p] [item consumed] [item consumed]] [[item result]]]] [examples [[[1 2 3 [+ +] shielddowndown] [1 6]]]]]] [snapshot [[examples [[[1 2 3 snapshot] [1 2 3 [3 2 1]]] [[snapshot] [[]]]]] [spec [[] [list]]] [definition [[] evert clone evert unwrap]]]] [* [[spec [[number number] [number]]]]] [dictionary [[spec [[] [list]]]]] [word? [[examples [[[foo word?] [true]] [[[foo] unwrap word?] [true]] [[true word?] [false]]]] [spec [[item] [boolean]]]]] [put [[spec [[item [pipe in]] [[pipe in]]]]]] [max [[spec [[number number] [number]]] [definition []]]] [positive? [[spec [[number] [boolean]]] [definition [0 >]]]] [float [[examples [[[1 2 3 float] [2 3 1]]]] [spec [[[item a] [item b] [item c]] [[item c] [item a] [item b]]]]]] [zip [[examples [[[[a b c] [1 2 3] zip] [[[a 1] [b 2] [c 3]]]]]] [spec [[[list values] [list keys]] [association]]] [definition [[[]] dipdown [[take wrap] dip put swap [put] dip] step drop]]]] [quot [[definition []] [spec [[number number] [number]]]]] [reverse [[spec [[list] [list]]] [examples [[[[1 2 3] reverse] [[3 2 1]]]]]]] [string? [[examples [[["hi" string?] [true]] [["" string?] [true]] [[["hi"] string?] [false]] [[true string?] [false]]]] [spec [[item] [boolean]]]]] [disassemble [[definition [[swap [put] dip] join [empty? not] swap while drop]] [spec [[program item [pipe in]] [[pipe in]]]]]] [step [[examples [[[1 [2 3 4] [*] step] [24]] [[1 [] [*] step] [1]]]] [spec [[program list] [*]]]]] [wrap [[examples [[[1 wrap] [[1]]] [[[1 2] wrap] [[[1 2]]]]]] [spec [[item] [list]]]]] [> [[spec [[number number] [boolean]]] [examples [[[2 1 >] [true]] [[1.1 2.2 >] [false]] [[2.2 1 >] [true]]]]]] [zero? [[spec [[number] [boolean]]] [definition [0 =]] [examples [[[0 zero?] [true]] [[0 zero?] [true]] [[-0.00001 zero?] [false]] [[1.1 zero?] [false]]]]]] [addmethod [[spec [[[pair condition] [program combinator] word] []]] [definition [float [wrap dictionary swap lookup] shield [wrap swap put] dipdown float [float [execute] dip] join inject swap inscribe]]]] [lingo [[definition [dictionary sink [clone] dipdown [execute] dip float swapdown [redefine execute] dip redefine]] [examples [[[[[square] [[definition [clone *]] [spec [[number] [number]]]] assign] [9 square] lingo] [81]]]] [spec [[[program enriched-lexicon] [program dictionary-modifier]] [*]]]]] [redefine [[spec [[association] []]]]] [unassign [[spec [[[item key] association] [association]]] [examples [[[[[a b] [c d]] [a] unwrap unassign] [[[c d]] association]] [[[[a b] [c d]] [e] unwrap unassign] [[[a b] [c d]] association]]]]]] [swap [[examples [[[1 2 3 swap] [1 3 2]]]] [spec [[[item a] [item b]] [[item b] [item a]]]]]] [prepend [[spec [[item list] [list]]] [examples [[[[1 2] 3 prepend] [[3 1 2]]]]] [definition [wrap swap join]]]] [spawn [[spec [[program] []]] [definition []]]] [recur [[spec [[[program rec2] [program rec1] [program true-branch] [program pred]] [*]]] [examples [[[3 [1 <=] [] [clone dec] [execute *] recur] [6]]]]]] [closed? [[spec [[pipe] [boolean]]]]] [sink [[spec [[[item a] [item b] [item c]] [[item b] [item c] [item a]]]] [examples [[[1 2 3 sink] [3 1 2]]]]]] [negative? [[spec [[number] [boolean]]] [definition [0 <]]]] [evaluate [[examples [[[[[program [1 2 3 4 + *]]] environment evaluate [stack] lookup] [[14 1]]]]] [spec [[list] [list]]]]] [not [[examples [[[1 even? not] [true]] [[false not] [true]] [[true not] [false]] [[[] not] [true]]]] [spec [[item] [boolean]]]]] [timeout [[definition []] [spec [[integer] [pipe]]]]] [environment [[examples [[[[[program [1 2 3]]] environment eval-step [stack] lookup] [[1]]]]] [spec [[association] [list]]]]] [bytes? [[spec [[item] [boolean]]]]] [update [[examples [[[[[a 1] [b 2]] [b] [inc] update] [[[a 1] [b 3]] association]] [[[[a [[c 3] [d 5]]] [b 2]] [a c] [inc] update] [[[a [[c 4] [d 5]]] [b 2]] association]] [[[[a [[c 3] [d 5]]] [b 2]] [a c] [drop 10 15] update] [[[a [[c 15] [d 5]]] [b 2]] association]] [[[[a 1] [b 2]] [d] [5] update] [[[a 1] [b 2] [d 5]] association]] [[[[a [[c 3] [d 5]]] [b 2]] [a e] [5 6 +] update] [[[a [[c 3] [d 5] [e 11]]] [b 2]] association]]]] [definition [[[lookup] shield] dip shielddown assign]] [spec [[program [list keys] association] [association]]]]] [tunnel [[definition [[[[type [ip-host] unwrap =] [clone [port] lookup [[address] lookup] dip !**java.net.Socket.]]] decide]] [spec [[item] [pipe]]]]] [number? [[spec [[item] [boolean]]] [examples [[[[1] number?] [false]] [[[] number?] [false]] [[5 number?] [true]] [[5.01 number?] [true]]]]]] [loop [[spec [[program [item flag]] [*]]] [examples [[[10 true [-2 * clone 50 <] loop] [160]]]]]] [select [[definition []] [spec [[[list pipes]] [item pipe [list pipes]]]]]] [evert [[spec [[list] [list *]]] [examples [[[1 2 3 [4 5 6] evert] [6 5 4 [3 2 1]]]]]]] [advance [[spec [[environment] [environment]]] [definition [[[program] lookup count] shield swap [[program] lookup count [[positive?] [<=]] [execute] every?] [eval-step] while swap drop]]]] [dipdown [[spec [[program [item a] [item b]] [[item a] [item b] *]]] [examples [[[1 2 3 [inc] dipdown] [2 2 3]]]]]] [map [[spec [[program list] [list]]] [examples [[[[1 2 3] [inc] map] [[2 3 4]]] [[1 [1 2 3] [+] map] [[2 3 4] 1]] [[7 9 [1 2 3] [+ *] map] [[70 77 84] 9 7]] [[7 9 [+] [] map] [[+] 9 7]]]] [definition [[snapshot [] swap] dipdown [wrap swap clone float] swap put [[swap join] dip inject first swap [put] dip] join step drop]]]] [primrec [[examples [[[5 [1] [*] primrec] [120]]]] [spec [[[program rec1] [program exit] [number data]] [*]]] [definition [[execute] swap join [[drop] swap join] dip [[zero?]] dipdown [[clone dec]] dip recur]]]] [execute [[spec [[program] [*]]] [examples [[[[1 2 +] execute] [3]] [[2 [+] 4 swap execute] [6]]]]]] [clone [[examples [[[1 2 3 clone] [1 2 3 3]]]] [spec [[[item a]] [[item a] [item a]]]]]] [or [[examples [[[1 odd? 3 even? or] [true]] [[1 2 or] [1]] [[[] 2 or] [2]] [[[] [] or] [false]]]] [spec [[item item] [item]]]]] [= [[spec [[item item] [boolean]]] [examples [[[1 2 =] [[]]] [[1 1 =] [true]] [[[] [] =] [true]] [[[1] [] =] [[]]] [[[1 [false]] [1 [false]] =] [true]] [[[1 ["foo"]] [1 ["foo"]] =] [true]] [["hi" "hi" =] [true]] [["hi" "there" =] [[]]] [[[] true =] [[]]] [[[1 ["foo"]] [1 ["bar"]] =] [[]]] [[[[] [] association =] [true]]]]]]] [take [[spec [[[pipe out]] [item [pipe out]]]]]] [something? [[definition [empty? not]] [spec [[item] [boolean]]] [examples [[[1 something?] [true]] [[false something?] [true]] [[[] something?] [false]]]]]] [type [[examples [[[[[foo 1]] type] [[foo] unwrap]] [[1] [[number] unwrap]] [[1] [[number] unwrap]] [[[]] [[nothing] unwrap]] [["foo" bytes] [[bytes] unwrap]] [["foo"] [[string] unwrap]] [[[[type foo]] [[foo] unwrap]]] [[[[type foo] [attr "blah"]] [[foo] unwrap]]] [[[[attr1 foo] [attr2 "blah"]] [[association] unwrap]]] [[[[foo 1]] [[foo] unwrap]]] [[[[type url] [value "http://foo.com"]] type] [[url] unwrap]]]] [spec [[item] [item]]] [definition [[[[empty?] [[nothing] unwrap]] [[association?] [[[[type] lookup] [[count 1 =] [[first [type] unwrap =] [first second] [first first] if] [[]] if] [[association] unwrap]] [execute] any?]] [[list?] [[list] unwrap]] [[number?] [[number] unwrap]] [[word?] [[word] unwrap]] [[bytes?] [[bytes] unwrap]] [[string?] [[string] unwrap]] [[pipe?] [[pipe] unwrap]] [[error?] [[error] unwrap]]] decide swap drop]]]] [fail [[spec [[association] [*]]]]] [decide [[examples [[[5 [[[3 =] ["three"]] [[5 =] ["five"]] [[7 =] ["seven"]] [[true] ["something else"]]] decide] [5 "five"]] [[9 [[[3 =] ["three"]] [[5 =] ["five"]] [[7 =] ["seven"]] [[true] ["something else"]]] decide] [9 "something else"]] [[9 [[[3 =] ["three"]] [[5 =] ["five"]] [[7 =] ["seven"]]] decide] [9 []]]]] [spec [[[association test-expr-pairs]] [*]]]]] [break [[spec [[environment [program condition]] [environment [program condition]]]] [definition [[[[[program] lookup something?] [swap execute not]] [execute] every?] [eval-step] while]]]] [unwrap [[spec [[list] [*]]] [examples [[[[1] unwrap] [1]]]]]] [handoff [[spec [[] [pipe]]] [definition []]]] [even? [[spec [[number] [boolean]]]]] [assert [[definition [snapshot [shield] dip swap [drop] [string ["assertion failed "] dip join fail] branch]] [spec [[program] [*]]]]] [rest [[spec [[list] [list]]] [examples [[[[1 2 3] rest] [[2 3]]]]]]] [false [[spec [[] [item]]] [definition [nothing]]]] [pump [[spec [[program [pipe in] [pipe out]] [[pipe in] [pipe out]]]] [definition [wrap [shield] join [[] sink [put] dip swapdown [put] dip [[closed?] any?] dip swap]]]]] [branch [[examples [[[5 true [3 *] [4 +] branch] [15]] [[6 false [3 *] [4 +] branch] [10]]]] [spec [[[program false-branch] [program true-branch] [item condition]] [*]]]]] [rem [[spec [[number number] [number]]] [definition []]]] [/ [[spec [[number number] [number]]]]] [value [[definition [[count 1 =] [first second] [[value] lookup] if]] [examples [[[[[foo 1]] value] [1]] [[[[type url] [value "http://foo.com"]] value] ["http://foo.com"]]]] [spec [[association] [item]]]]] [dec [[spec [[number] [number]]]]] [any? [[spec [[program list] boolean]] [definition [[shielddown] swap prepend [take swap] swap put [dip swap] join wrap [dip or] join [[] [[[empty?] shield] dip swap [or] shielddown] []] dip [execute] recur swap drop]] [examples [[[[2 4 6] [even?] any?] [true]] [[[3 5 7] [even?] any?] [false]] [[[] [even?] any?] [false]] [[[2 4 6] [] any?] [2]] [[11 [3 5 6] [+ odd?] any?] [true 11]] [[-15 [[even?] [positive?] [3 rem 0 =]] [execute] any?] [true -15]]]]]] [and [[examples [[[1 odd? 2 even? and] [true]]]] [spec [[item item] [item]]]]] [pipe-in [[spec [[item] [pipe]]] [definition [[[[type [file] unwrap =] [value file-in]] [[type [stdout] unwrap =] [stdout]]] decide]]]] [nothing [[definition [[]]] [spec [[] [item]]]]] [range [[examples [[[1 5 range] [[1 2 3 4]]]]] [spec [[integer integer] [list]]]]] [take [[spec [[list] [item list]]] [examples [[[["a" "b" "c"] take] [["b" "c"] "a"]]]]]] [count [[examples [[[["a" "b" "c"] count] [3]]]] [spec [[list] [number]]]]] [list? [[examples [[[[1] list?] [true]] [[[] list?] [true]] [[5 list?] [false]]]] [spec [[item] [boolean]]]]] [retry [[spec [[error] [*]]] [examples [[[2 3 "four" * + handle [drop 4] dip retry] [14]]]] [definition [[unwound] lookup execute]]]] [min [[spec [[number number] [number]]] [definition []]]] [spit [[definition [[pipe-in] dip bytes put close drop]] [spec [[item [item target]] []]]]] [ceil [[spec [[number] [integer]]]]] [atom [[definition []] [spec [[item] [pipe]]]]] [join [[examples [[[["a" "b"] ["c" "d"] join] [["a" "b" "c" "d"]]] [["ab" "cd" join] ["abcd"]] [["ab" bytes "cd" bytes join "abcd" bytes =] [true]]]] [spec [[item item] [item]]]]] [odd? [[spec [[number] [boolean]]]]] [file-out [[spec [[string] [pipe]]]]] [drop [[spec [[item] []]] [examples [[[1 2 3 drop] [1 2]] [[1 2 3 [a b c] drop] [1 2 3]]]]]] [tos [[examples [[[[[stack [1 2 3]] [program [[+] step]]] tos] [1]]]] [definition [[stack] lookup first]] [spec [[environment] [item]]]]] [+ [[examples [[[1 2 +] [3]] [[1.1 2.2 +] [3.3]] [[1 2.2 +] [3.2]]]] [spec [[number number] [number]]]]] [second [[spec [[list] [item]]] [examples [[[[4 5 6] second] [5]]]]]] [recover [[examples [[[[+] [drop 1 [+] [drop 2 +] recover] recover] [3]] [5 [1 2 "oh fudge"] [[+] [drop drop] recover] map] [5 [6 7 5]] [[swap] [swap] recover] [swap]]] [definition [[[handle] join] dip [snapshot] dipdown sink inject [first error?] [first swap execute] [evert drop] if]] [spec [[program program] [*]]]]] [inc [[examples [[[1 inc] [2]] [[-1 inc] [0]] [[99 inc] [100]]]] [spec [[number] [number]]]]] [put [[examples [[[[] 1 put] [[1]]] [[[1 2 3] 4 put] [[1 2 3 4]]] [["foo" bytes 32 put string] ["foo "]]]] [spec [[item list] [list]]]]] [true [[spec [[] [word]]]]] [pipe? [[spec [[item] [boolean]]]]] [error? [[spec [[item] [boolean]]]]] [bytes [[spec [[item] [bytes]]]]] [a 1] [while [[examples [[[3 [0 >] [clone dec] while] [3 2 1 0]]]] [spec [[[program body] [program pred]] [*]]] [definition [swap wrap [shield] join clone dipdown join loop]]]] [>= [[spec [[number number] [boolean]]]]] [shielddown [[examples [[[1 2 3 [=] shielddown] [1 2 false]]]] [definition [shield swap drop]] [spec [[program item] [item]]]]] [derivations [[definition [[]]]]] [times [[definition [swap [dec] swap put [dip] join [0 >] swap while drop]] [spec [[[integer howmany] [program body]] [*]]]]] [get [[spec [[item association] [item]]]]] [mod [[spec [[number number] [number]]]]] [<= [[spec [[number number] [boolean]]]]] [toe [[examples [[[[[stack [1 2 3]] [program [[+] step]]] toe] [[+]]]]] [definition [[program] lookup first]] [spec [[environment] [item]]]]]]
#+end_src

Need a way of converting an item to an entry that just pushes that item.

#+begin_src kcats :results code
  1 wrap [[[spec [[[] [item]]]]] [definition]] dip assign 
#+end_src

#+RESULTS:
#+begin_src kcats
[[spec [[[] [item]]]] [definition [1]]]
#+end_src

#+begin_src kcats :results code
  dictionary
  [[spec [[] [item]]]
   [definition [23]]]
  [fooptoopy] swap assign
  [fooptoopy] lookup
#+end_src

#+RESULTS:
#+begin_src kcats
[[spec [[] [item]]] [definition [23]]]
#+end_src

#+begin_src kcats
  [[a [1 1 1]]
   [b [6 7 *]]]
  [a b +] let
#+end_src

*** TODO Error should have actual struct fields :optimization:
It's still implemented as generic Hashmap data field. 

*** TODO Script
**** DONE Cryptographic primitives
***** DONE SHA256
#+begin_src kcats
"foo" bytes hash "fop" bytes hash =
#+end_src

#+RESULTS:
: []

#+begin_src kcats
  ["foo" bytes key] 2 times =
#+end_src

#+RESULTS:
: true

#+begin_src kcats
"foo" bytes key
#+end_src

#+RESULTS:
: [[public #b64 "NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA="] [type elliptic-curve-key] [secret #b64 "LCa0a2j/xo/5m0U8HTBBNBNCLXBkg7+g+YpeiGJm564="]]

***** DONE Signing
#+begin_src kcats :results code
  "foo" bytes key "we attack at dawn" bytes [sign] shield verify
#+end_src

#+RESULTS:
#+begin_src kcats
true
#+end_src

#+begin_src kcats :results code
  "foo" bytes key "we attack at dawn" bytes [sign] shield
  ;; now change the message
  [drop "we attack at dawn" bytes] dip
  verify
#+end_src

#+RESULTS:
#+begin_src kcats
#b64 "d2UgYXR0YWNrIGF0IGRhd24="
#+end_src

We need to be able to construct scripts and their hash. What is the
public key format? We can sort the assoc so that the serialization is
always the same.

#+begin_src kcats
  "foo" bytes key ;; new key
  [secret] unassign ;; discard the secret portion
  [first] sort ;; make sure the assoc is always serialized the same way
  wrap [sink verify] join 
  emit; bytes hash 
#+end_src

#+RESULTS:
#+begin_src kcats
"[[[public #b64 \"NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA=\"] [type elliptic-curve-key]] sink verify]"
#+end_src

So this is the script data. Then the high level script (that's always
the same) is: we've got inputs, a script, and a script hash. If the
hash of the script is equal the given hash, execute the program on the
given input.

#+begin_src kcats
"[[[public #b64 \"NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA=\"] [type elliptic-curve-key]] sink verify]" bytes [hash] shield
#+end_src

#+RESULTS:
#+begin_src kcats
#b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM=" #b64 "W1tbcHVibGljICNiNjQgIk5OSmxlZHUwVm1rK1ZBWnl6NUl2VXQzZzFsTXVOYjhHdmdFNmZGTXZJT0E9Il0gW3R5cGUgZWxsaXB0aWMtY3VydmUta2V5XV0gc2luayB2ZXJpZnld"
#+end_src

Now let's make a signature with that same key
#+begin_src kcats
"foo" bytes key "we attack at dawn" bytes [sign] shield
#+end_src

#+RESULTS:
#+begin_src kcats
#b64 "sAVOx61lJzZAcVMPNFBeDGjzaSej++hqjLctgr1stVcAMk+L1mSZC7nxbtj5+8rYj99zXKLZX6gQzO8bBvvlAA=="
#b64 "d2UgYXR0YWNrIGF0IGRhd24=" [[type elliptic-curve-key]
                                 [secret #b64 "LCa0a2j/xo/5m0U8HTBBNBNCLXBkg7+g+YpeiGJm564="] [public #b64 "NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA="]]
#+end_src

Now use that data and execute the script on it
#+begin_src kcats 
  [#b64 "sAVOx61lJzZAcVMPNFBeDGjzaSej++hqjLctgr1stVcAMk+L1mSZC7nxbtj5+8rYj99zXKLZX6gQzO8bBvvlAA=="
   #b64 "d2UgYXR0YWNrIGF0IGRhd24="] emit
  read first 
  "[[[public #b64 \"NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA=\"] [type elliptic-curve-key]] sink verify]" read first inject first string
#+end_src

#+RESULTS:
#+begin_src kcats
"we attack at dawn"
#+end_src

Now let's make a word 'authenticate', that takes a script hash, a
script, and its args, and returns true if it's the right script and it
validates. Important: check the hash before attempting to execute or
even read the script. That ensures that it's what the sender intended
(doesn't protect against malicious real sender, just malicious impostors).

#+begin_src kcats
  #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM=" ;; script hash
  #b64 "W1tbcHVibGljICNiNjQgIk5OSmxlZHUwVm1rK1ZBWnl6NUl2VXQzZzFsTXVOYjhHdmdFNmZGTXZJT0E9Il0gW3R5cGUgZWxsaXB0aWMtY3VydmUta2V5XV0gc2luayB2ZXJpZnld" ;; script
  ;"foo"
  [#b64 "sAVOx61lJzZAcVMPNFBeDGjzaSej++hqjLctgr1stVcAMk+L1mSZC7nxbtj5+8rYj99zXKLZX6gQzO8bBvvlAA=="
   #b64 "d2UgYXR1YWNrIGF0IGRhd24="
   ] emit bytes ;; the proof (key) as serialized bytes list - the sig and message
  ;; first check hash
  [[[hash =] dive]
   [swap [string read first] both functional [inject] lingo first]
   [drop drop []] if] [[]] recover
   [string] bail ;; gives the message and who it's from
#+end_src

#+RESULTS:
#+begin_src kcats
[] #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM="
#+end_src

Try where the actual script is not what the hash requires, should return =nothing=
#+begin_src kcats 
  #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM=" ;; script hash
  "[true]" emit bytes
  [#b64 "sAVOx61lJzZAcVMPNFBeDGjzaSej++hqjLctgr1stVcAMk+L1mSZC7nxbtj5+8rYj99zXKLZX6gQzO8bBvvlAA=="
   #b64 "d2UgYXR0YWNrIGF0IGRhd24="
   ] ;; data as list
  ;; first check hash
  [[[hash =] dive]
   [swap string read first functional [inject] lingo first]
   [drop drop []] if] [[]] recover
  
#+end_src

#+RESULTS:
#+begin_src kcats
[] #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM="
#+end_src

Try where the signature is invalid by substituting a sig from a different message - same key.
#+begin_src kcats
"foo" bytes key "we attack at dusk" bytes sign
#+end_src

#+RESULTS:
#+begin_src kcats
#b64 "XtOnDCT9+iiHV0BElSAckjo76e2yY3swEOOWo0FfstHgukymw9XXHm7+jLtEBsBjJzo5kyo6058WJ/XPpAe1Aw=="
#+end_src

#+begin_src kcats 
  #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM=" ;; script hash
  #b64 "W1tbcHVibGljICNiNjQgIk5OSmxlZHUwVm1rK1ZBWnl6NUl2VXQzZzFsTXVOYjhHdmdFNmZGTXZJT0E9Il0gW3R5cGUgZWxsaXB0aWMtY3VydmUta2V5XV0gc2luayB2ZXJpZnld" ;; lock
  [#b64 "XtOnDCT9+iiHV0BElSAckjo76e2yY3swEOOWo0FfstHgukymw9XXHm7+jLtEBsBjJzo5kyo6058WJ/XPpAe1Aw=="
   #b64 "d2UgYXR0YWNrIGF0IGRhd24="
   ] ;; data as list
  ;; first check hash
  [[[hash =] dive]
   [swap string read first functional [inject] lingo first]
   [drop drop []] if] [[]] recover

#+end_src

#+RESULTS:
#+begin_src kcats
[] #b64 "SsjPm5GDruW/Ixa/pY97y+Y2JI1+siSETU6yJwlSUvM="
#+end_src

try a dummy script that really does always validate
#+begin_src kcats
  [true] encode hash
  "[true]" encode []
  [[dump [hash =] dive]
   [swap string read first functional [inject] lingo first]
   [drop drop []] if] [[]] recover
#+end_src

#+RESULTS:
#+begin_src kcats
[[] #b64 "W3RydWVd" #b64 "M+LwVX3X2/aNUvQNUQxkH9+m5dpgq8cN+sB9K2tsvM8="]
[] #b64 "M+LwVX3X2/aNUvQNUQxkH9+m5dpgq8cN+sB9K2tsvM8="
#+end_src

***** DONE Make verify return the message
- State "DONE"       from "INPROGRESS" [2023-09-28 Thu 10:43]
one thing I hadn't considered before. We receive this package of
"proof" - proof of what? That this message is from the party
represented by the given script hash. What message?  It's contained in
the proof. The important thing is that if the proof is good *we return
the message*. I think a good contract is that we return the message (as
bytes) if it's valid proof, otherwise =nothing=.  If we only return =true=
on valid proof then we have to embark on digging out the message from
potentially nested proofs. If we just return the message from each
layer (on success) then we don't have to have this separate logic.

I think it's best to just have the contract of the word =verify= do this
for us - there's no reason to just return the truthy value =true= when
the message is a perfectly good truthy value. I suppose signing an
empty byte array could cause confusion (if that were considered
"nothing" which I suppose it should, but currently isn't). But I can't
think of any valid reason to sign 'nothing'.
***** TODO [#A] AES Encryption
***** TODO [#B] Random

**** DONE Pure functional env
#+begin_src kcats
  [[pipe-in pipe-out channel timeout handoff file-in file-out timestamps standard serversocket animate future spit tunnel ] [wrap unassign] step] [1 2 swap] lingo
#+end_src

#+RESULTS:
: 1 2
**** TODO Infinite loop protection
We need to prevent an attacker presenting =true [clone] loop= as their
identity proof, which would never halt. It may be easiest to just
remove all the looping words from the dictionary, but that seems
overly restrictive, when the point is just to limit the resources an
attacker can consume, and we already have a direct solution for that:

#+begin_src kcats
[[program [true [clone] loop]]] environment
#+end_src
*** DONE Multithreading
**** Overview
There are a few major components here:
+ Be able to tell whether an environment can advance. It's basically
  "if there's nothing in the program, it's done, otherwise it can
  run unless it's currently putting/taking from a pipe"
**** Pipes
It's not clear to me what to do about pipes. As soon as we call =take=
(for example) we're going to block the rust thread. In order to use
lightweight "threads" we're going to need a non-blocking check to see
if something can come out (or fit in) the pipe. For things like files
and sockets, it looks like we will need =tokio=.

tokio has Task which can manage this. It looks like tokio has file io
and network io that will automatically yield and allow other tasks to
run.

So then another question is, how to use something like =select= in
kcats. It might be possible to pass in a list of pipes to select and
then return the item that came out (along with the pipe itself i
guess). But this is advanced functionality that probably isn't a high
priority.

I think the basic design here is that each environment is a single
"thread" of execution, and that will map to a tokio Task. Pipe
operations within an env will call the async functions but will
immediately =await=. That should yield to allow other envs to run.

It looks like the =async= will creep all the way up to =axiom::eval=. If
the criteria is that anything we want to be able to pre-empt (if it's
waiting on i/o) needs to be labeled async, then everything up to =eval=
is going to be =async=.

I think that means fns like =f_stack1= etc will need to be async because
the =f= it calls can potentially call i/o. Actually it's probably best
to make new async versions of these so we don't have to make all the
Item fns async too.

We'll also need to think about what to do about dangling
environments - let's say we have the main env, and it spawns env e,
which will feed values back to main. But let's say main is done and
doesn't want any more values from e. Is the entire program done and we
can garbage collect e? My first instinct here is to blow everything
away as soon as main is done. If we don't want to exit we should be
taking from a pipe that won't produce anything until we're ready to
exit. So we're not going to =join= with other environment's tasks.
**** DONE Add tokio as dep
**** DONE Prepare for multithreading
***** DONE Use Arc instead of Rc
Does Arc have =make_mut=?  Yes! So hopefully it will be a drop-in
replacement.
**** DONE Update pipe types for fs and net to use tokio calls
One problem here is that we don't have a trivial way to mix step
functions that are pure vs involving pipes.

If we don't know until runtime what it is, we have to assume async and
there's probably a huge performance hit.

Maybe one way to proceed is to make an =Item= variant =Future=. So if
we're taking from a pipe, we can just put the =Future= on the stack and
continue. Of course, very soon we'll need to access the value and call
=await= on it. 

What then, do we do about =put=? Let's say the pipe is full and the put
needs to wait. We can return the Env but we still need to await sometime.

Maybe in eval-step, we can check if the top item is a Future. If so,
await it. If it returns another Item, replace it. If it returns Unit,
just drop it. Somewhere we'd need a type =Option<Item>= for what the
futures return (None if we're just waiting on a value to put into a
pipe, Item if we're taking)

So will this work in nested envs? I am not sure but I can't think of
why it wouldn't.

If this works then only eval/eval-step will need =async=.
**** DONE Use channel type to implement handoff pipe
***** DONE Use crossbeam channels
mpsc doesn't allow us to clone the receiver (Out) end of the pipe, and
that would seem like a rather sharp corner to users of kcats who
generally aren't too performance sensitive and want simple programs to
"just work".

#+begin_src kcats :results code
  handoff clone
  wrap [5 put "hello" put] join
  [] swap [[program]] dip assign environment animate take [take] dip
#+end_src

#+RESULTS:
#+begin_src kcats
5 "hello" [[type pipe] [handoff todo: id-or-hash here]]
#+end_src

#+RESULTS:
:

One issue here is that we accidentally made a bidirectional channel. I
don't know if that should be the default mode of operation. When we
create a handoff maybe we should really create two stack items: the in
and out. 

The question is, what should be a tunnel? I am not sure single stack
items really should allow both put and take.

The problem with splitting them is it can exascerbate the already
difficult problem of stack manipulation (if indeed you actually need
to read from a file and then write to the same spot... is that
common?)

The benefit is that a process that's supposed to be reading can't
accidentally write, if it doesn't have the In part of the pipe.

For now I think I'm inclined to leave it as-is and see how it goes.
***** TODO Nonblocking eval-step (for inner envs)
It would be nice if calling eval-step on an inner env and having it
block, wouldn't block the outer env (or at least it would be nice if
it were an option not to wait). Maybe =try_eval_step= which tries to
make progress immediately and if it can't, just returns as-is.

There's probably a way to do this by polling the future. using =select!=
with a short timeout future would do it but there's probably a better
way.
***** TODO Combine implementations for net and fs
They're both using AsyncReadExt and AsyncWriteExt methods. The only
difference between them is how the pipes are created. It would be
easier to make pipes for stdin/stdout this way.  I tried it but the
compiler complained about not being able to make trait objects out of
them. Will revisit later.

**** DONE Implement 'spawn' or equavalent
Can probably think of a better name. What we're doing is taking an
environment that's a local piece of data on the stack and spitting it
out to make it its own autonomous thing.
=animate= seems rather fitting.

#+begin_src kcats
 [[program [+ 1 1]]] environment animate 
#+end_src

#+RESULTS:
: 
**** DONE Implement 'future' or equivalent
The idea here is to take an program and run it in its own spawned
env, and when it's done, snapshot the stack and put it into a
pipe and close it. The original env gets the other end of the pipe.

I think the new env should probably inherit the current env's stack.
#+begin_src kcats :results code
  1 2 [+] 
  ;; make a pipe
  handoff swap
  ;; save the stack, including pipe
  [snapshot] dip
  ;; prepare the program for the new env
  ;; end up with [[+ snapshot] dip swap put]
  [snapshot] join wrap [dip swap put drop] join
  ; ;; now we have expr stack
  pair
  [stack program] swap zip environment
  animate take
#+end_src

#+RESULTS:
#+begin_src kcats
[3] [[type pipe] [handoff todo: id-or-hash here]] 2 1
#+end_src

#+begin_src kcats
  1 [2 +] future take swap drop
#+end_src

#+RESULTS:
: [3] 1
*** TODO retry should have opposite argument order :stdlib:consistency:
Currently it expects an error on ToS and then a program beneath. But
it seems like we'd nearly always have to =dip= the program beneath the
error. I think it would be better if =retry= expected the program to fix
the issue on top, and the error beneath.
*** INPROGRESS Support Kademlia DHT
**** DONE XOR
We have a node id (maybe just the i2p destination address?) and we
want to calculate the distance to another node as the XOR
**** INPROGRESS Simple API server
Construct a socket listener, and serve something from a trivial local
database. Disable exploitable words. Catch errors and return to the user.

#+begin_src kcats :tangle examples/api.kcats
  ;; create an API service
  ;; 
  ;; Takes from the stack:
  ;; 
  ;; * a Database (can be a regular data structure for read-only apis),
  ;; or a pipe to an actual (sql or other) database that accepts queries for
  ;; read/write ops
  ;;
  ;; * a program that modifies the dictionary that clients can
  ;; access. It should add words to make interaction easier (for
  ;; example, you might provide a word 'customers' that gets the customers
  ;; db table). It should also remove words that the clients should not be able
  ;; to use - for example, they shouldn't be able to create file or network pipes. 
  ;;
  ;; * a server socket pipe to serve from
  ;;
  ;; The client sends a program to run in a fresh environment where he
  ;; can expect to find:
  ;;
  ;; * The database (either a pipe or data structure)
  ;;
  ;; His program runs and then the resulting stack is returned to him.
  ;; 
  ;; socket listener
  [[type ip-host] [port 12121] [address "127.0.0.1"]] pipe-out

  ;; book db
  "examples/books.kcats" file-out slurp read

  ;functional ;; dictionary modifications, removes any io access 

  ;; API Server code begins here

  ;dictionary swap execute ;; -> new-dict db sock

  ;; start building the environment
  [[program [take ;; the request as bytes
             swap ;; we want the pipe on top so we can dip the user's program under it -> pipe req db
             [string ;; translate to a string -> req-str db
              read first ;; the request program into a data structure -> prog db
              clone emit print ;; log the request
              functional [[execute] [] recover] lingo ;; the program -> items*
              snapshot] dip ;; under the pipe so the user's code has no access
             swap ;; -> response pipe
             emit ;; -> response-str pipe
             bytes ;; -> response-bytes pipe
             put ;; the response into the pipe
             drop ;; close the connection
            ]]] environment ;; -> env new-dict db sock 
  ;[dictionary] float ;; -> new-dict [dictionary] env db sock
  ;assign  ;; -> env db sock

  ;; now just need to assign the stack, which is [pipe db] 
  float ;; -> sock env db
  ;; loop to accept connections and start new env with the db and a pipe
  ;; to take requests and reply
  [[float ;; -> pipe db env
    pair ;; -> stack env
    [stack] swap ;; -> stack ks env
    assign ;; -> env
    environment
    animate ;; let it fly  
   ] shielddown  ;; shielded so as not to consume the db each time
   drop ;; drop whatever the result is of this iteration, we don't need it
  ]

  step ;; accepts incoming connections until killed
#+end_src
**** INPROGRESS Simple API client
#+begin_src kcats
  "localhost" 12121 socket
  [[[title] lookup count 10 <] filter]
  bytes put
  [[take] joiner generate string read] shielddown
  #+end_src

#+RESULTS:
#+begin_src kcats
[[[[[author-first "George"]
    [author-last "Orwell"]
    [title "1984"]
    [year 1949]
    [subjects [government dystopia surveillance totalitarianism freedom]]]
   [[author-first "Charlotte"]
    [author-last "Bronte"]
    [title "Jane Eyre"]
    [year 1847]
    [subjects [love morality society class womanhood independence]]]]]]
#+end_src

**** TODO Kademlia functions
***** TODO COMMENT Distance
takes two hashes, returns the xor distance between them

helper function that takes an int 0-255 and returns the most
significant bit position, eg 33 is 5

#+begin_src kcats :tangle src/kcats/dht.kcats
  [msb [[spec [[int] [int]]]
        [definition [8 swap [1 >] [2 / [dec] dip] while drop]]
        [examples [[[] []]]]]]
#+end_src

#+begin_src kcats :results code
[[msb [8 swap [1 >] [2 / [dec] dip] while drop]]] [63 msb] let
#+end_src

#+begin_src kcats 
[[msb [+]]] [1 2 msb] let
#+end_src

#+begin_src kcats
  [[msb] [[definition [8 swap [1 >] [2 / [dec] dip] while drop]]
          [spec [[number] [number]]]]
   assign]
  ["foo" hash 0 swap ]
  lingo
#+end_src

#+RESULTS:
: 3

#+begin_src kcats
  "bardddddddd" bytes hash "foodf" bytes hash xor ;; inputs
  ;; function begins here
  -1 swap 0 ;; i bs ct 
  [zero?] 
  [drop take [inc] dipdown]
  while
  float 8 * swap
  ;; calculate the number of leading zeros of the first nonzero byte
  8 swap [1 >] [2 / [dec] dip] while drop
  + ;; add them 
  255 swap - ;; subtract from 255
#+end_src

#+RESULTS:
: 253 #b64 "9xFLZf2AmWe7DRojlnYwLsBsq1Iz7mfo8BYH33X3FQ=="

*** DONE Implement print (opposite of read)
We don't have a way to convert objects to their string serialization
Completed as the word emit
*** TODO read and emit don't have quite the same semantics :consistency:
read will read all the bytes and return however many objects were read.
emit will take an object and return its serialization.

There should be some way of round tripping here, maybe a word =read1= or
something that just reads one object. 
*** INPROGRESS [#A] Inconsistent stack handling when encountering error :consistency:
- State "INPROGRESS" from "TODO"       [2023-12-30 Sat 14:17]
Some words pop the arguments off the stack, then if an error is
encountered, throws the error without the args on the stack. Others
leave the args intact. This needs to be consistent.

I would lean towards leaving the args intact so that =retry= is easily applied.
**** TODO 'read' on invalid edn consumes the string argument
It should attempt to parse before popping the item off the stack.
**** TODO Division by zero consumes stack items
=5 0 /= shouldn't consume the =5= and =0= - compare to =1 "2" += behavior
(which leaves items on stack).
*** DONE Inconsistent expression handling when encountering error
- State "DONE"       from "INPROGRESS" [2023-10-15 Sun 15:24]
- State "INPROGRESS" from "TODO"       [2023-10-15 Sun 15:20]
Some errors lose the word on which they occurred. They should be in
the expression still.

#+begin_src kcats
[[]] [foo] unwrap get
#+end_src

#+RESULTS:
#+begin_src kcats
[[type error]
 [reason "type mismatch"]
 [asked [pair]]
 [actual []]
 [unwound [get]]
 [handled true]]
#+end_src

The word =get= should still be in the =unwound= field.

I think this only works correctly when the invalid argument is caught
by spec checking and not in the actual axiom function.

#+begin_src kcats
  1 "" +
#+end_src

#+RESULTS:
#+begin_src kcats
[[reason "type mismatch"]
 [unwound [+]]
 [actual ""]
 [type error]
 [asked [number]]
 [handled true]]
"" 1
#+end_src

Here's an example where the spec is too permissive and the actual
function throws the error.
#+begin_src kcats
1 set
#+end_src

#+RESULTS:
#+begin_src kcats
[[reason "type mismatch"]
 [type error]
 [asked [sized]]
 [unwound [set]]
 [actual 1]
 [handled true]]
#+end_src

The question then is how to fix this? Hopefully this can be fixed
inside =eval_step=. After the function completes, we can check if there
was an error on top (if there wasn't before), and if so, we can replace the 
*** DONE logical enum hierarchy
**** DONE Collection hierarchy
There are read (peek/first) and write operations (pack/put/conj).

Then there are read/write ops like (take/unpack) that mutate the coll
and also return a value.

An In pipe supports only write. An Out pipe supports only
read-write. Pipes in general do not support peeking.

Collections (lists, maps, sets etc) support all of them.

It's not clear how to support overlapping functionality in an enum.
**** DONE pipe as list-like thing
Are both words =put= and =pack= needed (similarly =take= and =unpack=)? Seems
like the former should be all that's needed. That starts to address
that pack/unpack aren't inverse (they shouldn't be because it's really
put/take, and whether you get the last item back or not depends on the
underlying impl - a stack you would, a queue you wouldn't).

Also take in other langs takes a number arg (how many to take). You
could do this as =[take] 5 times=, but that's less efficient. Could
maybe create a new word like =split= or =unload= or something.

The possibility that these words might block, and you don't know
except by the argument type, is a bit off-putting, and maybe these
should be different words? I don't know, the contract is to "take
thing out of other thing" and sometimes that's instant and sometimes
it isn't. (You can ask if the object is a pipe before taking)

=step= should work on pipes. It continues until the pipe closes. How do
we write step in terms of take? The problem is we don't know when to
stop. We know if a collection is empty, but we need to know if a pipe
is closed. The way pipes work now is that if something goes wrong, it
produces an error from the pipe. That's ok for pipes, where we're ok
with the limitation that you can't tell whether the error was
generated during the take or was the actual data sent. However when
dealing with lists, errors are never generated, they're always the
item in the list. We want step to treat both errors and =nothing= as
actual items and not a flag value for error conditions

OK here's a plan: Result<Option<Item>>.  If the pipe is closed, return
Ok(None), if error return Err. The way we differentiate between Errors
in a list and Errors that just happened, is already implemented: via
the 'handled' field of the Error. So if there's a error in the list,
it'll have handled=true and it won't cause the program to
unwind. If it's an actual error reading from the underlying data,
it'll have handled=false and unwind. This will also allow us to
support Nothing in lists and pipes, we won't reserve it as a sentinel
value.
**** DONE Step accepts pipes
**** DONE Set close = drop
**** DONE Remove closed? 
***** DONE Write assemble in terms of step
I don't think we actually need assemble anymore, since this is just a
regular =step= (same as reducing any other iterable).
***** DONE Do something with network pipes
I think this does have a notion of closing.
**** DONE make a polymorphic 'join'
:LOGBOOK:
CLOCK: [2023-01-04 Wed 05:48]--[2023-01-04 Wed 07:26] =>  1:38
:END:
The problem is that it's not symmetrical. If you have two different
types, whose semantics do you use? Sometimes it's obvious regardless
of order. Other times I suppose it's ok to use the first one (the
deeper in the stack).

 - list assoc -> list
 - assoc list -> list
 - list string -> list
 - assoc string -> error
 - assoc assoc -> assoc (merge top into 2nd)

   #+begin_src kcats :results code
     [[a b] [c d]] [[e f]] join
   #+end_src

   #+RESULTS:
   #+begin_src kcats
   [[a b] [c d] [e f]]
   #+end_src

   #+begin_src kcats :results code
     [[a b] [c d]] association [[a f]] association join
   #+end_src

   #+RESULTS:
   #+begin_src kcats
   [[a f] [c d]]
   #+end_src
**** DONE Update spec types to be more abstract
For example, =step= now accepts not only lists but also out-pipes. So
really the spec type for this argument should be =iterable= or
something.

For ideas of what to call these types, how about =in= and =out=? So eg
step takes a program and an out. =put= takes an =in=, =take= takes an =out=. I
am not sure if the =tunnel= concept will be necessary.
*** DONE Support char type
If we don't support char, that breaks the abstraction of a String as a
sort of collection. A collection of what? Characters, not 1-length
strings.

Might have to do something similar with byte, but a byte array can
also be thought of as an array of ints (8 bit unsigned), and we
already have an integer type (even though it holds more bits).
*** DONE implement sleep                                           :stdlib:
helps with debugging multithreading

#+begin_src kcats
1000 sleep
#+end_src

#+RESULTS:
#+begin_src kcats

#+end_src

#+begin_src kcats
timestamps take [1000 timer take] shield drop [take] dive 1000 - 100 within? 
#+end_src

#+RESULTS:
#+begin_src kcats
true [[type out]
      [from systemtime]
      [values [[type integer]
               [units milliseconds]]]]
#+end_src

*** DONE handoff tests
This should block, not error
#+begin_src kcats
handoff take
#+end_src

#+RESULTS:
: [[reason "type mismatch"] [unwound [unpack]] [type error] [asked [list]] [actual [[type pipe] [handoff todo: id-or-hash here]]] [handled true]] [[handoff todo: id-or-hash here] [type pipe]]

#+begin_src kcats
  handoff [1 2 +] future take 
#+end_src

#+RESULTS:
: [3 [[type pipe] [handoff todo: id-or-hash here]]] [[handoff todo: id-or-hash here] [type pipe]] [[handoff todo: id-or-hash here] [type pipe]]

#+begin_src kcats
handoff clone [snapshot] dip swap [1 put 2 put] join [[] [program]] dip assign environment animate take [take] dip +
#+end_src

#+RESULTS:
: 3 [[type pipe] [handoff todo: id-or-hash here]] [[type pipe] [handoff todo: id-or-hash here]]

Should make a word that creates an inner env with access to a handoff also present in the outer env.
#+begin_src kcats
    [[1 2 3] [put] step close] handoff clone ; p h h
    [wrap swap join [[] [program]] dip assign environment animate] dip
    0 swap [+] step
  ;;[snapshot] dip swap  join [[] [program]] dip assign environment animate take [take] dip +
#+end_src

#+RESULTS:
: 6

#+begin_src kcats
    [[1 2 3] [put] step close] handoff clone ; p h h
    [wrap swap join [[] [program]] dip assign environment animate] dip
    0 swap [+] step
  ;;[snapshot] dip swap  join [[] [program]] dip assign environment animate take [take] dip +
#+end_src

Read from one file and write to another 
#+begin_src kcats
  [[file "/tmp/bar"]] pipe-in
  [[file "/tmp/foo"]] pipe-out 
  [put] step
#+end_src

#+RESULTS:
: [[type pipe] [file "/tmp/bar"]]

As a library function
#+begin_src kcats :results code
  "/tmp/bar" "/tmp/foo" file-out [file-in] dip
  [put] step close
#+end_src

#+RESULTS:
#+begin_src kcats
Closing In
[[file "/tmp/bar"] [type pipe]]
#+end_src

*** TODO Performance optimizations :optimization:
**** TODO Compile programs
Here is how it could maybe be done. We already have a type StepFn
(which takes an env and returns a new one, in a future).

So let's say we have a program [1 2 +], and we want to convert that
into a StepFn. We could have a function =compose= and another
=self_insert=, and then call compose([self_insert(1), self_insert(2),
plus]), which would return a StepFn.

Let's look at something more complex:

=1 2 3 4 [+ *] dip=

In this case, the program is the composition of the 5 self-inserts and
dip. But what is self-inserted as the 5th item in this case could be
compiled because we know =dip= follows it. How we know in advance a list
can be compiled is difficult.

Let's try this:

=0 1 [2 3 4] [[+] dip] step=

In this case, the program for =step= is easy to spot, and in turn =dip=.

How about this:

=[+ *] [2 3 4] swap join execute=

We can't know the first two programs can be compiled until later on,
unless we look ahead in the program. Even then we can only know
what arguments end up being passed to join and execute by examining
the words' specs, and even that is not foolproof, as we have wildcard
specs like dip where the stack change is arbitrary.

One major issue with this optimization is that it will stop the
debugger from working properly, unless special care is taken: with the
debugger we can go step by step, but if the function composition is
bundled up, we can only "step over" that function and not "into" it. I
am not sure if it's possible to build this such that we preserve
stepping ability and increase performance substantially.
**** TODO Programs as their own immutable type
Programs executing in a loop are generally not modified (exception -
the =recur= word, which can modify but usually just calls =execute=)- so
when we execute a program with =loop= we don't want to have to clone it
each time through the loop.

Instead we'll do the following: when =loop= places a program into the
program, instead of joining it, it's just going to put it right on
top as a =program= - we may need to differentiate programs that are
active vs meant to be run later. When =eval-step= runs, it sees an
active program on the top of the program, so it calls =next= and gets
a reference to the next word (or None if it's at the end, drop the
program). Then we lookup that word. If it's an axiom, we call it. If
it's derived, we place a new program on the top of the program,
with its PC set to 0. The actual programs are immutable, and behind an
Rc. Each "copy" of the program is just an Rc and a counter. Then all
programs are references except the counter.


example program:
#+begin_src kcats
  [flip drop] ;;0 
  [float swapdown] [flip drop] ;; 0 1
#+end_src
#+begin_src kcats
  [[+] shield] ;; pc 0
  [[+] shield] ;; pc 1 
  [[snapshot] dip inject first] [[+] shield] ;; pc 0 1
  ;; etc
#+end_src

So when printing out the program, we could cheat and only show the
remaining program (instead of a stack of partially executed programs).

*** INPROGRESS Generators                                          :stdlib:
**** DONE Basic functionality and generators
There's the concept of "lazy sequence" that I think maps nicely to
pipes - you can keep calling 'take' and it keeps calculating new
values. Everything it needs is contained in the object, it's not like
a network or filesystem pipe where the data is coming from somewhere
external. But it acts like a pipe.

#+begin_src kcats :results code
  0 []
  ;; the producer - infinite seq of integers
  [[inc clone] dip swap put] ;; -> [1] 1
  ;; the filter condition
  [3 mod 0 =] ;; divisible by 3

  ;; filter-xf
  [pop] swap put [[put] [drop] if] join  

  join ;; [generation filtration] [] 0 
  clone [execute] dip ;;generate ;; [3]
  clone [execute] dip ;;generate ;; [3]
  clone [execute] dip ;;generate ;; [3]
  clone [execute] dip ;;generate ;; [3]
#+end_src

The problem above is =generate= will not produce a value until one
passes the filter. I think filter needs to keep calling =generate= on the xf below it?
#+RESULTS:
#+begin_src kcats
[[inc clone] dip swap put pop [3 mod 0 =] [put] [drop] if] [3] 4
#+end_src

#+RESULTS:
: 1 [[unwound [[[[inc clone] dip swap put [pop [3 mod 0 =]] [put] [drop] if]] unwrap]] [type error] [asked [packable]] [actual 1] [reason "type mismatch"] [handled true]]

#+begin_src kcats :results code
  ;; the impl of filter-xf
  [3 mod 0 =]
  [pop] swap put [[put] [drop] if] join  
#+end_src

#+RESULTS:
#+begin_src kcats
[pop [3 mod 0 =] [put] [drop] if]
#+end_src
 
#+begin_src kcats
  0 [inc clone]
  clone [execute] dip swap
  drop clone [execute] dip swap
#+end_src

#+RESULTS:
: 2 [inc clone] 2

#+begin_src kcats
0 [inc] [] [[generate] dip] ]
#+end_src

#+RESULTS:
: [[generate] dip] [] [inc] 1

#+begin_src kcats :results code
  [
  ;;[1 2 3 4 6 9] liberate ;; produce from list
  1 [2 * clone] ;; infinite list
  ;; increment each
  ;;[3 * 3 -] each
  ;; drop the first few
  5 dropper
  ;; limit the list
  10 taker
  ;; collect into list
  collect
  ] shield
#+end_src

#+RESULTS:
#+begin_src kcats
[64 128 256 512 1024 2048 4096 8192
 16384 32768]
#+end_src

#+begin_src kcats
0 [inc clone] generate
#+end_src

#+RESULTS:
: 1 [inc clone] 1

Now express the debugger interface in terms of generated environment states!

#+begin_src kcats :results code
  ;; the steps of execution
  [[program [0 0 10 1 range [+] step]]] environment
  [[[program] lookup something?]
   [eval-step clone]
   [[]]
   if] ;; the generator, which needs to emit 'nothing' once the program is empty
  [[stack] lookup] each
  50 taker
  laster
  generate
#+end_src

#+RESULTS:
#+begin_src kcats
[[reason word is not defined]
 [unwound [laster generate]]
 [type error]
 [asked [laster]]
 [handled true]] [[positive?] [dec [generate] dive] [[]] if] 50 [generate [[[stack] lookup]
           bail]
 shielddown] [[[program] lookup something?] [eval-step clone]
 [[]] if] [[stack []]
 [program [0 0 10 1 range [+] step]]]
#+end_src

implement 'laster' which returns only the last in the seq
#+begin_src kcats
  0 100 1 range liberate
  laster
  generate
#+end_src

#+begin_src kcats
  [1 2 3] traversal ;; a generator for the list
  [inc] each
  collect
#+end_src
#+RESULTS:
: 99 [generate [] swap [] [swap drop [generate] dip swap] while drop] liberate []

Now implement 'keep' which returns only an item that passes the filter
#+begin_src kcats
  0 [inc clone] 
  [odd?] keep
  1 dropper
  10 taker
  [clone *] each
  collect
#+end_src

#+RESULTS:
: [9 25 49 81 121 169 225 289 361 441] [generate [[clone *] bail] shielddown] [[positive?] [dec [generate] dip swap] [drop []] if] [[[positive?] [[generate drop] dip dec] while [generate swap] dip swapdown swap] bail] 0 [clone [[generate] dip [drop generate] while] dip swap] [[[something?] [odd? not]] [execute] every?] [inc clone] 21
#+begin_src kcats
[odd?] [something?] swap pair wrap [every?] join ;; [odd? not]

#+end_src

#+RESULTS:
: [[[something?] [odd?]] every?]

dropper (almost got it, doesn't detect end of parent stream yet)
#+begin_src kcats :results code
  [0 20 1 range liberate
   5 dropper
   10 taker
   [5 *] each
   [odd?] keep
   collect] shield
#+end_src

#+RESULTS:
#+begin_src kcats
[25 35 45 55 65]
#+end_src

Collect fix
#+begin_src kcats
  [1 2 3] liberate

  generate ;; n
  [] swap clone ;; n n r
  [put ;; r
   [generate] dip ;; r n
   swap clone]  ;; n n r 
  loop drop
#+end_src

#+RESULTS:
: [1 2 3] liberate []

#+begin_src kcats
integers 10 taker collect drop generate 
#+end_src

#+RESULTS:
: [] [[positive?] [dec [generate] dive] [[]] if] 0 [inc clone] 9

**** DONE map
**** DONE filter
**** DONE take
**** DONE drop
#+begin_src kcats
integers 15 taker 10 dropper [+] reduce
#+end_src

#+RESULTS:
: 60 [[[positive?] [[generate drop] dip dec] while [generate swap] dip float] bail] 0 [[positive?] [dec [generate] dive] [[]] if] 0 [inc clone] 14
**** DONE drop-while (skipper)

- State "DONE"       from "INPROGRESS" [2023-11-30 Thu 18:01]
- State "INPROGRESS" from "TODO"       [2023-11-30 Thu 17:28]
  This is what drop-while looks like
#+begin_src kcats
  [] [take]
  [positive?]
  [] ;; the state (whether threshold reached)
  [[] ;; condition - whether we've finished dropping or not 
   [[generate] divedown] ;; true - pass everything else through
   [[[generate] divedown] ;; prime init
    [[[clone] divedown execute] bail] ;; bring pred up and exec it
    [drop] ;; if pred passes drop the value
    prime ;; after this should have value on top
    [drop true] dip ;; set flag
   ] ;; false - generate, check pred, repeat
   if]
  collect
#+end_src
**** DONE take-while (catcher)

- State "DONE"       from "INPROGRESS" [2023-11-30 Thu 18:02]
- State "INPROGRESS" from "TODO"       [2023-11-30 Thu 17:30]

#+begin_src kcats
  [1 2 3 ] [take]
  [positive?]

  [[generate] dive
   [[[clone] dive execute] bail not]
   [drop []]
   when]




  collect
#+end_src

#+RESULTS:
#+begin_src kcats
[1 2 3] [[generate] dive [[[clone] dive execute] bail not] [drop []]
         when]
[positive?] [take] []
#+end_src

**** CANCELED last
**** TODO distinct
depends on sets

The difference between this and just calling =set= is that the result is
still a list, and it preserves the original order, just removes
duplicates. Should be a similar impl to =keep=.
#+begin_src kcats
  [1 1 3] liberate
  [] set ;; state
  [[generate] dive ;; n seen g

   [contains?]
   [put ;; seen g
    [generate] dive] ;; n seen g
   while
  ]
  collect
#+end_src

#+RESULTS:
: [1 1 3] [[generate] dive [contains?] [put [generate] dive] while] [] [take] []

**** DONE partition
- State "DONE"       from "TODO"       [2023-12-07 Thu 17:39]
#+begin_src kcats
  [1 2 3 4 5 6] [take]
  2 []
  [[generate] dive]
  [[[] [drop count inc ]] [execute] every?]
  []
#+end_src

#+RESULTS:
#+begin_src kcats
[] [[[] [drop count inc]]
    [execute] every?]
[[generate] dive]
[] 2 [take] [1 2 3 4 5 6]
#+end_src

**** DONE joiner (aka catenate)
#+begin_src kcats
  [[1 2 3] [4 5 6] [7 8 9]]
  liberate
  [generate [] swap
   []
   [join
    [generate] dip swap] 
   while drop] 
  generate
#+end_src

#+RESULTS:
: [1 2 3 4 5 6 7 8 9] [generate [] swap [] [join [generate] dip swap] while drop] [take] []

**** TODO groupby
#+begin_src kcats :results code
   ["foo" "bar" "baaz" "quux"]
   liberate ;; (the next word foo)
   ;liberate ;; (the first letter f)
   [take]

   wrap
   [shield ;; k v state
    wrap swap  ;;  v k state
    wrap [put] join update] join
   [] association ;; state f
   swap

   cram
#+end_src

#+RESULTS:
#+begin_src kcats
[[\q ["quux"]]
 [\f ["foo"]]
 [\b ["bar" "baaz"]]]
[take] []
#+end_src

Ok so now we just need to insert the [take] program instead of
specifying it inline.

#+begin_src kcats
  [1 2 3 4] [take]
  [odd?] group
#+end_src

#+RESULTS:
#+begin_src kcats
[[true [1 3]]
 [[] [2 4]]]
[take] []
#+end_src

**** CANCELED Map/filter can't access lower stack items
***** Problem
this doesn't work:

#+begin_src kcats :results code
10 [1 2 3] liberate [+] each
#+end_src

#+RESULTS:
#+begin_src kcats
[generate [[+] bail] shielddown] [take] [1 2 3] 10
#+end_src

We should get =[11 12 13]= but it errors out.

The reason is that when + runs, the generators are still on the stack,
in between this mapping function, and the original stack arguments.

We need a way to break out of the generation part of the stack and let
the mapping function access the arguments below it.

I can't immediately think of a good way to do it.

Actually I think that instead of recursively calling generate, and
passing the values back up the stack, there might be a way to build up
the program recursively, and then execute it in one swoop? 

Perhaps we can split each stage into several parts:

+ Generate from the layer below (in which case we obviously need the
  layers below to get the next value)
+ dip underneath the layers to calculate the next value using lower stack items
+ swap the new value to the top of stack
+
***** Debug session
#+begin_src kcats :results code
[[program [10 [1 2 3] liberate [+] each generate]]] environment
advance advance advance advance eval-step [advance] 5 times eval-step
[advance] 2 times [eval-step] 99 times 
#+end_src

#+begin_src kcats
10 [1 2 3] liberate [+] each generate
#+end_src

#+RESULTS:
: [[asked [number]] [reason "type mismatch"] [unwound [+ [[1 [take] [2 3] 10]] unwrap evert first swap drop [[generate [[+] bail] shielddown]] unwrap swap]] [actual [take]] [type error] [handled true]] 1 [take] [2 3] 10


#+begin_src kcats :results code
  [[program [[[program [+]]] environment advance]]] environment advance advance eval-step
#+end_src

#+RESULTS:
#+begin_src kcats
[[program [[[program] lookup count] shield swap [[program] lookup count [[positive?] [<=]] [execute] every?] [eval-step] while swap drop]] [stack [[[stack []] [program [+]]]]]]
#+end_src
***** Resolution
After thinking about this some more, my conclusion:

This is supporting multi-arity mapping functions, which did work in
the original map implementation but they are not supported in other
languages. The way you access multiple values there is by closing over
them. So the way you'd do it in kcats is like so:

#+begin_src kcats
  10 [1 2 3] ;; the extra arg and the list
  [-] ;; the multi-arity map fn
  [clone] dipdown ;; clone the 10
  [swap] unwrap prepend ;; prepend the word swap to the fn so that the 10 ends up beneath the list item
  float prepend ;; prepend the 10
  map
#+end_src

#+RESULTS:
: [9 8 7] 10

In theory we could write a helper function called =capture1= or something that does this for us, so you can write

#+begin_src 
10 [1 2 3] [-] capture1 map
#+end_src

#+begin_src kcats
  10 [1 2 3] ;; the extra arg and the list
  [-] ;; the multi-arity map fn

  [swapdown ;; f i
   [swap] unwrap prepend
   swap prepend] shielddown
  [liberate] dip each collect
#+end_src

#+RESULTS:
: [9 8 7] [generate [[10 swap -] bail] shielddown] [take] [] 10

#+begin_src kcats
  [1 2 "oh fudge"]
  [[5 +]
   [drop 5]
   recover]
  map
#+end_src

#+RESULTS:
: [6 7 5]
***** DONE Add functions to help capture environment for map/filter fns
It's too difficult to do this manually.

#+begin_src kcats
  1 [2 3 4] [+] map
#+end_src

we want to redesign this so that we build the mapping function first:

#+begin_src kcats
  1 [+] capture
  [2 3 4] swap map
#+end_src

#+RESULTS:
#+begin_src kcats
[3 4 5] 1
#+end_src

and the generator equivalent
#+begin_src kcats
5 [* inc] capture [integers 100 dropper 10 taker] dip each collect
#+end_src

#+RESULTS:
#+begin_src kcats
[501 506 511 516 521 526 531 536 541 546]
[generate [[[5] swap [unwrap] dip * inc] bail]
 shielddown]
[[positive?] [dec [generate] dive] [[]] if] 0 [[[positive?] [[generate drop]
                                                             dip dec]
                                                while [generate swap]
                                                dip float]
                                               bail]
0 [inc clone]
109 5
#+end_src

**** DONE Reduce
#+begin_src kcats :results code
  0 [inc clone] 30 taker [+]
  [generate] dive clone ;; acc acc f
  ;;drop [generate] divedown [] [float execute clone] [] if
  ;; acc f g
  [[generate] divedown ;; i acc f g
   [] [float execute clone] [] if]  ;; acc acc f g
  loop
#+end_src

#+begin_src kcats :results code
  0 [inc clone] 10 taker 
  generate clone ;; acc acc 
  ;;drop [generate] divedown [] [float execute clone] [] if
  ;; acc g
  [[generate] dive ;; i acc g
   [] [+ clone] [] if]  ;; acc acc f g
  loop
#+end_src

#+RESULTS:
#+begin_src kcats
55 [[positive?] [dec [generate] dive] [drop []] if] [inc clone] 10
#+end_src

#+begin_src kcats :results code
  0 [inc clone] 3 taker
  [*]
  ;; build the 'then' branch
  [clone] join ;; -> [+ clone]
  ;; build the loop body
  [[generate] dive []] swap put [[] if] join
  ;; generate the first item under the loop body
  [generate clone] dip
  loop
#+end_src

#+RESULTS:
#+begin_src kcats
6 [[positive?] [dec [generate] dive] [[]] if] 0 [inc clone] 3
#+end_src

#+begin_src kcats
1 2 3 4 [+] divedown
#+end_src

#+RESULTS:
: 3 4 3

#+begin_src kcats
1 true [ inc clone 5 < ] loop
#+end_src

#+RESULTS:
: 5

#+begin_src kcats
  integers
  1 dropper ;; start with 1
  1000 taker ;; take items
  [3 *] each
  [odd?] keep
  [+ 37 mod] reduce
#+end_src

#+RESULTS:
: 10 [clone [[generate] dip [drop generate] while] dive] [[[something?] [odd? not]] [execute] every?] [generate [[3 *] bail] shielddown] [[positive?] [dec [generate] dive] [drop []] if] [[[positive?] [[generate drop] dip dec] while [generate swap] dip float] bail] 0 [inc clone] 1000

#+begin_src kcats
1025 8 mod
#+end_src

#+RESULTS:
: 1

let's make an equivalent to =map= (that doesn't require a generator) for ease of use
#+begin_src kcats
0 [1 2 3 4] [+]  
#+end_src

...wait a minute, isn't that just =step=?

**** TODO Generator combinators?
When writing =partition=, it would be nice if we could use generators
*within* a generator. For example, we need to partition a list into
pairs. It would be nice if we could use =2 taker= repeatedly. Let's see if we can make that work:

#+begin_src kcats
  [1 2 3 4 5 6 7] [take]
  [2 taker collect dropdown dropdown] collect

#+end_src

#+RESULTS:
#+begin_src kcats
[[1 2]
 [3 4]
 [5 6]
 [7]]
[2 taker collect dropdown dropdown] [take] []
#+end_src

Ok wow did not expect that to be so easy.

Maybe we can even implement the window shifting version?

#+begin_src kcats 
  [1 2 3 4 5 6 7] [take]
  3 1  ; params: window-size, shift-size, state
  []
  [[[dotake [[taker collect
              dropdown dropdown] ; drop the used-up taker generator
             join divedeep]]
    [doshift [[[count <=]
               [swap 0 slice]
               [[]] if] shield swap]]]
   [
    []
    [over wrap dotake [join doshift] bail]
    [[over] dive wrap dotake swap drop doshift]
    if]
   let]
  collect
#+end_src

#+RESULTS:
#+begin_src kcats
[[1 2 3] [2 3 4] [3 4 5] [4 5 6] [5 6 7]] [[[dotake [[taker collect dropdown dropdown]
                                                     join divedeep]]
                                            [doshift [[[count <=]
                                                       [swap 0 slice] [[]] if]
                                                      shield swap]]]
                                           [[] [over wrap dotake [join doshift]
                                                bail]
                                            [[over] dive wrap dotake swap drop doshift]
                                            if]
                                           let]
[6 7]
1 3 [take] []
#+end_src

**** DONE Applying generator to an existing container
- State "DONE"       from "INPROGRESS" [2023-12-07 Thu 17:40]
- State "INPROGRESS" from "TODO"       [2023-11-10 Fri 16:36]
we commonly have this construct: =[[1 2 3] ... collect] shield=, where
we're transducing a list and we want to just get the result.

#+begin_src kcats
  [1 2 3 4 5] [[odd?] keep] 
  [xform dispenser] label
  [[[poke dispenser] [take] [splice xform] collect] shield]
  template execute
#+end_src

#+RESULTS:
#+begin_src kcats
[1 3 5]
#+end_src

*** DONE Investigate simpler map/filter impls
#+begin_src kcats :results code
7 8 [+] [] [] sink [shielddown dip] decorate [swap] unwrap prepend [swap put] join step
#+end_src

#+RESULTS:
#+begin_src kcats
[+] 8 7
#+end_src

#+begin_src kcats :results code
3 [1 2 3 4 5 6] [drop odd?] [] sink [shield dip] decorate [swap] unwrap prepend [sink [put] [drop] branch] join step
#+end_src

#+RESULTS:
#+begin_src kcats
[1 2 3 4 5 6] 3
#+end_src

*** DONE Allow generator transforms to work on pipes
pipe + [take] = generator
*** INPROGRESS Implement hashset :stdlib:
Once we have this, we can implement stuff like the =distinct= transform
function.

**** INPROGRESS Implement set membership check
Could possibly piggyback on =lookup= here, but the semantics are a
little different (nested sets are not allowed, return value is the
same as the key argument).

Another option is to call it =contains?= and check for membership. The
implementation could accept any Sized type, but it's not obvious how
to handle map types - are we checking just for the key, or key/val
pair? I lean slightly toward just the key, but hard to say. For list
types do we convert or promote to set, or just do a (worst case) full
pass over the elements? Vec[Deque] has a contains method so I'm
inclined to just use that.

***** TODO Substring or subcollection
Included as part of this should be substring and subarray checking. eg
="foobar" "bar" contains?= should return =true=. It's a different behavior
when the member and collection are the same type vs different
types. Should probably error when it's two different collection types,
eg =[1 2 3] [2 3] set contains?= should error.


*** DONE Implement until
like =while= but always runs the body once.

#+begin_src kcats :results code
  64 [50 >] [clone *] ;; until
  swap ;; pred body
  [not] join ;; reverse logic
  [shield] decorate ;; add shield to the pred program -> pred body
  join ;; [body ..  pred]
  true swap ;; run at least once
  loop
#+end_src

#+RESULTS:
#+begin_src kcats
4096
#+end_src

use until in places I wish i'd had it:
laster:
#+begin_src kcats :results code
  [1 2 3 4] liberate
  [] []
  [[empty?]
   ;; l sl
   [swap ;; sl l
    drop ;; l
    [generate] dip ;; sl l
    swap] ;; l sl 
   until swap
   [[]] dipdown] ;; replace the empty state
  collect
#+end_src

joiner
#+begin_src kcats :results code
  [[1 2 3] [4 5 6] [7 8 9]] liberate
  [] []
  [empty?]
  [drop ;; r
   [generate] dip ;; r i
   swap ;; i r
   clone ;; i i r
   [join] dip ;; i r2
  ] until  generate
#+end_src
#+RESULTS:
#+begin_src kcats
[1 2 3 4 5 6 7 8 9] [] [take] []
#+end_src

#+begin_src kcats
[1 2 3 4] liberate generate
#+end_src

#+RESULTS:
: 1 [take] [2 3 4]

*** INPROGRESS Implement sorting                                   :stdlib:

**** TODO Implement partialord
Each type needs to be comparable to another.

#+begin_src kcats
  [["b" 2]["g" 5]["a", 1]["d" 4] ["c" 3]] association sort-indexed
#+end_src

#+RESULTS:
: [1 2 3 4 5]

#+begin_src kcats
  [-2 10 -8 -12 8 0 1 20]
  [5 - abs]
  [clone] swap join
  [ pair] join
  map  sort-indexed 
#+end_src

#+RESULTS:
: Pair is (Int(-2), Int(7))
: Pair is (Int(10), Int(5))
: Pair is (Int(-8), Int(13))
: Pair is (Int(-12), Int(17))
: Pair is (Int(8), Int(3))
: Pair is (Int(0), Int(5))
: Pair is (Int(1), Int(4))
: Pair is (Int(20), Int(15))
: [8 1 10 0 -2 -8 20 -12]

UHOH
#+begin_src kcats
  ["hi" "there" "what" "is" "your" "birthdate" "homeboy"]
  []
  [clone] swap join
  [pair] join
  map  sort-indexed 
#+end_src

#+RESULTS:
: Pair is (Iterable(Sized(String("hi"))), String("hi"))
: Pair is (Iterable(Sized(String("there"))), String("there"))
: Pair is (Iterable(Sized(String("what"))), String("what"))
: Pair is (Iterable(Sized(String("is"))), String("is"))
: Pair is (Iterable(Sized(String("your"))), String("your"))
: Pair is (Iterable(Sized(String("birthdate"))), String("birthdate"))
: Pair is (Iterable(Sized(String("homeboy"))), String("homeboy"))
: ["birthdate" "hi" "homeboy" "is" "there" "what" "your"]

#+begin_src kcats
8 5 - 
#+end_src

#+RESULTS:
: 3

#+begin_src kcats
1 2 [inc] both
#+end_src

#+RESULTS:
: [[reason "word is not defined"] [unwound [both]] [type error] [asked [both]] [handled true]] [inc] 2 1

**** TODO Make floats hashable
This will allow floats to be added to the =KeyItem= enum. Floats are not
normally hashable, because mathematically identical numbers are not
always represented the same way in memory and wouldn't hash the
same. But for the purposes of kcats, I think this doesn't matter. We
can document that you can't expect (10.0 + 10.0) and (15.0 + 5.0) to
be the same map key.

This will then allow a list that contains floats, to be sorted, or be
able to use float values as a sort-by key.

**** TODO Implement compare
Should expose Rust's comparison function. That will allow a native
sort function, for max flexibility (but not performance).

#+begin_src kcats
  "a" "b" compare
#+end_src

#+RESULTS:
: less

#+begin_src kcats
"a" "a" compare
#+end_src

#+RESULTS:
: equal

#+begin_src kcats
["a" "b"] ["a" "c"] compare
#+end_src

#+RESULTS:
: less

#+begin_src kcats
"foo" bytes [1] compare
#+end_src

#+RESULTS:
: less

This should work - the empty set and map maybe can't be compared but Nothing should be in there.
#+begin_src kcats
[] -1000 compare
#+end_src

#+RESULTS:
: less

*** DONE CI on github                                               :alpha:

*** DONE Add a kcats logo to github project page                    :alpha:

*** DONE Add a video snippet of repl interaction to github project page :alpha:

*** INPROGRESS Write an alpha release announcement :alpha:
Show HN: Kcats: A Powerful, Beginner-Friendly, Stack-Based Programming Language
#+begin_src fundamental
  Hello everyone,

  I'm excited to introduce the alpha release of kcats, a fresh take on stack-based programming languages, inspired by the language Joy, designed with simplicity, learnability, and functionality in mind.

  Our aim with kcats is to make it easier for anyone to write short programs for personal automation tasks. We believe that existing languages require learning too many specialized functions and concepts. Kcats addresses these issues by offering a streamlined alternative. Originally conceived as a scripting language for a forthcoming messaging protocol, it's useful for general programming as well.

  Key features of kcats:

      Simplicity: kcats emphasizes fewer, general-purpose tools instead
      of a complex array of specialized ones. Its syntax uses words and
      bracket quotation marks [ and ], and no other symbols. It uses a
      few simple programming concepts including stacks, lists,
      functions, and pipes.

      Introspective: The documentation, examples, and even the entire
      state of a running program, are data that can be queried and
      processed with the language itself. Kcats is its own debugger.

      Powerful and Versatile: Despite its simplicity, kcats is designed
      to be a powerful tool capable of handling a wide range of
      programming tasks. The tools programmers use in other languages
      are there, and built from simple primitives - closures, error
      handling, metaprogramming, multithreading, channels, generators,
      i/o, and serialization.

      A Focus on Tooling: kcats intends to make tool development,
      including IDEs and debuggers, as easy as possible.

  As this is the alpha release, we eagerly welcome all feedback, contributions, and constructive criticisms from the community. We're especially interested in improving the documentation and learning experience.

  Join us in exploring this new language and contribute to making programming more accessible to everyone. Your feedback is essential to making it intuitive and easy to use!

  Please check out our docs and alpha release here:
  https://github.com/skyrod-vactai/kcats

  Happy coding!

  Best, Skyrod
#+end_src
#+begin_src fundamental
  Announcing the Alpha Release of kcats: A Simple, Powerful,
  Beginner-Friendly, Stack-Based Programming Language

  Hello everyone,

  I'm excited to introduce the alpha release of kcats, a fresh take on
  stack-based programming languages, inspired by the language Joy,
  designed with simplicity, learnability, and functionality in mind.

  Our aim with kcats is to make it easier for anyone to write short
  programs for personal automation tasks. We believe that existing
  languages require learning too many specialized functions and
  concepts. Kcats addresses these issues by offering a streamlined
  alternative. Originally conceived as a scripting language for a
  forthcoming messaging protocol, it's useful for general programming as
  well.

  Key features of kcats:

      Simplicity: kcats emphasizes fewer, general-purpose tools instead
      of a complex array of specialized ones. Its syntax uses words and
      bracket quotation marks [ and ], and no other symbols. It uses a
      few simple programming concepts including stacks, lists,
      functions, and pipes.

      Introspective: The documentation, examples, and even the entire
      state of a running program, are data that can be queried and
      processed with the language itself. Kcats is its own debugger.

      Powerful and Versatile: Despite its simplicity, kcats is designed
      to be a powerful tool capable of handling a wide range of
      programming tasks. The tools programmers use in other languages
      are there, and built from simple primitives - closures, error
      handling, metaprogramming, multithreading, channels, generators,
      i/o, and serialization.

      A Focus on Tooling: kcats intends to make tool development,
      including IDEs and debuggers, as easy as possible.

  As this is the alpha release, we eagerly welcome all feedback,
  contributions, and constructive criticisms from the community. We're
  especially interested in improving the documentation and learning
  experience.

  Join us in exploring this new language and contribute to making
  programming more accessible to everyone. Your feedback is essential to
  making it intuitive and easy to use!

  Please check out our alpha release here:
  https://github.com/skyrod-vactai/kcats

  Happy coding!

  Best, Skyrod

#+end_src

*** INPROGRESS Post announcement on various forums                  :alpha:

- [ ] Hacker news
- [X] Reddit r/concatenative
- [ ] Reddit r/programming
- [ ] r/learnprogramming
- [ ] r/coding
- [X] programming.dev
**** DONE Solve some programmer.dev challenges
- State "DONE"       from "TODO"       [2023-10-05 Thu 11:11]
Remove matching parens
#+begin_src kcats
  "[(({})({)(()}]"
  [[\[ \]] [\{ \}] [\( \)]]
  "" float
  [[[last] dive wrap swap [lookup] dip =]
   [drop pop drop]
   [put]
   if] step
   dropdown
#+end_src

#+RESULTS:
#+begin_src kcats
"[(({)(}]"
#+end_src

*** TODO Stream transformation
Problem: kcats doesn't speak http or https or various other protocols
and formats, but rust does. We want to be able to use the complicated
bits of rust, but let kcats decide how to combine them.

Implementation: I think we may need to create a new Rust enum Item
type, that acts as a generator. It has an input method "next_input"
that takes an input chunk which is the result of the generator
beneath, then it either returns None (updated the state, but no new
item yet), or Item (got a new item), or some signal for end of stream,
or Error. So it would have some program with a while loop to
iterate. All such transforms would probably have the same program.

*** DONE [#A] Auto code formatter
- State "DONE"       from "INPROGRESS" [2023-09-22 Fri 09:25]
This is desperately needed, as a big blob of output line-wrapped is
very hard to read.

I am not sure exactly how to determine where line breaks should occur
but literally anything is better than how it is now.
#+begin_src kcats :results code
[[foo bar][baz [[quux floop][toop poop]]]]
#+end_src

#+RESULTS:
#+begin_src kcats
[[foo bar]
 [baz [[quux floop]
       [toop poop]]]]
#+end_src

now test decreasing indent
#+begin_src kcats :results code
  [[foo bar] [baz [[quux floop] [toop poop]]] goop]
#+end_src

#+RESULTS:
#+begin_src kcats
[[foo bar]
 [baz [[quux floop]
       [toop poop]]]
 goop]
#+end_src

#+begin_src kcats :results code
  [[[1 2 3] [4 5 6] [7 8 9]] liberate [] [] [empty?] [drop [generate] dip swap clone [join] dip] until  generate] reverse
#+end_src

#+RESULTS:
#+begin_src kcats
[generate until [drop [generate] dip swap clone [join] dip] [empty?] [] [] liberate
 [[1 2 3] [4 5 6] [7 8 9]]]
#+end_src

#+begin_src kcats :results code
[blahblah blah [blah blah foop foop [toopy] foop foop] toop [blah foop] toopy]
#+end_src

#+RESULTS:
#+begin_src kcats
[blahblah blah [blah blah foop foop [toopy] foop foop] toop [blah foop]
 toopy]
#+end_src

#+begin_src kcats :results code
[[[1 2 =] [false]] [[1 1 =] [true]]]
#+end_src

#+RESULTS:
#+begin_src kcats
[[[1 2 =] [false]]
 [[1 1 =] [true]]]
#+end_src

#+begin_src kcats :results code
[[[] b] [c d]]
#+end_src

#+RESULTS:
#+begin_src kcats
[[[] b]
 [c d]]
#+end_src

#+begin_src kcats :results code
 [[a b] [c d]] "hello"
#+end_src

#+RESULTS:
#+begin_src kcats
"hello" [[a b]
         [c d]]
#+end_src

*** DONE Have eval-step return nothing when program is done
That means eval needs to keep the input until it checks the output.

That may make normal runtime a little less efficient but it means
debuggers and step generators are easy and more efficient.

At that point =stepper= can be removed and we can use =eval-step= in its place. 

(actually stepper still has a use, it just doesn't need to check for =nothing= anymore)

*** INPROGRESS Select from multiple pipes
A basic select (which I call =attend=) is in place. 

**** TODO Attend should leave the pipe list argument
A lot of callers would want to re-use that argument so it shouldn't
need to be shielded by default.

**** TODO Better error handling
There's lots of places where flume could throw an error and we don't
do anything about it.

*** DONE print
It's probably just an alias for something like =[standard] dip bytes put
drop= (write to stdout and then drop the pipe).

*** DONE Remove references to "expression"
I think the expression is just a "program". I suppose *the* program. But
still "program". And yes, it gets shorter as it runs. Still, it's a program.
**** DONE Clear up odd language
There are places in the docs where we used "expression" and "program"
in the same phrase, where now it says program in both places, and it's
confusing.
*** DONE implement breakpoints
**** DONE Fix break arg order
 I think the args are in the wrong order - env should be under the program.
 #+begin_src kcats 
   [[program [1 [1 2 3] [+] step]]] environment
   [[program 0] lookup wrap [+] =]
   [[[swap something?] ;; still running
     [execute not]] ;; check condition not true yet
    [execute]
    every?] ;; break?
   [[eval-step] dip]  ;; evaluate the environment one step
   while
 #+end_src

 #+RESULTS:
 #+begin_src kcats
 [[program 0]
  lookup wrap [+] =]
 [[stack [1 1]]
  [program [+ [2 3]
               [+] step]]]
 #+end_src
**** DONE Test breakpoint
#+begin_src kcats
  [[program [2 [100 breakpoint <] [2 *] while]]] environment [sprint clone] collect
#+end_src

#+RESULTS:
#+begin_src kcats
[[[program [< [[2]] unwrap evert first [[2 *]] unwrap [[[100 breakpoint <] shield]]
               unwrap join loop]]
  [stack [100 2]]]
 [[program [< [[4]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]
  [stack [100 4]]]
 [[program [< [[8]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]
  [stack [100 8]]]
 [[program [< [[16]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]
  [stack [100 16]]]
 [[program [< [[32]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]
  [stack [100 32]]]
 [[program [< [[64]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]
  [stack [100 64]]]
 [[stack [100 128]]
  [program [< [[128]] unwrap evert first [2 * [100 breakpoint <] shield] loop]]]]
[sprint clone]
[]
#+end_src
*** TODO Monitoring tools
**** TODO Reporting back to the mothership
When we spawn/animate, the environment is in its own universe and the
main environment has no way to get any information about it, except by
whatever means are baked into the spawned env's program. Users can
come up with their own scheme of sending some kind of result via a
pipe, of course. But what happens if the program encounters an error?

It would be nice to wrap the program such that it reports the final
stack via a pipe, back to the main environment. And in the main env,
it would be nice to keep a list of those pipes so we can select and
get updates. Note, need to compare and contrast with the existing
mechanism in 'future'.

Another nice tool would be the ability to send the current state back
on demand (sort of like a thread dump) - in the spawned env, call
eval-step until some signal comes in on the pipe from the main env,
then send back a copy of the env. This mechanism could be used later
to implement a monitoring tool.

How to do this: I think a combination of "channel of channels", and
redefinition of =spawn= with =let= should go a long way. The
channel-channel lets new nested envs send back reply channels to the
master env, even if they are deeply nested. Redefining =spawn= lets us
insert the code to send those channels back (by passing in the channel
that leads back to the master env). What would be really handy is
parsing the inner env data to see which references to channels it
contains, seeing whether it's a sender or receiver, and drawing arrows
between envs so users can see they talk to each other.
**** TODO Monitoring UI
We could show not only all the envs and ther recent state (perhaps
dumped every few seconds), we could show arrows between environments
that represent pipes (if two envs have a copy of the same pipe
anywhere in the stack or program, draw an arrow. If one env has a
sender and the other receiver, then show an arrow indicating the
direction of data flow along with the pipe id.

We could also allow views into a particular pipe where we copy the
last handful of values to pass through (this is doable for channels
but probably not file/network pipes).
*** DONE Rewrite future in terms of spawn
#+begin_src kcats
  1 [2 +]
  ;; do other stuff

  handoff swap 
  [snapshot] join ;; return the whole stack
  wrap [dive put drop] join 
  spawn animate

    4 5 + drop

  take dropdown
#+end_src

#+RESULTS:
#+begin_src kcats
[3] 1
#+end_src
*** DONE Re-implement let
I think it's pretty useless as-is. I think it should just be a quicker
version of lingo, where you don't need to specify a spec, and it
always adds items to the dictionary instead of arbitrary changes.

#+begin_src kcats
  [[times5 [5 *]]
   [doubledec [dec dec]]]
  [3 times5 doubledec]
  [[[1] [[[[spec [[] []]]] ;; spec of self-insert
          [definition]] dip
         assign] ;; build a full entry
    update]
   map wrap [join] join] dip
lingo
#+end_src

#+RESULTS:
#+begin_src kcats
13
#+end_src
*** INPROGRESS Native REPL
**** DONE Main mode of reading program from cmdline or file
- State "DONE"       from "TODO"       [2023-10-19 Thu 21:08]
**** INPROGRESS REPL as a kcats program
- State "INPROGRESS" from "TODO"       [2023-10-19 Thu 21:08]
Read inputs from stdin, eval in a nested env, write to stdout.

#+begin_src kcats :tangle repl.kcats
  standard [take] 
  [string] each
  ""
  [[[complete? [swap count <=]]
    [readcount [[take] "\n" split generate
                [[drop] 4 times] dip
                [read first] bail 0 or]]]
   [[[generate] dive [] [join] [drop] if readcount]
    [complete? not]
    [[generate] divedown swapdown join swap] prime]
   let cut]
  [read] each
  collect
#+end_src
*** TODO Words that quote programs instead of executing them
eg =liberate= - it is just =[take]=, so it doesn't actually do anything by
itself. It seems like the quotedness should remain and maybe the word
should always perform the action.

In that case we would have to write =5 [taker]=. I'm not thrilled with
that either, but maybe it's just not a good name.

It does seem like there's an inconsistency having a word quote a
program instead of the caller doing it.

There are certainly words that operate on programs without executing
them (like =each=) but the word is still executing a program vs just
self-inserting one object.

So I think I do have to fix this. I'm just not sure what to do.

I think it will *look* inconsistent to write:
#+begin_src kcats
  integers
  5 [taker]
  [inc] each
#+end_src
People will see that and wonder why =taker= is quoted but not =each=. It
makes sense when you dive into it (each modifies a program and taker
executes a program).
*** DONE Loop combinator that has an initialization program
Like =while= but calls init before starting and each time through the loop. Call it =prime=?
#+begin_src kcats
  timestamps
  [take] [odd?] [dump drop] [clone [execute] dip] dipdown float  join while  
#+end_src
*** DONE startswith/endswith
Note this impl is not efficient because it zips the entire input
before starting comparison. An efficient one would keep an index
counter and compare via lookup.

starts
#+begin_src kcats
"abcd" "" zip [unwrap =] every? 
#+end_src

#+RESULTS:
#+begin_src kcats
true
#+end_src

ends
#+begin_src kcats
"abcd" "abcd" [reverse] both zip [[=] inject first] map [] every? 
#+end_src

#+RESULTS:
#+begin_src kcats
true
#+end_src
*** DONE map doesn't handle nothing values
#+begin_src kcats
[1 2 3 4 5] [odd?] map
#+end_src

#+RESULTS:
#+begin_src kcats
[yes [] yes [] yes]
#+end_src

ughhh should probably revert the change that left map in terms of
generators, because map isn't indefinite and has different handling of =nothing=.
*** DONE Separate formatting from emitting
- State "DONE"       from "INPROGRESS" [2023-10-19 Thu 21:04]
- State "INPROGRESS" from "TODO"       [2023-09-23 Sat 10:29]
*** DONE Fix line breaks with byte literals
- State "DONE"       from "INPROGRESS" [2023-11-19 Sun 19:17]
- State "INPROGRESS" from "TODO"       [2023-11-19 Sun 18:48]
#+begin_src kcats
"foo" bytes key
#+end_src

#+RESULTS:
#+begin_src kcats
[[type elliptic-curve-key]
 [public #b64 "NNJledu0Vmk+VAZyz5IvUt3g1lMuNb8GvgE6fFMvIOA="]
 [secret #b64 "LCa0a2j/xo/5m0U8HTBBNBNCLXBkg7+g+YpeiGJm564="]]
#+end_src

Line break doesn't get added because it thinks =#b64= is an item when
it's really a parsing hint.
*** DONE slice ordered items
- State "DONE"       from "INPROGRESS" [2023-10-19 Thu 21:04]
- State "INPROGRESS" from "TODO"       [2023-10-04 Wed 19:00]
We have indexing to a single subitem but we need to be able to get
ranges too. I think all the underlying types support it so we just
need to expose it.
#+begin_src kcats
"foobarbaz" 3 60 slice
#+end_src

#+RESULTS:
#+begin_src kcats
#+end_src

#+begin_src kcats
[a b c d e f] 2 4 slice
#+end_src

#+RESULTS:
#+begin_src kcats
[c d]
#+end_src

This works but currently panics if you go beyond the valid
indices. Should probably throw a proper error.
*** DONE Templating
- State "DONE"       from "INPROGRESS" [2023-10-19 Thu 21:04]
- State "INPROGRESS" from "DONE"       [2023-10-15 Sun 17:23]
- State "DONE"       from "INPROGRESS" [2023-10-09 Mon 19:04]
- State "INPROGRESS" from "TODO"       [2023-10-09 Mon 19:04]
It would be nice if we could build nested programs as a template
instead of assembling them from parts.

For example lets say I wanted =[foo [[blah] dip] shield]= where =blah= is
a runtime value. Currently I'd have to use =join= to put it together.

#+begin_src kcats
  [[w1 [join]]]
  ["baz" "bar" "foo" [[w1] shield] dip]
  let
#+end_src

#+RESULTS:
#+begin_src kcats
"foo" "bazbar" "bar" "baz"
#+end_src

This isn't quite "templating", since it requires that the =let= scope
encompasses wherever the program is *executed*, and not just where it is
built. What we want is a portable program with =join= substituted for
=w1=. I think recursive replace should be straightforward enough.

#+begin_quote
function template_recurse(template, mapping):
    if template is a list:
        return [template_recurse(item, mapping) for item in template]
    else if template is a placeholder (string) and template in mapping:
        return mapping[template]
    else:
        return template

function template(template, mapping):
    return template_recurse(template, mapping)
#+end_quote

#+begin_src kcats
  [[*a* [foo]] [*b* bar]] [*a* [*b*] c d 1 2 3]
  ; t v
  [list? not] ;; recur condition
  [[word?]
   [[wrap lookup] shield clone [dropdown] [drop] branch dropdown]
   when]
  [] ;; rec1
  [map] recur dropdown
#+end_src

#+RESULTS:
#+begin_src kcats
[[foo] [bar] c d 1 2 3]
#+end_src

Note this currently behaves oddly if you don't declare the mapping as
an association and you have integers in your template. Should probably
fix that, I don't think we intend to replace ints with other values
based on index.

Come to think of it, since the template's values will come from the
stack, I think we should let the caller construct that first and then
put the template on top.

Test this out on the current impl of =until=.
#+begin_src kcats
  2 [even?] [inc]
  pair [pred body] swap zip 
  [[splice body] [[splice pred] not] shield] template
  yes swap loop
#+end_src

#+RESULTS:
#+begin_src kcats
4
#+end_src

Aha, we need =unquote-splicing= ! Well I am not sure how to implement that.

So this is implementing the different syntax for placeholders, =[poke
a]= and =[splice a]=. However splicing is still not supported, as it
requires a different =recur= structure.

#+begin_src kcats
  [[a [foo]] [b bar]] [[poke a] [[poke b] x [poke a]] c d 1 2 3]
  ; t v
  [[subs-point? [[[list?]
                  [count 2 =]
                  [first [poke splice] set swap contains?]]
                 [execute] every?]]]
  [[[[list? not]
     [subs-point?]] [execute] any?];; recur condition
   [[subs-point?]
    [second [wrap lookup] shield clone [dropdown] [drop] branch ]
    when dump]
   [] ;;  rec t v

   ;;ok so the idea here is to just use `step` and the trick is that the
   ;; recur fn needs to have the accumulator out of the way, via `dip`,
   ;; and then the step fn (after the recur is done) should have the acc
   ;; on top again, with the new value beneath, which it can just `swap
   ;; put` or `swap join` i suppose. So we need to append that part to
   ;; the step program.
   [[] sink ;; rec t acc v
    ;; now build the step fn to include the push into acc
    [dip] decorate ;; run the rec with dip (under the acc) 
    [swap] swap join ;; prepend floating the acc to the top before the dipping
    ;; then after the dipping we have acc res 
    [swap put swap] join step
   ]

   ;;drop dump
   ;; rec2 acc t  v
   ;;  
   recur dropdown]
  let
#+end_src

Ok so maybe an easier way to think about this is using =let= and calling
the templating recursively.

#+begin_src kcats
  [[a [foo quux]] [b bar]]
  [[[a b [splice a] c]]]
  ; [[poke a] [[poke b] x [splice a]] c d 1 2 3]
    ; t v
    [[subs-point? [[[list?]
                    [count 2 =]
                    [first [poke splice] set swap contains?]]
                   [execute] every?]]
     [subs [second [wrap lookup] shield clone
            [dropdown] [drop] branch]]
     ;; takes t v
     [template [[[[subs-point?] [[first wrap [poke] =]
                                 [subs wrap]
                                 [subs] if]]
                 [[list?] [[] swap ;;  t acc v
                           [swap [template] dive join] step wrap]]
                 [[yes] [wrap]]]
                decide]]]
    [template]
    let unwrap dropdown
#+end_src

#+RESULTS:
#+begin_src kcats
[[[a b foo quux c]]]
#+end_src

#+begin_src kcats
[[body [inc]] [pred [even?]]]
[[not [splice pred]] shield] template
#+end_src

#+RESULTS:
#+begin_src kcats
[not even? shield]
#+end_src

*** DONE Eliminate 'nothing'
- State "DONE"       from "INPROGRESS" [2023-10-17 Tue 18:58]
The concept is confusing because an empty container is not =nothing=. 
**** DONE Rename nothing? to empty?
- State "DONE"       from "INPROGRESS" [2023-10-17 Tue 18:51]
- State "INPROGRESS" from "TODO"       [2023-10-17 Tue 18:33]
**** DONE Use yes instead of true
- State "DONE"       from "INPROGRESS" [2023-10-17 Tue 18:33]
- State "INPROGRESS" from "TODO"       [2023-10-17 Tue 18:06]
*** DONE Reimplement every? and any? using recursive call
- State "DONE"       from "INPROGRESS" [2023-10-20 Fri 13:48]
- State "INPROGRESS" from "TODO"       [2023-10-20 Fri 13:45]
#+begin_src kcats
    -12 [[negative?] [even?]] [execute]
    [[every? [[swap]
              [[take] dip clone [float [shielddown] dive] dive 
               []
               [drop every?]
               [dropdown dropdown] if]
              [drop drop yes] if]]]
    [every?]
    let 

#+end_src

#+RESULTS:
#+begin_src kcats
yes -12
#+end_src

#+begin_src kcats
  11 [[negative?] [even?]] [execute]
  [[any? [[swap]
            [[take] dip clone [float [shielddown] dive] dive 
             []
             [dropdown dropdown]
             [drop any?] if]
            [drop drop []] if]]]
  [any?]
  let 

#+end_src

#+RESULTS:
#+begin_src kcats
[] 11
#+end_src
*** DONE Remove notion of Nothing from the implementation
- State "DONE"       from "INPROGRESS" [2023-10-21 Sat 11:29]
- State "INPROGRESS" from "TODO"       [2023-10-21 Sat 11:29]
I don't think the performance boost (if any) is worth it. Everywhere
we use NOTHING now, we can just set it to an empty List. And probably
rename it to Empty or something like that. There's no need for the enum variant.
*** TODO Data compression
Data streams that we intend to produce later are going to need
compression - the streams should be as small as possible (they'll be
encrypted later so it's too late to compress them after that). lz4 maybe?
*** DONE improve 'capture' semantics with 'bind'
- State "DONE"       from "INPROGRESS" [2023-12-30 Sat 14:34]
- State "INPROGRESS" from "TODO"       [2023-10-30 Mon 17:02]
The problem is that =capture= as written, doesn't make it obvious that
it's combining the captured items with the stack at the time of
execution - what it actually does is takes the top item from the stack
and puts it on top of the captured stack (dropping the rest of the
current stack).

So what's missing is the 'arity'. Also it's not clear that we always
want the current stack items on top of the captured stack. For
example, what if we wanted a "subtract 5 from" closure:

#+begin_src kcats
[5] [-] capture [10] dip execute 
#+end_src

#+RESULTS:
#+begin_src kcats
-5
#+end_src

What we got was actually "subtract from 5".

But that's easy enough to fix:

#+begin_src kcats
[5] [swap -] capture [10] dip execute 
#+end_src

#+RESULTS:
#+begin_src kcats
5
#+end_src

I suppose what we could do here is keep with the =down=, =deep= convention
and implement =capturedown= and =capturedeep= to represent the 2 and 3
arities.

I am not even sure we need something this complex - joy doesn't seem
to have it at all. What we could do instead is just prepend stuff to a
program, which could be equivalent to =partial= in clojure. So to do
"subtract 5 from":

#+begin_src kcats
10 [-] 5 prepend execute
#+end_src

#+RESULTS:
#+begin_src kcats
5
#+end_src

And to do "subtract from 10":

#+begin_src kcats
  ;6 [-] [10 swap] swap join execute
  6 10 [-] [swap] unwrap prepend swap prepend execute
#+end_src

#+RESULTS:
#+begin_src kcats
4
#+end_src

Of course in many cases we are trying to partial in a value from the stack:

#+begin_src kcats
6 10 [-] [swap] swap join swap prepend execute  

#+end_src

#+RESULTS:
#+begin_src kcats
4
#+end_src

So there's two things happening: inserting values from the stack and
inserting operations to move those values into the correct position on
the stack later.

What words will help us here? I suppose we could do =partial= =partialdown= etc:

#+begin_src kcats
  [[bind [swap prepend]]
   [binddown [[swap] swap join swap prepend]]
   [binddeep [[sink] swap join swap prepend]]]

  ;10 [-] partial [25] dip execute]
  ;[10 5 [-] binddown bind ] ;; bind multiple
  [5 [range] binddeep [10 2] dip execute]
  let
#+end_src

#+RESULTS:
#+begin_src kcats
[5 7 9]
#+end_src

One question here is whether the binding should consume the value from
the stack, I think it should and if the caller doesn't want that he
can use the =shielddown= combinator.

Ok let's see if we can go back and use this in existing code.
*** DONE Implement more functions from Joy
- State "DONE"       from "TODO"       [2023-10-30 Mon 16:31]
+ over
+ dupd (clonedown)
+ dupdd (clonedeep)
+ tuck (opposite of over: under) 
*** DONE implement 'label'
- State "DONE"       from "TODO"       [2023-11-10 Fri 14:05]
We're "labeling" items on the stack and get a map. eg
="Alice" 23 "123 Main St" [address age name] label=

The question is do we label from stack's top to bottom or the other
direction? Let's try "top first" - if we have a literal we can just
write a map literal to start, so i think this is ok.

#+begin_src kcats 
  "Alice" 23 "123 Main St" [address age name]
  [] swap ;; labels acc
  [wrap float assign] step
#+end_src

#+RESULTS:
#+begin_src kcats
[[address "123 Main St"]
 [age 23]
 [name "Alice"]]
#+end_src
*** DONE Refactor bytes as 'encode'
- State "DONE"       from "INPROGRESS" [2023-12-02 Sat 15:12]
- State "INPROGRESS" from "TODO"       [2023-12-02 Sat 14:44]
Make this a multimethod
*** TODO Multimethod improvements
**** TODO Convert to multi
**** DONE Refactor addmethod
- State "DONE"       from "INPROGRESS" [2023-12-04 Mon 16:24]
- State "INPROGRESS" from "TODO"       [2023-12-04 Mon 16:13]
#+begin_src kcats
  [[[[count 3 >] ["foo" put]]
    [[not] ["bar" put]]] decide]
  [count 1 =] [rest]
  pair ;; [c b] [[[...]] decide]
  wrap [prepend] join [[0]] dip update
#+end_src

#+RESULTS:
#+begin_src kcats
[[[[count 1 =] [rest]]
  [[count 3 >] ["foo" put]]
  [[not] ["bar" put]]]
 decide]
#+end_src

#+begin_src kcats
  [[hash definition]
   [[number?] ["foo" hash] addmethod] update]
  [1 hash]
  lingo
#+end_src

#+RESULTS:
#+begin_src kcats
#+end_src

**** DONE ismulti?
- State "DONE"       from "TODO"       [2023-12-04 Mon 16:25]
**** 
*** TODO Database
**** Simple Test
#+begin_src kcats
"create table Person (firstName text not null, lastName text not null, email text)" database 
#+end_src

#+RESULTS:
#+begin_src kcats
[]
#+end_src

#+begin_src kcats
"insert into Person (firstName, lastName, email) values ('Skywife', 'Vactai', 'skywife@skyrod.me')" database 
#+end_src

#+RESULTS:
#+begin_src kcats
[]
#+end_src

#+begin_src kcats
  "select (firstName) from Person where lastName='Vactai'" database 
#+end_src

#+RESULTS:
#+begin_src kcats
[[[firstName "Skyrod"]] [[firstName "Skykid"]] [[firstName "Skywife"]]]
#+end_src


#+begin_src kcats
dictionary [swap] lookup
#+end_src

#+RESULTS:
#+begin_src kcats
[[definition builtin-function]
 [examples [[[1 2 3 swap] [1 3 2]]]]
 [spec [[[item a]
         [item b]]
        [[item b]
         [item a]]]]]
#+end_src
**** Books db
#+begin_src kcats
  [[author-first "George"] [author-last "Orwell"] [title "1984"] [year 1949] [subjects [government dystopia surveillance totalitarianism freedom]]]
  [[author-first "Aldous"] [author-last "Huxley"] [title "Brave New World"] [year 1932] [subjects [society technology dystopia happiness drugs]]]
  [[author-first "F. Scott"] [author-last "Fitzgerald"] [title "The Great Gatsby"] [year 1925] [subjects [wealth love obsession american-dream tragedy]]]
  [[author-first "J.D."] [author-last "Salinger"] [title "The Catcher in the Rye"] [year 1951] [subjects [adolescence alienation innocence society adulthood]]]
  [[author-first "Jane"] [author-last "Austen"] [title "Pride and Prejudice"] [year 1813] [subjects [love marriage society class reputation]]]
  [[author-first "Mary"] [author-last "Shelley"] [title "Frankenstein"] [year 1818] [subjects [creation science responsibility monster humanity]]]
  [[author-first "John"] [author-last "Steinbeck"] [title "Of Mice and Men"] [year 1937] [subjects [friendship dream loneliness society tragedy]]]
  [[author-first "Ernest"] [author-last "Hemingway"] [title "The Old Man and the Sea"] [year 1952] [subjects [endurance nature old-age fisherman sea]]]
  [[author-first "Harper"] [author-last "Lee"] [title "To Kill a Mockingbird"] [year 1960] [subjects [racism innocence morality law childhood]]]
  [[author-first "J.R.R."] [author-last "Tolkien"] [title "The Lord of the Rings"] [year 1954] [subjects [adventure elf dwarf hobbit ring journey magic evil]]]
  [[author-first "Joseph"] [author-last "Conrad"] [title "Heart of Darkness"] [year 1899] [subjects [colonization africa journey morality darkness europeans]]]
  [[author-first "Leo"] [author-last "Tolstoy"] [title "War and Peace"] [year 1869] [subjects [war peace society history love aristocracy]]]
  [[author-first "Homer"] [title "The Odyssey"] [year -800] [subjects [journey odyssey homecoming gods heroism adventure]]]
  [[author-first "Charlotte"] [author-last "Bronte"] [title "Jane Eyre"] [year 1847] [subjects [love morality society class womanhood independence]]]
  [[author-first "Mark"] [author-last "Twain"] [title "Adventures of Huckleberry Finn"] [year 1884] [subjects [adventure racism slavery morality friendship river]]]
  [[author-first "Ray"] [author-last "Bradbury"] [title "Fahrenheit 451"] [year 1953] [subjects [censorship knowledge books society dystopia future]]]
  [[author-first "Charles"] [author-last "Dickens"] [title "A Tale of Two Cities"] [year 1859] [subjects [revolution love sacrifice resurrection society history]]]
  [[author-first "William"] [author-last "Golding"] [title "Lord of the Flies"] [year 1954] [subjects [society civilization savagery childhood morality island]]]
  [[author-first "Miguel de"] [author-last "Cervantes"] [title "Don Quixote"] [year 1605] [subjects [adventure idealism reality knight insanity literature]]]
  [[author-first "H.G."] [author-last "Wells"] [title "The War of the Worlds"] [year 1898] [subjects [invasion aliens society technology war humanity]]]

#+end_src

#+begin_src kcats
  db [take]
  [[[type [book] unwrap =]
    [[publishYear] lookup 1940 >=]]
   [execute] every?]
  keep
#+end_src
**** EAVTO (entity, attribute, value, time, observer)
Here's a database of the most basic and abstract observations
(ignoring time and observer for now - those are all "now" and "me").

Down to a certain level, all attributes are also entities of their
own, but at some point they have to be either axiomatic or
circular. In the table below =type= and =format= are axiomatic.

| Entity    | Attribute    | Value           |
|-----------+--------------+-----------------|
| Alice     | street       | 123 Fake St     |
| Alice     | email        | alice@alice.com |
| Alice     | birthdate    | 1/1/1980        |
| street    | type         | attribute       |
| street    | format       | string          |
| email     | type         | attribute       |
| email     | format       | string          |
| birthdate | type         | attribute       |
| birthdate | format       | integer         |
| Alice     | relationship | Bob             |
| Alice-Bob | type         | relationship    |
| Alice-Bob | nature       | friends         |
| Alice-Bob | trust        | 5/10            |

Let's create an EAV table
#+begin_src kcats
  "CREATE TABLE EAV
  ( Entity STRING,
    Attribute STRING,
    ValueString TEXT,
    ValueInteger INTEGER,
    ValueReal REAL,
    ValueBlob BLOB,
    ValueNumeric NUMERIC );" database 
#+end_src

#+RESULTS:
#+begin_src kcats
[]
#+end_src

Create indices (should really do this for all the columns)

#+begin_src kcats
"CREATE INDEX idx_entity ON EAV (Entity);
CREATE INDEX idx_attribute ON EAV (Attribute);
CREATE INDEX idx_valuestring ON EAV (ValueString);
" database
#+end_src

#+RESULTS:
#+begin_src kcats
[]
#+end_src

#+begin_src kcats
  "INSERT INTO EAV (Entity, Attribute, ValueString, ValueInteger, ValueReal, ValueBlob, ValueNumeric) VALUES
  ('Book1', 'Title', '1984', NULL, NULL, NULL, NULL),
  ('Book1', 'Author', 'George Orwell', NULL, NULL, NULL, NULL),
  ('Book1', 'Year', NULL, 1949, NULL, NULL, NULL),
  ('Book2', 'Title', 'To Kill a Mockingbird', NULL, NULL, NULL, NULL),
  ('Book2', 'Author', 'Harper Lee', NULL, NULL, NULL, NULL),
  ('Book2', 'Year', NULL, 1960, NULL, NULL, NULL),
  ('Author1', 'Name', 'George Orwell', NULL, NULL, NULL, NULL),
  ('Author1', 'BirthYear', NULL, 1903, NULL, NULL, NULL),
  ('Author2', 'Name', 'Harper Lee', NULL, NULL, NULL, NULL),
  ('Author2', 'BirthYear', NULL, 1926, NULL, NULL, NULL); " database
#+end_src

#+RESULTS:
#+begin_src kcats
[]
#+end_src

#+begin_src kcats
  "SELECT e1.ValueString AS Title
  FROM EAV e1
  JOIN EAV e2 ON e1.Entity = e2.Entity
  WHERE e1.Attribute = 'Title'
    AND e2.Attribute = 'Author'
    AND e2.ValueString = 'George Orwell';
  " database
#+end_src

#+RESULTS:
#+begin_src kcats
[[[Title "1984"]]]
#+end_src

#+begin_src kcats
  "SELECT e1.Entity as id, e1.Attribute, e1.ValueString, e1.ValueInteger, e1.ValueReal, e1.ValueBlob, e1.ValueNumeric
  FROM EAV e1
  INNER JOIN (
      SELECT Entity 
      FROM EAV 
      WHERE Attribute = 'Author' AND ValueString = 'George Orwell'
  ) AS e2 ON e1.Entity = e2.Entity;" database
#+end_src

#+RESULTS:
#+begin_src kcats
[[[ValueReal []]
  [ValueNumeric []]
  [ValueInteger []]
  [id "Book1"]
  [ValueString "George Orwell"]
  [Attribute "Author"]
  [ValueBlob []]]
 [[ValueBlob []]
  [ValueReal []]
  [ValueString "1984"]
  [id "Book1"]
  [ValueInteger []]
  [Attribute "Title"]
  [ValueNumeric []]]
 [[ValueBlob []]
  [ValueReal []]
  [ValueNumeric []]
  [ValueString []]
  [id "Book1"]
  [Attribute "Year"]
  [ValueInteger 1949]]]
#+end_src
**** Attribute database using CozoDB
The idea here is to ignore identity in the database and make that the
responsibility of the client. The database only links attributes, and
has nothing to say about whether a given entity is the "same" entity
as another. It only says "something has both the color brown and the
height 1.5m". What attributes are sufficient to establish identity is
not part of the database. It's just a graph connecting attribute/value
pairs.
*****  First experiments
#+begin_src fundamental
  ?[a_attr, a_val, b_attr, b_val] <-
  [
    ["author", "George Orwell", "title", "1984"],
    ["author", "George Orwell", "title", "Animal Farm"],
    ["author", "George Orwell", "genre", "dystopia"],
    ["genre", "dystopia", "title", "1984"],
    ["created", "1949", "title", "1984"],
    ["format", "book", "title", "1984"],
    ["language", "english", "title", "1984"],
    ["name", "George Orwell", "created", "1905"],
    ["name", "George Orwell", "sex", "male"]
  ]

  :replace also {a_attr, a_val, b_attr, b_val}
#+end_src

#+begin_src restclient
  POST http://127.0.0.1:3000/text-query
  Content-Type: application/json

  {"script": ":create attributes { a_attr: String, a_val: Any, b_attr: String, b_val: Any}",
   "params": {}}
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "headers": [
    "status"
  ],
  "next": null,
  "ok": true,
  "rows": [
    [
      "OK"
    ]
  ],
  "took": 0.016436112
}
// POST http://127.0.0.1:3000/text-query
// HTTP/1.1 200 OK
// content-type: application/json
// content-length: 79
// access-control-allow-origin: *
// vary: origin
// vary: access-control-request-method
// vary: access-control-request-headers
// date: Tue, 19 Dec 2023 23:25:15 GMT
// Request duration: 0.018199s
#+END_SRC

#+begin_src restclient
  POST http://127.0.0.1:3000/text-query
  Content-Type: application/json

  {"script": "?[a_attr, a_val, b_attr, b_val] <- [['author', 'George Orwell', 'title', '1984'], ['author', 'George Orwell', 'title', 'Animal Farm'], ['author', 'George Orwell', 'genre', 'dystopia'], ['genre', 'dystopia', 'title', '1984'], ['created', '1949', 'title', '1984'], ['format', 'book', 'title', '1984'], ['language', 'english', 'title', '1984'], ['name', 'George Orwell', 'created', '1905'], ['name', 'George Orwell', 'sex', 'male']] :put attributes",
     "params": {}}
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "headers": [
    "status"
  ],
  "next": null,
  "ok": true,
  "rows": [
    [
      "OK"
    ]
  ],
  "took": 0.011967695
}
// POST http://127.0.0.1:3000/text-query
// HTTP/1.1 200 OK
// content-type: application/json
// vary: origin
// vary: access-control-request-method
// vary: access-control-request-headers
// access-control-allow-origin: *
// transfer-encoding: chunked
// date: Tue, 19 Dec 2023 23:39:51 GMT
// Request duration: 0.064371s
#+END_SRC

"When was the author of 1984 born?"
#+begin_src restclient
  POST http://127.0.0.1:3000/text-query
  Content-Type: application/json

  {"script": "linked[a, v, oa, ov] := *attributes[a, v, oa, ov] or *attributes[oa, ov, a, v]\n?[born] := linked['title', '1984', 'author', author], linked['created', born, 'name', author]", 
   "params": {}}
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "headers": [
    "born"
  ],
  "next": null,
  "ok": true,
  "rows": [
    [
      "1905"
    ]
  ],
  "took": 0.001707655
}
// POST http://127.0.0.1:3000/text-query
// HTTP/1.1 200 OK
// content-type: application/json
// content-length: 79
// access-control-allow-origin: *
// vary: origin
// vary: access-control-request-method
// vary: access-control-request-headers
// date: Tue, 19 Dec 2023 23:56:27 GMT
// Request duration: 0.002975s
#+END_SRC

"What books did the author of 1984 write?"
#+begin_src restclient
  POST http://127.0.0.1:3000/text-query
  Content-Type: application/json

  {"script": "linked[a, v, oa, ov] := *attributes[a, v, oa, ov] or *attributes[oa, ov, a, v]\n?[title] := linked['title', '1984', 'author', author], linked['title', title, 'author', author]", 
   "params": {}}
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "headers": [
    "title"
  ],
  "next": null,
  "ok": true,
  "rows": [
    [
      "1984"
    ],
    [
      "Animal Farm"
    ]
  ],
  "took": 0.001771184
}
// POST http://127.0.0.1:3000/text-query
// HTTP/1.1 200 OK
// content-type: application/json
// content-length: 96
// access-control-allow-origin: *
// vary: origin
// vary: access-control-request-method
// vary: access-control-request-headers
// date: Wed, 20 Dec 2023 00:05:26 GMT
// Request duration: 0.002879s
#+END_SRC



How to write that query in kcats format?
#+begin_src kcats
  [[title "1984" author a?]
   [created c? name a?]
   [c?]]
#+end_src

Everything about Orwell
#+begin_src restclient
  POST http://127.0.0.1:3000/text-query
  Content-Type: application/json

  {"script": "linked[a, v, oa, ov] := *attributes[a, v, oa, ov] or *attributes[oa, ov, a, v]\n?[a1, v, a2] := linked[a1, v, a2, 'George Orwell'] ", 
   "params": {}}
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "headers": [
    "a1",
    "v",
    "a2"
  ],
  "next": null,
  "ok": true,
  "rows": [
    [
      "created",
      "1905",
      "name"
    ],
    [
      "genre",
      "dystopia",
      "author"
    ],
    [
      "sex",
      "male",
      "name"
    ],
    [
      "title",
      "1984",
      "author"
    ],
    [
      "title",
      "Animal Farm",
      "author"
    ]
  ],
  "took": 0.00130435
}
// POST http://127.0.0.1:3000/text-query
// HTTP/1.1 200 OK
// content-type: application/json
// content-length: 213
// access-control-allow-origin: *
// vary: origin
// vary: access-control-request-method
// vary: access-control-request-headers
// date: Wed, 20 Dec 2023 00:14:07 GMT
// Request duration: 0.002445s
#+END_SRC

***** Using org-mode eval
Now we have an org-mode evaluator!
#+begin_src cozodb :results value table
{:create attributes {a_attr: String, b_attr: String, a_val: Any, b_val: Any}}
#+end_src

#+RESULTS:
| OK |

#+begin_src cozodb :results value table
  %import /home/v/workspace/kcats/countries-cozo.json
#+end_src

#+RESULTS:
| [31mparser::pest[0m |


#+begin_src cozodb
::index create attributes:rev {b_attr, a_attr, b_val, a_val}
#+end_src

#+begin_src cozodb :results value table
  linked[a, v, oa, ov] := *attributes[a, v, oa, ov] or *attributes[oa, ov, a, v]
  ?[title] := linked['title', '1984', 'author', author], linked['title', title, 'author', author]
#+end_src

#+RESULTS:

What movies has robert de niro been in?
#+begin_src cozodb
linked[a, v, oa, ov] := *attributes[a, v, oa, ov] or *attributes[oa, ov, a, v]
?[title] := linked['title', title, 'cast', cast], actor in cast, actor == 'Robert De Niro'
#+end_src

#+RESULTS:
| GoodFellas                    |
| Jackie Brown                  |
| Mean Streets                  |
| Midnight Run                  |
| Once Upon a Time in America   |
| Raging Bull                   |
| Righteous Kill                |
| Silver Linings Playbook       |
| Stardust                      |
| The Irishman                  |
| The Irishman: In Conversation |
| The Score                     |



What directors has robert de niro worked with?
#+begin_src cozodb
  linked[a, oa, v, ov] := *attributes[a, oa, v, ov] or *attributes[oa, a, ov, v]
  ?[director] := linked['title', 'cast', title, cast],
                 linked['title', 'director', title, director], 
                 actor in cast, actor = 'Robert De Niro' 
#+end_src

#+RESULTS:
|                   |
| David O. Russell  |
| Frank Oz          |
| Jon Avnet         |
| Martin Brest      |
| Martin Scorsese   |
| Matthew Vaughn    |
| Quentin Tarantino |
| Sergio Leone      |


What movies had both Adam Sandler and David Spade?
#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[title] := linked['title', title, 'cast', cast],
              actor1 in cast,
              actor2 in cast,
              actor1 == 'Adam Sandler', actor2 == 'David Spade'
#+end_src

#+RESULTS:
| Grown Ups                             |
| Hotel Transylvania 3: Summer Vacation |
| The Do-Over                           |
| The Ridiculous 6                      |

Adam Sandler's 5 most recent movies
#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
   ?[title, year] := linked['title', title, 'cast', cast],
                     linked['release_year', year, 'title', title],
                     actor in cast, actor == 'Adam Sandler',
   :limit 5
   :order -year
#+end_src

#+RESULTS:
| Hubie Halloween                       | 2020 |
| Murder Mystery                        | 2019 |
| Uncut Gems                            | 2019 |
| ADAM SANDLER 100% FRESH               | 2018 |
| Hotel Transylvania 3: Summer Vacation | 2018 |

What actors have been in the most movies with Sandler
#+begin_src cozodb
  ?[count(title), actor2] := linked['title', title, 'cast', cast],
                    target = 'Adam Sandler',
                    actor1 in cast, actor1 == target,
                    actor2 in cast, actor2 != target
  :limit 10
  :order -count(title)
#+end_src

#+RESULTS:
| 7 | Rob Schneider     |
| 6 | Allen Covert      |
| 5 | Nick Swardson     |
| 5 | Steve Buscemi     |
| 4 | David Spade       |
| 4 | Kevin James       |
| 3 | Blake Clark       |
| 3 | Colin Quinn       |
| 3 | John Turturro     |
| 3 | Jonathan Loughran |


#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[attr, val] := linked['title', 'Murder Mystery', attr, val]
#+end_src

#+RESULTS:
| cast         | [Adam Sandler Jennifer Aniston Luke Evans Gemma Arterton Adeel Akhtar Luis Gerardo Méndez Dany Boon Terence Stamp]                               |
| country      | United States                                                                                                                                    |
| description  | On a long-awaited trip to Europe, a New York City cop and his hairdresser wife scramble to solve a baffling murder aboard a billionaire's yacht. |
| director     | Kyle Newacheck                                                                                                                                   |
| duration     | 98                                                                                                                                               |
| rating       | PG-13                                                                                                                                            |
| release_year | 2019                                                                                                                                             |
| type         | Movie                                                                                                                                            |

10 longest movie titles
#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[title, ct] := linked['title', title, _, _], ct = length(title)
  :limit 10
  :order -ct
#+end_src 

#+RESULTS:
| Jim & Andy: The Great Beyond - Featuring a Very Special, Contractually Obligated Mention of Tony Clifton | 104 |
| Ken Burns Presents: College Behind Bars: A Film by Lynn Novick and Produced by Sarah Botstein  |  93 |
| Mike Birbiglia: What I Should Have Said Was Nothing: Tales from My Secret Public Journal       |  88 |
| The Power of Grayskull: The Definitive History of He-Man and the Masters of the Universe       |  88 |
| Steve Martin and Martin Short: An Evening You Will Forget for the Rest of Your Life            |  83 |
| Cultivating the Seas: History and Future of the Full-Cycle Cultured Kindai Tuna                |  79 |
| Power Rangers Samurai: Christmas Together, Friends Forever (Christmas Special)                 |  78 |
| Willy and the Guardians of the Lake: Tales from the Lakeside Winter Adventure                  |  77 |
| Ya no estoy aquí: Una conversación entre Guillermo del Toro y Alfonso Cuarón                   |  76 |
| The Road to El Camino: Behind the Scenes of El Camino: A Breaking Bad Movie                    |  75 |

#+begin_src cozodb
  linked[a, oa, v,  ov] := *attributes[a, oa, v, ov] or *attributes[oa, a, v, ov]
  ?[count(title)] := linked['title', title, _, _], 
#+end_src 

#+RESULTS:
| 70456 |

#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[title] := linked['director', 'Steven Spielberg', 'title', title ], 
#+end_src 

#+RESULTS:
| Catch Me If You Can                                |
| Indiana Jones and the Kingdom of the Crystal Skull |
| Indiana Jones and the Last Crusade                 |
| Indiana Jones and the Raiders of the Lost Ark      |
| Indiana Jones and the Temple of Doom               |
| Jaws                                               |
| Lincoln                                            |
| Schindler's List                                   |
| The Adventures of Tintin                           |
| The BFG                                            |
| War Horse                                          |

#+begin_src cozodb
  ::explain {
            linked[a, v, oa, ov] := *attributes[a, v, oa, ov]
  ?[title] := linked['title', title, 'director', 'Steven Spielberg'] }
#+end_src 

#+RESULTS:
| 0 | 0 | ?      | 3         |     load_mem | ?                  | S.0.0                              | :null                             | []                 | [*1 *2 *3]          |            |
| 0 | 0 | ?      | 2         |     load_mem | linked             | Mbfbb                              | :null                             | []                 | [**0 title **1 **2] |            |
| 0 | 0 | ?      | 1         | mem_mat_join | :null              | ((*1 . **0) (*2 . **1) (*3 . **2)) | :null                             | [title]            |                     |            |
| 0 | 0 | ?      | 0         |          out | :null              | :null                              | :null                             | [title]            |                     |            |
| 0 | 1 | linked | Mbfbb     |            4 | load_mem           | linked                             | S.0.0bfbb                         | :null              | []                  | [a oa ov]  |
| 0 | 1 | linked | Mbfbb     |            3 | load_stored        | :attributes                        | :null                             | []                 | [**0 v **1 **2]     |            |
| 0 | 1 | linked | Mbfbb     |            2 | stored_mat_join    | :null                              | ((a . **0) (oa . **1) (ov . **2)) | :null              | [a oa ov v]         |            |
| 0 | 1 | linked | Mbfbb     |            1 | reorder            | :null                              | :null                             | :null              | [a v oa ov]         |            |
| 0 | 1 | linked | Mbfbb     |            0 | out                | :null                              | :null                             | :null              | [a v oa ov]         |            |
| 0 | 2 | linked | Mbfbb     |            4 | load_mem           | linked                             | S.1.0bfbb                         | :null              | []                  | [a oa ov]  |
| 0 | 2 | linked | Mbfbb     |            3 | load_stored        | :attributes                        | :null                             | []                 | [**0 **1 **2 v]     |            |
| 0 | 2 | linked | Mbfbb     |            2 | stored_prefix_join | :null                              | ((a . **2) (oa . **0) (ov . **1)) | :null              | [a oa ov v]         |            |
| 0 | 2 | linked | Mbfbb     |            1 | reorder            | :null                              | :null                             | :null              | [a v oa ov]         |            |
| 0 | 2 | linked | Mbfbb     |            0 | out                | :null                              | :null                             | :null              | [a v oa ov]         |            |
| 0 | 3 | linked | Ibfbb     |            1 | load_mem           | ?                                  | S.0.0                             | :null              | []                  | [*1 *2 *3] |
| 0 | 3 | linked | Ibfbb     |            0 | out                | :null                              | :null                             | :null              | [*1 *2 *3]          |            |
| 0 | 4 | ?      | S.0.0     |            3 | unify              | *1                                 | :null                             | "title"            | [*1]                |            |
| 0 | 4 | ?      | S.0.0     |            2 | unify              | *2                                 | :null                             | "director"         | [*1 *2]             |            |
| 0 | 4 | ?      | S.0.0     |            1 | unify              | *3                                 | :null                             | "Steven Spielberg" | [*1 *2 *3]          |            |
| 0 | 4 | ?      | S.0.0     |            0 | out                | :null                              | :null                             | :null              | [*1 *2 *3]          |            |
| 0 | 5 | linked | S.0.0bfbb |            1 | load_mem           | linked                             | Ibfbb                             | :null              | []                  | [a oa ov]  |
| 0 | 5 | linked | S.0.0bfbb |            0 | out                | :null                              | :null                             | :null              | [a oa ov]           |            |
| 0 | 6 | linked | S.1.0bfbb |            1 | load_mem           | linked                             | Ibfbb                             | :null              | []                  | [a oa ov]  |
| 0 | 6 | linked | S.1.0bfbb |            0 | out                | :null                              | :null                             | :null              | [a oa ov]           |            |

#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[c] := linked['timezone', 'America/New_York', 'country', c]
#+end_src

#+RESULTS:
| United States |


#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[a, v, distance] := linked['coordinates', c, a, v], distance = l2_dist(vec([35.99403, -78.89862], 'F32'), c)
  :limit 10
  :order distance
#+end_src

#+RESULTS:
#+begin_example
[31meval::throw[0m

  [31m×[0m Evaluation of expression failed
   ╭─[1:1]
 [2m1[0m │ linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
 [2m2[0m │ ?[a, v, distance] := linked['coordinates', c, a, v], distance = l2_dist(vec([35.99403, -78.89862], 'F32'), c)
   · [35;1m                                                                ─────────────────────────────────────────────[0m
 [2m3[0m │ :limit 10
   ╰────
[36m  help: [0m'l2_dist' requires two vectors of the same type
#+end_example

Furthest cities (the distance formula isn't quite right but
demonstrates the concept). Disambiguate the city of Durham from other
durhams, using the state.
#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[v, s, country, distance] := linked['coordinates', c, 'state', 'North Carolina'], 
        linked['coordinates', c, 'name', 'Durham'],
        linked['coordinates', c2, 'name', v], distance = l2_dist(vec(c), vec(c2)),
        linked['coordinates', c2, 'state', s],
        linked['name', s, 'country', country]
        :limit 10
        :order -distance
#+end_src

#+RESULTS:
| Gisborne    | Gisborne District    | New Zealand | 71571.2578125 |
| Wairoa      | Hawke's Bay Region   | New Zealand |       71301.0 |
| Napier      | Hawke's Bay Region   | New Zealand |   71137.46875 |
| Hastings    | Hawke's Bay Region   | New Zealand |   71127.15625 |
| Taradale    | Hawke's Bay Region   | New Zealand | 71111.7421875 |
| Opotiki     | Bay of Plenty Region | New Zealand |    71107.5625 |
| Castlepoint | Wellington Region    | New Zealand |       70996.5 |
| Whakatane   | Bay of Plenty Region | New Zealand | 70945.6328125 |
| Murupara    | Bay of Plenty Region | New Zealand |  70875.046875 |
| Edgecumbe   | Bay of Plenty Region | New Zealand | 70871.4765625 |

#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[a, v] := linked['coordinates', c, 'country', 'United States'], linked['coordinates', c, a, v]
#+end_src

#+RESULTS:
| country    | Liberia                              |
| country    | United States                        |
| name       | Alabama                              |
| name       | Alaska                               |
| name       | American Samoa                       |
| name       | Arizona                              |
| name       | Arkansas                             |
| name       | Baker Island                         |
| name       | California                           |
| name       | Colorado                             |
| name       | Connecticut                          |
| name       | Delaware                             |
| name       | District of Columbia                 |
| name       | Florida                              |
| name       | Georgia                              |
| name       | Guam                                 |
| name       | Hawaii                               |
| name       | Howland Island                       |
| name       | Idaho                                |
| name       | Illinois                             |
| name       | Indiana                              |
| name       | Iowa                                 |
| name       | Jarvis Island                        |
| name       | Johnston Atoll                       |
| name       | Kansas                               |
| name       | Kentucky                             |
| name       | Kingman Reef                         |
| name       | Louisiana                            |
| name       | Maine                                |
| name       | Maryland                             |
| name       | Maryland County                      |
| name       | Massachusetts                        |
| name       | Michigan                             |
| name       | Midway Atoll                         |
| name       | Minnesota                            |
| name       | Mississippi                          |
| name       | Missouri                             |
| name       | Montana                              |
| name       | Navassa Island                       |
| name       | Nebraska                             |
| name       | Nevada                               |
| name       | New Hampshire                        |
| name       | New Jersey                           |
| name       | New Mexico                           |
| name       | New York                             |
| name       | North Carolina                       |
| name       | North Dakota                         |
| name       | Northern Mariana Islands             |
| name       | Ohio                                 |
| name       | Oklahoma                             |
| name       | Oregon                               |
| name       | Palmyra Atoll                        |
| name       | Pennsylvania                         |
| name       | Puerto Rico                          |
| name       | Rhode Island                         |
| name       | South Carolina                       |
| name       | South Dakota                         |
| name       | Tennessee                            |
| name       | Texas                                |
| name       | United States Minor Outlying Islands |
| name       | United States Virgin Islands         |
| name       | Utah                                 |
| name       | Vermont                              |
| name       | Virginia                             |
| name       | Wake Island                          |
| name       | Washington                           |
| name       | West Virginia                        |
| name       | Wisconsin                            |
| name       | Wyoming                              |
| state_code | AK                                   |
| state_code | AL                                   |
| state_code | AR                                   |
| state_code | AS                                   |
| state_code | AZ                                   |
| state_code | CA                                   |
| state_code | CO                                   |
| state_code | CT                                   |
| state_code | DC                                   |
| state_code | DE                                   |
| state_code | FL                                   |
| state_code | GA                                   |
| state_code | GU                                   |
| state_code | HI                                   |
| state_code | IA                                   |
| state_code | ID                                   |
| state_code | IL                                   |
| state_code | IN                                   |
| state_code | KS                                   |
| state_code | KY                                   |
| state_code | LA                                   |
| state_code | MA                                   |
| state_code | MD                                   |
| state_code | ME                                   |
| state_code | MI                                   |
| state_code | MN                                   |
| state_code | MO                                   |
| state_code | MP                                   |
| state_code | MS                                   |
| state_code | MT                                   |
| state_code | MY                                   |
| state_code | NC                                   |
| state_code | ND                                   |
| state_code | NE                                   |
| state_code | NH                                   |
| state_code | NJ                                   |
| state_code | NM                                   |
| state_code | NV                                   |
| state_code | NY                                   |
| state_code | OH                                   |
| state_code | OK                                   |
| state_code | OR                                   |
| state_code | PA                                   |
| state_code | PR                                   |
| state_code | RI                                   |
| state_code | SC                                   |
| state_code | SD                                   |
| state_code | TN                                   |
| state_code | TX                                   |
| state_code | UM                                   |
| state_code | UM-67                                |
| state_code | UM-71                                |
| state_code | UM-76                                |
| state_code | UM-79                                |
| state_code | UM-81                                |
| state_code | UM-84                                |
| state_code | UM-86                                |
| state_code | UM-89                                |
| state_code | UM-95                                |
| state_code | UT                                   |
| state_code | VA                                   |
| state_code | VI                                   |
| state_code | VT                                   |
| state_code | WA                                   |
| state_code | WI                                   |
| state_code | WV                                   |
| state_code | WY                                   |

***** Using an artificial entity column
#+begin_src cozodb :results value table
{:create eav {entity: Uuid, attribute: String, value: Any}}
#+end_src

What type should =entity= be? Some keys are uuids that link to pk attrs,
others are just the entity id. Maybe everything should use uuid? 
***** Add source and time columns
#+begin_src cozodb :results value table
  {:create trust {source: Bytes,
                  target: Bytes,
                  with: Any,
                  ts: Validity default 'ASSERT'
                  =>
                  score: Int,
                  }}
#+end_src

#+RESULTS:
| [31mparser::pest[0m |


#+begin_src cozodb
::remove trust
#+end_src

#+RESULTS:
: [31mquery::relation_not_found[0m
: 
:   [31m×[0m Cannot find requested stored relation 'trusted_attributes'

#+begin_src cozodb 
  ?[source, target, with, ts, score] <-
  [
   ["bWU=", "QWxpY2U=", 'introduce', 'ASSERT', 11]       
  ]
  :put trust {source, target, with, ts, score}
#+end_src

#+RESULTS:
: [31meval::invalid_validity[0m
: 
:   [31m×[0m when executing against relation 'trust'
: [31m  ├─▶ [0mwhen processing tuple ["bWU=", "QWxpY2U=", "introduce", [1703279106.2922018, true], 10]
: [31m  ╰─▶ [0m[1703279106.2922018, true] cannot be coerced into validity

#+begin_src cozodb
::relations
#+end_src

#+RESULTS:
| attributes     | 4 | normal | 4 | 0 | 0 | 0 | 0 |   |
| attributes:rev | 4 | index  | 4 | 0 | 0 | 0 | 0 |   |
| trust          | 5 | normal | 4 | 1 | 0 | 0 | 0 |   |

#+begin_src cozodb
?[source, target, with, score] := *trust[source, target, with, ts, score @ 'NOW']
#+end_src

#+RESULTS:
| bWU= | QWxpY2U= | introduce | 11 |

***** Questions
What about when we insert "name=Alice, height=1.2", and then later
"name=Alice, height=1.3"?

I think part of the problem is we can't just arbitrarily pair
attributes, one of them has to be the "key".

For example, let's say we don't do that and we have:
[name Alice, height 1.6]
[height 1.6, weight 50]

In this case the "link" is height. But we don't want to link to
anything that's 1.6m high.

The first attribute has to be something that identifies the
entity. But as we know, not every entity has a single attribute that
uniquely identifies it. eg Person. The name isn't unique, but let's
say name+birthday is unique.

[name Alice, height 1.6]
[name Alice, bday 1/1]
[name Alice, bday 6/4]
[name Alice, height 1.3]

What we need is a unique id to attach to her attributes:

[id 1, name Alice]
[id 1, bday 1/1]
;; now we can hang other attrs off the id
[id 1, height 1.6]

One question is, does every entity have some unique attribute? It may,
but either we may not know it or it's really a combination of more
than one.

So there's several solutions,
+ Make the first attr a compound of multiple actual attrs, and make
  the individual ones linked from there.
+ Hash the multiple attrs

 If the attrs are a tuple, in theory we can fetch the record directly
  ,if the user knows how the key is built. THat's better than a
  generated id which the user is guaranteed not to know. So given
  this, let's remodel.

***** kcats query format
#+begin_src cozodb
  linked[a, v, oa, ov] := *attributes[a, oa, v,  ov] or *attributes:rev[a, oa, v, ov]
  ?[a, v] := linked['coordinates', c, 'country', 'United States'], linked['coordinates', c, a, v]
#+end_src

Let's say we wanted to write this query as kcats data instead of a string. How?
We've got 2 rules, one with an =or= and the other an =and=.

We could create some words to build some more explicit objects.
#+begin_src kcats
  [a v oa ov] [linked]  
  [a oa v ov] [attributes] rel ;; *attributes[a, oa, v,  ov]
  [a oa v ov] [attributes rev] index ;; *attributes:rev[a, oa, v, ov]
  or
  rule
  [a v] [?]
  ["coordinates" c "country" "United States"] [linked] rel
  ["coordinates" c a v] [linked] rel
  and
  rule

#+end_src

Of course, the most straightforward is to probably just build the
query string, it's just a bit error prone and inefficient.

Let's do that query and dump the parsed object, so we can imitate it a bit:

#+begin_src rust :crates '(cozo)
  extern crate cozo;
  use cozo;

  fn main() {
      let db = DbInstance::new("mem", "", Default::default());
      db.par
  }
#+end_src
Ok nevermind those functions that deal with parsed scripts are
private. I guess we'll have to just build the query string!

#+begin_src kcats
  [[comma-separate [[string] map ", " interpose "" swap [join] step]]]
  [[a b c d] comma-separate]
  let
#+end_src

#+RESULTS:
#+begin_src kcats
"a, b, c, d"
#+end_src

***** Import into cozo by reading json
#+begin_src kcats
  "Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng"
  [", " split] assemble
#+end_src

#+RESULTS:
#+begin_src kcats
["Ama Qamata" "Khosi Ngema" "Gail Mabalane" "Thabang Molaba" "Dillon Windvogel" "Natasha Thahane"
 "Arno Greeff" "Xolile Tshabalala" "Getmore Sithole" "Cindy Mahlangu" "Ryle De Morny"
 "Greteli Fincham" "Sello Maake Ka-Ncube" "Odwa Gwanya" "Mekaila Mathys" "Sandi Schultz"
 "Duane Williams" "Shamilla Miller" "Patrick Mofokeng"]
#+end_src

#+begin_src kcats
  "/home/jweiss/Downloads/netflix_titles.json" file-out slurp decodejson 

  [[300 taker
    [["cast"] [[", " split] assemble] update
     [take] [] into 
     ;encodejson "u[uuid] <- [[rand_uuid_v1()]] av[attribute, value] <- {} ?[entity, attribute, value] :=  av[attribute, value], u[entity] :put eav {entity, attribute, value}"
     ;swap wrap format
    ]
    each
    [["description"] lookup \" contains?] keep
   ]
   assemble first emit "u[uuid] <- [[rand_uuid_v1()]] av[attribute, value] <- {} ?[entity, attribute, value] :=  av[attribute, value], u[entity] :put eav {entity, attribute, value}"
     swap wrap format print] [] recover 
#+end_src

#+RESULTS:
#+begin_src kcats
u[uuid] <- [[rand_uuid_v1()]] av[attribute, value] <- [["duration" "1 Season"] ["description" "Sicily boasts a bold \"Anti-Mafia\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?"] ["type" "TV Show"] ["title" "Vendetta: Truth, Lies and The Mafia"] ["listed_in" "Crime TV Shows, Docuseries, International TV Shows"] ["show_id" "s11"] ["director" ""] ["release_year" 2021] ["country" ""] ["cast" []] ["date_added" "September 24, 2021"] ["rating" "TV-MA"]] ?[entity, attribute, value] :=  av[attribute, value], u[entity] :put eav {entity, attribute, value}
#+end_src


 #+begin_src cozodb
           u[uuid] <- [[rand_uuid_v1()]] av[attribute, value] <- [["listed_in","Crime TV Shows, Docuseries, International TV Shows"],["duration","1 Season"],["release_year",2021],["show_id","s11"],["title","Vendetta: Truth, Lies and The Mafia"],["type","TV Show"],["description","Sicily boasts a bold \"Anti-Mafia\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?"],["director",""],["date_added","September 24, 2021"],["country",""],["cast",[]],["rating","TV-MA"]] ?[entity, attribute, value] :=  av[attribute, value], u[entity] :put eav {entity, attribute, value}
          #+end_src

          #+RESULTS:
          : [31mparser::pest[0m
          : 
          :   [31m×[0m The query parser has encountered unexpected input / end of input at 292..292
          :    ╭────
          :  [2m1[0m │ u[uuid] <- [[rand_uuid_v1()]] av[attribute, value] <- [["listed_in","Crime TV Shows, Docuseries, International TV Shows"],["duration","1 Season"],["release_year",2021],["show_id","s11"],["title","Vendetta: Truth, Lies and The Mafia"],["type","TV Show"],["description","Sicily boasts a bold \"Anti-Mafia\" coalition. But what happens when those trying to bring down organized crime are accused of being criminals themselves?"],["director",""],["date_added","September 24, 2021"],["country",""],["cast",[]],["rating","TV-MA"]] ?[entity, attribute, value] :=  av[attribute, value], u[entity] :put eav {entity, attribute, value} 
          :    · [35;1m                                                                                                                                                                                                                                                                                                    ▲[0m
          :    ╰────

#+begin_src kcats
"" [", " split] assemble
;[1 2 3 4 5] [[odd?] keep] assemble
#+end_src

#+RESULTS:
#+begin_src kcats
[[type error]
 [unwound [source [take] ", " split collect [[]] unwrap evert first]]
 [asked [source]]
 [reason "word is not defined"]
 [handled yes]]
#+end_src

#+begin_src kcats
[foo] [take] [] into
#+end_src
#+begin_src kcats
":create eav {entity: Uuid, attribute: String, value: Any}" database
#+end_src
#+RESULTS:
#+begin_src kcats
[["status"] ["OK"]]
#+end_src

#+begin_src cozodb
    ?[entity, attribute, value] <~
    Constant(data: [[uuid, "release_year", 2021],
     [uuid, "cast", ["Sami Bouajila", "Tracy Gotoas", "Samuel Jouy", "Nabiha Akkari", "Sofia Lesaffre", "Salim Kechiouche", "Noureddine Farihi", "Geert Van Rampelberg", "Bakary Diombera"]],
     [uuid, "show_id", "s3"],
     [uuid, "country", ""],
     [uuid, "director", "Julien Leclercq"],
     [uuid, "listed_in", "Crime TV Shows, International TV Shows, TV Action & Adventure"],
     [uuid, "rating", "TV-MA"], [uuid, "type", "TV Show"], [uuid, "title", "Ganglands"],
     [uuid, "date_added", "September 24, 2021"],
     [uuid, "duration", "1 Season"],
     [uuid, "description", "To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war."]]),
      uuid = rand_uuid_v4()
    :put eav {entity, attribute, value}

#+end_src

#+RESULTS:
: [31mparser::pest[0m
: 
:   [31m×[0m The query parser has encountered unexpected input / end of input at 777..777
:     ╭─[10:1]
:  [2m10[0m │  [uuid, "duration", "1 Season"],
:  [2m11[0m │  [uuid, "description", "To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war."]]),
:     · [35;1m                                                                                                                                                                              ▲[0m
:  [2m12[0m │   uuid = rand_uuid_v4()
:     ╰────

#+begin_src cozodb
  u[uuid] <- [[rand_uuid_v1()]]
  av[attribute, value] <- [["release_year",2021],["director","Julien Leclercq"],["description","To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war."],["duration","1 Season"],["rating","TV-MA"],["title","Ganglands"],["cast",["Sami Bouajila","Tracy Gotoas","Samuel Jouy","Nabiha Akkari","Sofia Lesaffre","Salim Kechiouche","Noureddine Farihi","Geert Van Rampelberg","Bakary Diombera"]],["type","TV Show"],["date_added","September 24, 2021"],["country",""],["listed_in","Crime TV Shows, International TV Shows, TV Action & Adventure"],["show_id","s3"]]
  ?[entity, attribute, value] :=  av[attribute, value], u[entity]

  :put eav {entity, attribute, value} :returning

#+end_src

#+RESULTS:
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | cast         | [Sami Bouajila Tracy Gotoas Samuel Jouy Nabiha Akkari Sofia Lesaffre Salim Kechiouche Noureddine Farihi Geert Van Rampelberg Bakary Diombera]      |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | country      |                                                                                                                                                    |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | date_added   | September 24, 2021                                                                                                                                 |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | description  | To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war. |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | director     | Julien Leclercq                                                                                                                                    |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | duration     | 1 Season                                                                                                                                           |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | listed_in    | Crime TV Shows, International TV Shows, TV Action & Adventure                                                                                      |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | rating       | TV-MA                                                                                                                                              |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | release_year | 2021                                                                                                                                               |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | show_id      | s3                                                                                                                                                 |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | title        | Ganglands                                                                                                                                          |
| inserted | 36fc42bd-a775-11ee-a783-d0c86867d02e | type         | TV Show                                                                                                                                            |

#+begin_src cozodb
  linked[a1, v1, a2, v2] := *eav[id, a1, v1], *eav[id, a2, v2]
  ?[t] := linked['title', t, 'release_year', 2021]          
#+end_src

#+RESULTS:
| Blood & Water                    |
| Ganglands                        |
| Jailbirds New Orleans            |
| Kota Factory                     |
| Midnight Mass                    |
| My Little Pony: A New Generation |
| The Great British Baking Show    |
| The Starling                     |
